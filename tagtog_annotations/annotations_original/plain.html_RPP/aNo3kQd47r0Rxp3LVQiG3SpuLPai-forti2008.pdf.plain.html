<!DOCTYPE html >
<html id="aNo3kQd47r0Rxp3LVQiG3SpuLPai-forti2008.pdf" data-origid="forti2008.pdf" class="anndoc" data-anndoc-version="3.6" lang="" xml:lang="" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="UTF-8"/>
    <meta name="generator" content="net.tagtog.anndoc.v3.parsers.general.StubPdfParser_v1_0_0"/>
    <title>aNo3kQd47r0Rxp3LVQiG3SpuLPai-forti2008.pdf</title>
  </head>
  <body>
    <article>
      <section data-type="">
        <div class="content">
          <p id="s1p1">Research Article Sensitivity to Object Viewpoint and Action Instructions During Search for Targets in the Lower Visual Field Sara Forti1,2 and Glyn W. Humphreys1 1Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, and 2Neuropsychology Unit, IRCCS ‘‘Eugenio Medea,’’ Bosisio Parini, Italy ABSTRACT—We contrasted visual search for targets pre- sented in prototypical views and targets presented in non- prototypical views, when targets were defined by their names andwhen theywere defined by the action thatwould normally be performed on them. The likelihood of the first fixation falling on the target was increased for prototypical- view targets falling in the lower visual field. When targets were defined by actions, the durations of fixations were reduced for targets in the lower field. The results are consistent with eye movements in search being affected by representations within the dorsal visual stream, where there is strong representation of the lower visual field. These representations are sensitive to the familiarity or the affordance offered by objects in prototypical views, and they are influenced by action-based templates for targets. In visual search tasks, participants are typically asked to detect particular targets presented among varying numbers of dis- tractors. How the target is defined appears to affect the nature of the search process.Humphreys andRiddoch (2001) reported data froma patient with unilateral visual neglect, who frequently failed to detect targets on the side of space contralateral to his lesion when targets were defined by their names. However, this neglect was strikingly reduced when the patient was asked to find targets that were defined by the action that would be performed on them (e.g., ‘‘find the object to drink from’’ vs. ‘‘find the cup’’). To account for these findings, the authors suggested that the patient was able tomatch inputwith a template based on the action, but was unable to match input with a template derived from the name of the ob- ject. This was true even though the patient knew what each object was from its name, and even though he showed normal identifi- cation of single objects. The patient may have been able to main- tain the action template better than any visual template derived from the object’s name, so that an action template helped him sustain search on the affected side; alternatively, the patient may have been able to respond to affordances that were computed in- dependently of an object’s identity and that were detectable from objects on both the ipsi- and contralesional sides of space. A study by Bekkering and Neggers (2002) provides converg- ing evidence from normal observers. In this study, participants either pointed to or grasped a target defined by a conjunction of its orientation and color. Saccades to distractors having the same orientation as the target were more likely when a grasping re- sponse was made than when a pointing response was made. This suggests that contrasting actions can differentially weight visual information, with orientation being weighted more strongly for selection when a grasping rather than a pointing response is re- quired (see also Hannus, Cornelissen, Lindemann, &amp; Bekkering, 2005). These data are consistent withmodels in which search can be guided in a top-down fashion by templates defined by the target or the action to be made with the target (cf. Duncan &amp; Humphreys, 1989;Moores, Laiti, &amp;Chelazzi, 2003;Wolfe, 1994). Apparently, holding a template for a particular action and holding a template based on a visual definition of an object can shape the search process differently. In the study reported in this article, we sought to examine further the contrast between searching for a target defined by an Address correspondence to Glyn W. Humphreys, Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, Birmingham B15 2TT, United Kingdom, e-mail: g.w.humphreys@ bham.ac.uk. PSYCHOLOGICAL SCIENCE 42 Volume 19—Number 1Copyright r 2008 Association for Psychological Science at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from action and searching for a target defined by its name. We mea- sured eye movements while normal participants searched for named-defined and action-defined targets. Performance was an- alyzed separately for trials with targets in the upper visual field and trials with targets in the lower visual field. The dorsal area of V1 represents the lower visual field and projects primarily to the dorsal visual pathway, whereas the ventral area of V1 represents the upper visual field and projects primarily to the ventral visual pathway (Horton &amp; Hoyt, 1991; Previc, 1990). Thus, there are stronger projections from the lower visual field than from the upper visual field into posterior parietal cortex (e.g., area V6A; Galletti, Fattori, Gamberini, &amp; Kutz, 1999). It is possible that searching by action and searching by name differentially recruit the dorsal and ventral visual pathways to support performance. Milner and Goodale (1993), for example, argued that the ventral pathway is functionally specialized for object recognition (the ‘‘what’’ pathway) and the dorsal pathway is functionally special- ized for the actions linked to objects (the ‘‘how’’ pathway; see also Creem &amp; Proffitt, 2001). It may follow that searching by action, recruiting the dorsal visual stream, favors information in the lower visual field. In addition, Previc (1990) argued that because the lower visual field represents near space, neural regions re- sponding to this area are specialized for the analysis of features relevant to actions with objects in near space. In contrast, searching for an object defined by its namemay favor information in the upper visual field, whichmay bemore specialized for distal properties of objects tied to their identity (cf. Previc, 1990). In addition to examining the effects of instruction, we evalu- ated search for targets in prototypical relative to nonprototypical views. Though the time needed to recognize objects and to de- rive action-related information about objects should be less for stimuli in prototypical views than for stimuli in nonprototypical views (e.g., Palmer, Rosch, &amp; Chase, 1981), this effect may be most pronounced for action decisions and for neural regions responsive to action affordances from objects. For example, in Humphreys and Riddoch’s (2001) study of neglect, the benefits for searching by action occurred when objects appeared in prototypical views for action. Similarly, Yoon and Humphreys (2007) reported that comparedwith semantic decisionsmade in re- sponse to objects, action decisions are more sensitive to view- point. Accordingly, dorsal regions, which are sensitive to action, might be particularly affected by viewpoint. METHOD Participants The 14 participants (11 females and 3 males; ages 17–39 years, M 5 25.7) were all right-handed and had either normal or cor- rected-to-normal vision. Apparatus The experiment was controlled by a 1.5-GHz Pentium IV com- puter. Stimuli were presented on a Trinitron Multiscan G240 monitor (17 in.), using a screen resolution of 600  800 pixels. The display height was adjusted for each participant by setting the height of the chair he or she sat on. Eye movements were recorded using a head-mounted eyetracker (SMI Eyelink V2.04; SensoMotoric Instruments GmbH, Berlin, Germany) with a sam- pling rate of 250 Hz. Responses were registered using a button box. Procedure The display sequence is depicted in Figure 1a. Each trial started with a black fixation point, shown against a white background screen. The duration of this display was unlimited. When ready, the participant pressed a button to remove the fixation point, and the instructions regarding what to search for were displayed for 2,000 ms (black text on a white background). A second fixation point (600 ms) preceded the stimulus display, which remained present until the participant responded. Participants were in- structed to look for and to fixate the target; once they were sure they had found the target, they were to press a button to end the trial. The speed of the button-press response was not empha- sized. The target was present in all trials. Presentation of stimuli was self-paced, and subjects were allowed to take an unlimited number of breaks. The stimuli were black-and-white photographs of real objects (see Fig. 1b). On any trial, all the stimuli were depicted in either a prototypical or a nonprototypical view (view was randomized across trials). When an object was depicted in a prototypical view, all its main features were visible, and the object was aligned for action. In the nonprototypical view, the object was rotated away from its usual view, and it was not oriented for a right-hand action; typically, the graspable part of the object was positioned toward the nondominant (left) hand (for our right- handed participants). Fig. 1. Illustration of the display sequence (a) and of an object in its prototypical and nonprototypical views (b). The example sequence shown here is from the name condition. Volume 19—Number 1 43 Sara Forti and Glyn W. Humphreys at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from Each photograph was inscribed into an area measuring 100 100 pixels (4.61 4.61 at a viewing distance of 60 cm), and the relative size of the objects was taken into account (e.g., a bicycle was bigger than a pen). Within each display, eight stimuli were presented in a circle with a radius of 170 pixels (7.41); the two middle objects were placed at eye level, in order to have the three upper objects falling in the upper visual field and the three lower objects falling in the lower visual field. The target’s position was randomized across trials. In the analyses, we ex- cluded trials in which the target was one of the two middle ob- jects, considering only stimuli in the upper and lower visual fields. There were two instruction conditions, presented in two sep- arate blocks of 240 trials each, and block order was randomized across participants. In the name condition, the participants were given the names of the objects they had to look at (e.g., ‘‘scis- sors’’); in the action condition, each target was defined by the associated action (e.g., ‘‘cut paper’’). Thus, the target was am- biguously specified in the action condition, because there are typically multiple objects consistent with a given action. How- ever, within a search display, there was only one object con- sistent with the instructions given (i.e., only one object with the name given in name search and only one object consistent with the action given in action search). We used a set of 60 familiar objects; 20 that could be defined either by a name or by a specific action were used as targets, and the remaining 40 were always used as distractors. RESULTS We considered the effects of three variables: the instructions (search by name vs. search by action), the viewpoint (proto- typical vs. nonprototypical), and the target’s visual field (upper vs. lower).1 The data were analyzed in three-way repeated measures analyses of variance. Including only correct trials (i.e., those on which the target was eventually fixated), we measured (a) the probability that the first fixation was on the target, (b) the time taken until the first fixation on the target, (c) the duration of the first fixation on the target, (d) the total number of fixations on the target, and (e) the total length of fixations on the target (summed across different fixations in a trial). Probability of the First Fixation Being on the Target The probability of the first fixation being on the target showed a significant effect of viewpoint, F(1, 13) 5 50.3, prep &gt; .99: Prototypical-view targets received more first fixations (M 5 12.2%) than nonprototypical-view targets (M 5 5.3%). There was also a significant main effect of the target’s visual field, F(1, 13) 5 22.6, prep &gt; .99, with targets in the lower visual field receiving more first fixations (M 5 12.2%) than targets in the upper visual field (M5 5.3%). These two factors interacted,F(1, 13)5 14.2, prep&gt; .99: The effect of visual field was enhanced for objects depicted in a prototypical orientation, though visual field was significant for both views. There was no main effect of instructions, F(1, 13) 5 1.2, prep 5 .64, and no interactions involving this factor were significant (all Fs &lt; .0). The results for this dependent measure are depicted in the top panel of Figure 2. Time Until the First Fixation on the Target This measure showed no reliable effects (see Fig. 2, bottom panel). Duration of the First Fixation on the Target The duration of the first fixation on the target showed a reliable main effect of viewpoint, with longer fixations to nonprototypical than to prototypical targets, F(1, 13)5 10.33, prep5 .852, but no effects of instructions or the target’s visual field, F(1, 13)5 2.46 and F&lt; 1.0, both preps&lt; .88. There was an interaction between the type of instruction and the target’s visual field, F(1, 13) 5 10.926, prep5 .86. In the action condition, first-fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13) 5 2.1, prep 5 .88. In the name con- dition, the durations of the first fixation on the target were, if anything, shorter for targets in the upper than for those in the lower visual field, t(13)5 1.8, prep5 .82.We also found a reliable interaction between instructions and viewpoint,F(1, 13)5 17.88, prep &gt; .99: First fixations to targets in prototypical viewers were shorter than first fixations to targets in nonprototypical views in the action condition, t(13)5 3.8, prep 5 .98, but not in the name condition, t(13) 5 1.4, prep 5 .74. Finally, there was a reliable three-way interaction among instructions, viewpoint, and visual field, F(1, 13) 5 6.44, prep 5 .92 (see Fig. 3, top panel). The effects of viewpoint were pronounced only in the action condition for targets in the upper field, t(13)5 3.8, prep 5 .98. Number of Fixations on the Target The number of fixations on the target (prior to responding to finding the target) showed a reliable main effect of viewpoint, F(1, 13) 5 6.23, prep 5 .91; there were more fixations on non- prototypical-view than on prototypical-view targets. The effect of instructions was not reliable, F(1, 13) 5 1.06, prep 5 .63, though the main effect of the target’s visual field approached significance, F(1, 13) 5 3.81, prep 5 .85. There was an inter- action between instructions and visual field, F(1, 13) 5 5.98, prep 5 .91. In the action condition, fewer fixations were made to targets in the lower visual field than to targets in the upper visual field, t(13)5 3.0, prep5 .95; in the name condition, there was no 1We also examined effects of whether items fell in the left or right visual field, because some studies indicate differences between the upper and lower visual fields on either only the left side (Niebauer &amp; Christman, 1998) or only the right side (Handy, Grafton, Shroff, Ketay, &amp; Gazzaniga, 2003), depending on the task. However, we failed to find effects of left versus right field. Hence, the data are averaged across this factor. 44 Volume 19—Number 1 Object Viewpoint, Visual Field, and Action Instructions During Search at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from effect of visual field, t(13)5 0.3, prep 5 .29. These effects held across both prototypical and nonprototypical views,F(1, 13)&lt; 1.0 for the interaction of instructions, viewpoint, and visual field. The bottom panel in Figure 3 presents the mean numbers of fixations on targets. Total Length of Fixations on the Target This measure showed a main effect of viewpoint, F(1, 13) 5 7.50, prep 5 .93, with total fixation time being longer for non- prototypical than for prototypical objects; the main effect of instructions was not reliable (F &lt; 1.0), but that of field ap- proached significance, F(1, 13) 5 4.00, prep 5 .85. There was one reliable interaction, between instructions and visual field, F(1, 13) 5 5.18, prep &gt; .89. In the action condition, fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13)5 2.7, prep5 .93; in the name condition, there was no effect of visual field, t(13) 5 0.3, prep 5 .33. The data are shown in the middle panel of Figure 3. DISCUSSION Search varied as a function of the orientation of the stimuli and the instructions given for the search task. We discuss each effect in turn. Generally, we found an effect of orientation in four of the five eye movement parameters measured, with performance being facilitated for stimuli depicted in a prototypical view. Thus, compared with nonprototypical-view targets, prototypi- cal-view targets were more likely to receive first fixations, had shorter total fixation durations, and required fewer fixations before the detection response was initiated. These effects of view- point are consistent with the literature on object recognition and on action decisions in response to objects, which shows that the familiarity of view is a strong determiner of performance (Palmer et al., 1981; Yoon &amp; Humphreys, 2007). Interestingly, though, viewpoint interacted with visual field when the probability of making a first fixation to a target and the duration of the first fixation to the target were measured. The increased probability of making a first fixation to a prototypical-view target was more pronounced when the target was in the lower visual field than when it was in the upper visual field. The instruction manipulation influenced several other eye movement parameters. Specifically, the action instructions fa- cilitated performance as measured by parameters reflecting eye movements after targets had been fixated (Fig. 3). These effects were confined to targets falling in the lower visual field. The duration of the first fixation made to the target, the number of fixations made to the target before the detection response was made, and the average total length of the fixations on the target were all selectively reduced for targets in the lower visual field in the action condition. When objects were cued by their names, these effects of field were absent (if anything, there was a tendency for the duration of the first fixations on targets to be reduced for targets in the upper visual field). Fig. 2. Probability of the first fixation falling on the target (top panel) and mean time taken before first fixations to targets (bottom panel), as a function of viewpoint, visual field, and instructions (search by name vs. action). Volume 19—Number 1 45 Sara Forti and Glyn W. Humphreys at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from To understand these results, it is useful to differentiate be- tween effects on the first saccade made in search and effects on subsequent fixation behavior. The probability of the first saccade being directed at a target was affected by the orientation of the stimuli and the visual field of the target, but not by the in- structions. The first saccade was more likely to go to a proto- typical-view than to a nonprototypical-view target, but only when that target fell in the lower visual field; indeed, only when a prototypical-view target fell in the lower visual field was the likelihood of the first fixation going to the target greater than chance. In many search tasks, search is biased to start in the upper visual field (Heywood &amp; Churcher, 1980). However, there was no evidence for such a bias in the present study. We cal- culated the probability of the first saccade being directed toward the upper versus the lower visual field, irrespective of the tar- get’s location, and found no difference in the rate of downward Fig. 3. Mean duration of the first fixation on the target (top panel), mean total length of fixations on the target (middle panel), and mean number of fixations on the target (bottom panel), as a function of viewpoint, visual field, and instructions (search by name vs. action). 46 Volume 19—Number 1 Object Viewpoint, Visual Field, and Action Instructions During Search at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from versus upward saccades, either as amain effect,F(1, 13)5 3.09, prep5 .81, or in combination with instructions or viewpoint (both Fs &lt; 1.0). The data suggest that there was no systematic ten- dency, across participants, for search to start or end in set locations. The tendency for first fixations to go to a prototypical- view target in the lower field, then, does not reflect a general pattern in search, but rather reflects the capture of overt atten- tion by the stimulus. This result is consistent with the proto- typical-view target being detected by the dorsal visual stream prior to the eye movement being programmed—so that the effect emerged only when the target was in the lower visual field. The data suggest that the dorsal stream is sensitive to either the fa- miliarity of the viewpoint or the affordance when the object is in the appropriate orientation for action. Viewpoint had an early effect on search, influencing where the first saccade was made. However, the task instructions did affect fixation behavior after the first saccade. Fixation durations were reduced, and fewer fixations weremade, when targets were in the lower visual field and the action instructions were given. In the name condition, first-fixation durations tended to be reduced for targets in the upper visual field. These results suggest that the different task instructions affected a stage of processing in which fixated information was matched to a template defining the target. There appears to be a better match of stimulus in- formation to an action-based template for a target falling in the lower, rather than the upper, visual field, whereas, if anything, there is a better match to a template derived from the object’s name when the target is in the upper, rather than the lower, vi- sual field. This fit to the template in the action task is also better for objects depicted in prototypical views, given that the dura- tion of the first fixation in this condition was shorter for targets in prototypical views than for targets in nonprototypical views. These results are consistent with action-based templates being represented in the dorsal visual stream.2 Although action instructions reduced the duration of the first fixation to targets in the lower visual field, first fixations were much longer under action than name instructions when targets fell in the upper visual field. This is not surprising. There is inherently more ambiguity about targets defined by action than about targets defined by their name (‘‘Is there an object that cuts paper present?’’ vs. ‘‘Are scissors present?’’), and one can thus expect that it would take more time to verify that a target matches a verbal instruction under action than under name in- structions. The striking result is that this advantage for the name condition was reversed for targets in the lower field, which suggests that an action template was matched directly to the stimulus in this case. It should be noted that once an observer makes a first saccade to an item in the upper or lower visual field, that item is no longer in the same retinotopic location, though the object remains in the same position with respect to the observer’s body. Also, after the first saccade, objects originally in the lower visual field may tend still to be represented in near space, and objects originally in the upper visual field to be represented in far space (cf. Previc, 1990). If processing biases in the dorsal stream are sensitive to the position of objects with respect to the observer’s body, or if the dorsal stream is more sensitive to object locations in near space than to object locations in far space, then the emergence of the lower-field advantage in searching by action can be explained. In addition, it is possible that the advantage of the lower visual field reflects the superior extraction of infor- mation from the retinotopic lower field, which then facilitates matching to the action template. The opposite tendency, for an upper-field advantage in searching for objects defined by their names, also arose for fixation behavior subsequent to the first saccade, which suggests that this tendency, too, reflects a pro- cess involving matching to memory, rather than directing at- tention in the first place. In conclusion, the data indicate that action instructions and viewpoint-dependent familiarity or affordance have specific ef- fects on search for objects appearing in the lower visual field. The results fit with the idea that the dorsal visual stream, where there is strong representation of the lower visual field, can both direct overt attention (the first saccade) and modulate the time required to match a stimulus to a template of the target. Acknowledgments—This work was supported by grants from the Biotechnology and Biological Sciences Research Council, Engineering and Physical Sciences Research Council, and Med- ical Research Council (UK). REFERENCES Bekkering, H., &amp; Neggers, S.F.W. (2002). Visual search is modulated by action intentions. Psychological Science, 13, 370–374. Creem, S.H., &amp; Proffitt, D.R. (2001). Defining the cortical visual systems: ‘‘What’’, ‘‘Where’’, and ‘‘How.’’ Acta Psychologica, 107, 43–68. Duncan, J., &amp; Humphreys, G.W. (1989). Visual search and stimulus similarity. Psychological Review, 96, 433–458. Galletti, C., Fattori, P., Gamberini, M., &amp; Kutz, D.F. (1999). The cor- tical visual area V6: Brain location and visual topography. Eu- ropean Journal of Neuroscience, 11, 3922–3936. Handy, T.C., Grafton, S.T., Shroff, N.M., Ketay, S., &amp; Gazzaniga, M.S. (2003). Graspable objects grab attention when the potential for action is recognized. Nature Neuroscience, 6, 421–427. Hannus, A., Cornelissen, F.W., Lindemann, O., &amp; Bekkering, H. (2005). Selection-for-action in visual search. Acta Psychologica, 118, 171–191. Heywood, S., &amp; Churcher, J. (1980). Structure of the visual array and saccadic latency: Implications for oculomotor control. Quarterly Journal of Experimental Psychology, 32, 335–341. Horton, J.C., &amp; Hoyt, W.F. (1991). Quadrantic visual-field defects: A hallmark of lesions in extrastriate (V2/V3) cortex. Brain, 114, 1703–1718. 2The action effects reported here may also reflect processing in the premotor cortex and the frontal eye fields, which is related to action planning, but we know of no evidence indicating a field preference in these cortical regions. Volume 19—Number 1 47 Sara Forti and Glyn W. Humphreys at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from Humphreys, G.W., &amp; Riddoch, M.J. (2001). Detection by action: Ev- idence for affordances in search in neglect. Nature Neuroscience, 4, 84–88. Milner, A.D., &amp; Goodale, M.A. (1993). Visual pathways to perception and action. Progress in Brain Research, 95, 317–337. Moores, E., Laiti, L., &amp; Chelazzi, L. (2003). Associative knowledge controls deployment of visual selective attention. Nature Neu- roscience, 6, 182–189. Niebauer, C.L., &amp; Christman, S.D. (1998). Upper and lower visual field differences in categorical and coordinate judgments. Psycho- nomic Bulletin &amp; Review, 5, 147–151. Palmer, S., Rosch, E., &amp; Chase, P. (1981). Canonical perspective and the perception of objects. In J.B. Long &amp; A.D. Baddeley (Eds.), Attention and performance, IX (pp. 135–151). Hillsdale, NJ: Erlbaum. Previc, F.H. (1990). Functional specialization in the lower and upper visual fields in humans: Its ecological origins and neurophysio- logical implications. Behavioral and Brain Sciences, 13, 519– 541. Wolfe, J.M. (1994). Guided Search 2.0: A revised model of visual search. Psychonomic Bulletin &amp; Review, 1, 202–238. Yoon, E.Y., &amp; Humphreys, G.W. (2007). Dissociative effects of view- point and semantic priming on action and semantic decisions: Evidence for dual routes to action from vision. Quarterly Journal of Experimental Psychology, 60, 601–623. (RECEIVED 4/24/07; REVISION ACCEPTED 6/3/07) 48 Volume 19—Number 1 Object Viewpoint, Visual Field, and Action Instructions During Search at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from</p>
        </div>
      </section>
    </article>
  </body>
</html>
