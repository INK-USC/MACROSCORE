<!DOCTYPE html >
<html id="amsVAwy6s1iog75qgt5WAgc..gP4-Jara_Ettinger_JournExPsychGen_2017_121q.pdf" data-origid="Jara-Ettinger_JournExPsychGen_2017_121q.pdf" class="anndoc" data-anndoc-version="3.6" lang="" xml:lang="" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="UTF-8"/>
    <meta name="generator" content="net.tagtog.anndoc.v3.parsers.general.StubPdfParser_v1_0_0"/>
    <title>amsVAwy6s1iog75qgt5WAgc..gP4-Jara_Ettinger_JournExPsychGen_2017_121q.pdf</title>
  </head>
  <body>
    <article>
      <section data-type="">
        <div class="content">
          <p id="s1p1">Children Understand That Agents Maximize Expected Utilities Julian Jara-Ettinger Yale University Sammy Floyd Princeton University Joshua B. Tenenbaum and Laura E. Schulz Massachusetts Institute of Technology A growing set of studies suggests that our ability to infer, and reason about, mental states is supported by the assumption that agents maximize utilities—the rewards they attain minus the costs they incur. This assumption enables observers to work backward from agents’ observed behavior to their underlying beliefs, preferences, and competencies. Intuitively, however, agents may have incomplete, uncertain, or wrong beliefs about what they want. More formally, agents try to maximize their expected utilities. This understanding is crucial when reasoning about others’ behavior: It dictates when actions reveal prefer- ences, and it makes predictions about the stability of behavior over time. In a set of 7 experiments we show that 4- and 5-year-olds understand that agents try to maximize expected utilities, and that these responses cannot be explained by simpler accounts. In particular, these results suggest a modification to the standard belief/desire model of intuitive psychology. Children do not treat beliefs and desires as independent; rather, they recognize that agents have beliefs about their own desires and that this has consequences for the interpretation of agents’ actions. Keywords: theory of mind, social cognition, cognitive development Supplemental materials: http://dx.doi.org/10.1037/xge0000345.supp Human commonsense psychology is characterized by a remark- able facility to draw meaningful interpretations of simple behavior with strong predictive power (Heider &amp; Simmel, 1944). At the center of our commonsense psychology lies an intuitive causal theory of how other people’s mental states—their beliefs and desires—relate to the actions they take (Dennett, 1989; Gopnik &amp; Meltzoff, 1997; Wellman, 1990, 2014). If we learn that Sally wants a cookie and that she believes there are cookies in the cookie jar, we can predict that Sally will walk toward the cookie jar and take a cookie out. This causal theory also enables us to work backward from Sally’s actions to her mental states. If Sally takes a cookie from the cookie jar and eats it, we can infer that she wanted a cookie and that she (correctly) believed that she would find one in the cookie jar. These accounts, however, have largely focused on beliefs that represent content about the world (e.g., the location of the cookies; Figure 1a). However, agents also have beliefs about the contents of their minds (see also Bartsch &amp; Wellman, 1995; Flavell, Flavell, Green, &amp; Moses, 1990; Miller, 2009). Consider again the simple case of watching Sally get a cookie from the jar. Usually this means that Sally likes cookies and that she would get a cookie again if she were in the same situation (and infants appear to share this intuition; Woodward, Sommerville, &amp; Guajardo, 2001). How- ever, this inference critically assumes that Sally knew that she liked cookies. If Sally had never tried a cookie before, we would not be so confident that Sally taking a cookie implies that she likes cookies, or that she will take them again in the future. For us to know what someone likes, she has to know it herself first. Cookies, of course, are almost universally familiar and univer- sally liked, but in novel contexts, inferences that depend on an agent’s beliefs about her desires are both commonplace and critical for social cognition. If your friend, for instance, buys food that she has never tasted before, her choices may not tell us anything about her stable, long-term preferences. Conversely, if your friend tries some food, changes her mind, and chooses a different kind of food, you might infer that she was initially naïve, unsure, or wrong about her preferences. In these cases, the instability of the agent’s be- havior reveals the initial uncertainty of her beliefs about her desires. The same logic applies to beliefs about the costs of actions. For example, Sally might be eager (or reluctant) to join a committee. However, if she does not understand the costs involved, her actions may not be informative about her future ones. Conversely, if Sally signs up for the committee and then fails to attend regularly, you This article was published Online First July 17, 2017. Julian Jara-Ettinger, Department of Psychology, Yale University; Sammy Floyd, Department of Psychology, Princeton University; Joshua B. Tenenbaum and Laura E. Schulz, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology. We thank the Boston Children’s Museum and the families who volun- teered to participate. We thank Holly Huey, Emily Lydic, Allison Kaslow, and Eileen Rivera for help with recruitment, data collection, and video coding. We are grateful to Paul Bloom, Rachel Magid, and Elizabeth Spelke for useful comments. This material is based upon work supported by the Center for Brains, Minds, and Machines (CBMM), funded by NSF- STC award CCF-1231216, and by the Simons Center for the Social Brain. Julian Jara-Ettinger and Sammy Floyd made an equal contribution. Correspondence concerning this article should be addressed to Julian Jara-Ettinger, Department of Psychology, Yale University, 2 Hillhouse Avenue, New Haven, CT 06520. E-mail: julian.jara-ettinger@yale.edu T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. Journal of Experimental Psychology: General © 2017 American Psychological Association 2017, Vol. 146, No. 11, 1574–1585 0096-3445/17/$12.00 http://dx.doi.org/10.1037/xge0000345 1574 might infer that she had not accurately estimated the commitment involved. Recent work suggests that the intuitive relationship between mental states and behavior is powered by a naive utility calculus (Jara-Ettinger, Gweon, Schulz, &amp; Tenenbaum, 2016; Jara-Ettinger, Gweon, Tenenbaum, &amp; Schulz, 2015; Jara-Ettinger, Schulz, &amp; Tenenbaum, 2017; Jara-Ettinger, Tenenbaum, &amp; Schulz, 2015; see also Johnson &amp; Rips, 2015; Lucas et al., 2014). According to this intuitive theory of decision-making, agents choose what to do by associating utilities with goals, and pursuing the one with the highest utility (Figure 1b). Each goal’s utility is given by the rewards the agent expects to obtain minus the costs she expects to incur. Thus, as a goal’s reward increases, its utility increases, and as a goal’s cost increases, its utility diminishes. Critically, the naïve utility calculus is a theory of how people think other people make decisions, and it may differ in important ways from how people actually make decisions (see Jara-Ettinger et al., 2016). More formally, the utility U(S, A) for taking actions A to reach goal-state S is given by the reward obtained in the goal-state state, R(S), minus the action costs, C(A), that lead to this state. Because agents cannot estimate the utility function U(S, A) precisely, they act on the expected utility, E[U(S, A)]  E[R(S)] – E[C(A)]. Over time, as agents interact with the world, they update their utility estimates. Figure 2a shows intuitive representations of agents’ beliefs about two sources of reward and how they are updated over time. Figure 2b shows a visual schematic of how the spread and expected value of these reward distributions determines the agent’s choice. Under this account, agents’ knowledge of the costs and rewards should influence their behavior in two ways. First, knowledgeable agents’ expected utilities should be closer to the true utilities compared to ignorant agents’ expected utilities. As such, knowl- edgeable agents should be more likely to select the utility- maximizing plan. Second, compared with ignorant agents, knowl- edgeable agents should be less likely to change their beliefs about which plan has the highest utility in light of new experience, and they should therefore have more stable choices over time (see Figure 2). Although current evidence suggests that children expect agents to maximize utilities (Jara-Ettinger, Gweon, et al., 2015), it is unknown if they understand that these utilities are estimated and not exact. To investigate children’s understanding of how agents’ uncer- tainty about their costs and rewards relates to their behavior we test the predictions outlined above. To the degree that researchers have looked at children’s inferences regarding beliefs, they have fo- cused primarily on issues related to epistemic access: canonically, whether the agent does or does not see where a desired object has been placed (e.g., Wimmer &amp; Perner, 1983). The current study goes beyond merely representing agents’ beliefs about the world and treating beliefs and desires as independent nodes affecting action (Goodman et al., 2006; Gopnik &amp; Meltzoff, 1997; Wellman, 1990; Figure 1a). Instead, we propose that children understand that agents can have beliefs about their own desires (Figure 2b) and understand that different agents might perform the same actions with the same beliefs about the world and yet interpret the expe- rience differently, depending on their knowledge or ignorance of their own utilities. Research suggests that, by age four, children can explicitly reason about others’ beliefs (Wellman, Cross, &amp; Watson, 2001), and that by five, children expect agents to maximize utilities (Jara-Ettinger, Gweon, et al., 2015). Because the current studies Beliefs Actions Desires Beliefs Utilities Actions RewardsCosts Beliefs Actions Costs Utilities Rewards Experiments 1-4 Experiments 5-7 a b c Figure 1. (a) Classical Theory of Mind model where the focus is on the independent contribution that beliefs and desires have on actions. (b) The naïve utility calculus embedded in the same framework. Desires are sep- arated into rewards (what agents like) and utilities (what agents want), and their relation is mediated by the costs. Agents’ beliefs about their own costs and rewards determine their expected utilities. (c) In Experiments 1–4 we explore children’s understanding of how knowledge of rewards determines actions, and how the actions lead to updating the agents’ rewards. In Experiments 5–7 we test the same understanding over utilities. See the online article for the color version of this figure. Experience E xp e ct e d re w ar d Ignorant Knowledgeable a b B e lie f Reward Yuck! Yum! Yuck! Yum! 1 2 1 2 Figure 2. Belief distributions over the space of possible rewards over time using two different visualizations. In this example, the belief distri- bution of the rambutan (red fruit; red/dark gray curve) begins with high uncertainty and a slight bias toward a lower reward (frame 1; left plot in panel a and left side of plot on panel b) and gets revised to a belief for a high reward (frame 2; right plot in panel b and right side of plot on panel b); the African cucumber (yellow fruit; yellow/light gray curve) shows a similar trend on the opposite direction. (a) Each plot shows a visual schematic of a distribution of beliefs over rewards. (b) Visual schematic of expected rewards as a function of experience. The x-axis represents the amount of experience with a source of rewards, and the y-axis represents the range of possible rewards. Each fruit represents the expected value at a given level of experience, and the ovals represent the agent’s uncertainty about this reward. The numbers above indicate the corresponding frame in panel (a). Together, these figures illustrate how ignorant agents (Ignorant end of Experience axis) are more likely to incorrectly judge which option has the highest expected reward, and they are more likely to revise their choices as their experience grows. The same logic applies to experience with costs, and thus to the overall expected utilities. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1575EXPECTED UTILITIES IN ACTION UNDERSTANDING focus on children’s explicit reasoning about agents’ mental states, here we focus on 4- and 5-year-olds, looking at whether children who understand that costs, rewards, and beliefs vary across agents also understand that beliefs interact with costs and rewards. Figure 1c shows a visualization of the structure of the experi- ments. In Experiments 1–4 we explore children’s understanding of how knowledge of rewards influences agents’ choices and their stability over time. In Experiments 5–7 we explore the same questions in a domain where both costs and rewards are in play. Our sample size (n  16 per experiment) was based on similar tasks with a similar age ranges. Monte Carlo power analyses using effect sizes estimated from past data show that our experiment was appropriately powered as long as each experiment contained an inclusion question that would help remove the noise in the anal- yses. Power analyses with parameters estimated from a meta- analysis on our data confirm that our experiments’ power is over .95, with a .04 chance of producing a false positive (see supple- mental text). Children’s Understanding of how Knowledge of Rewards Influence Action Experiment 1 In Experiment 1 we look at whether children understand that agents who are naive about rewards are more likely to make poor choices compared to knowledgeable agents. We introduce children to two puppets who are given a choice between two types of fruits. One puppet is knowledgeable and has tasted both fruits before; one puppet is naïve and has not. Both puppets choose the same fruit. One puppet tastes it and says “Yum!” and the other tastes it and says “Yuck!” We predict that children will infer that the knowl- edgeable puppet is more likely to say “Yum!” (see Figure 3). Method. Participants. Sixteen participants (mean age (SD): 5.09 years (195 days), range 4.13–5.89 years) were recruited at an urban children’s museum. One additional participant was recruited but not included in the study because he failed to respond to the inclusion questions correctly (see Procedure). Stimuli. The stimuli consisted of two pairs of gender-matched puppets, and picture cutouts of two fruits: rambutans and African cucumbers. Procedure. Participants were tested individually in a quiet room in a children’s museum. The child and the experimenter sat on opposite sides of a small table. The experimenter first intro- duced the cutout pictures of the rambutans and the African cu- cumbers and placed four pictures of each fruit on the table with each kind of fruit in its own pile. Next, the experimenter intro- duced the two puppets by name (“Anne” and “Sally,” or “Arnold” and “Bob,” depending on the participant’s gender). The experi- menter then explained that “Sally has never seen these fruits before and she doesn’t know what they taste like” while “Anne knows all about these fruits. She knows what they taste like.” Next, the experimenter told the participant, “Earlier today, we told our friends they had to pick one fruit each, and both of our friends picked a rambutan” (actual fruit counterbalanced). Next, the ex- perimenter placed a picture of a rambutan in front of each puppet and explained, “Both of our friends took a bite of their fruit and one of them said ‘Yum!’ and one of them said ‘Yuck’!” Partici- pants were then asked inclusion questions to ensure the child remembered the critical information: “Can you tell me, which of our friends has tasted the fruits before? And which one of our friends has not tasted these fruits before?” Finally, participants were asked which puppet said “Yum!” and which puppet said “Yuck!” Puppets were placed equidistant from the child. We independently counterbalanced (i) the fruits that the puppets chose, (ii) which puppet was knowledgeable, (iii) the knowledgeable puppet’s position relative to the child, and (iv) which puppet’s knowledge state was introduced first. Results and discussion. Children who failed to respond cor- rectly to the inclusion questions were excluded from analysis and replaced (n  1). Results were first coded for adherence to the protocol by a coder blind to the child’s final response (no partic- ipants were dropped due to experimenter error). Videotapes were then coded to record the child’s response to the test question. Children were coded as answering correctly if they indicated that the knowledgeable puppet had said “Yum” and that the ignorant puppet said “Yuck,” and they were coded as responding incor- rectly otherwise. Of the 16 children who responded to the inclusion questions correctly, 16 (100%) responded correctly to the test question (see Figure 4).1 Note that if children believe that an agent’s choices always reflect her preferences, then children should have expected both puppets to say “Yum!” Both agents knew they had a choice of the two fruits, and both agents made the same choice: If children recovered agents’ desires only from information about the agents’ actions and beliefs about the state of the world, then children should have responded at chance in this context. Instead children recognized that the knowledgeable agent would be more likely to like the chosen fruit. This suggests that children understand that 1 Because of conceptual limitations with p values (Cohen, 1994; Cum- ming, 2014), here we report bootstrapped 95% confidence intervals in- stead. This approach does not enable us to compute confidence intervals for the first experiment (because the data has no variance). However, the conclusion we draw is consistent with null-hypothesis significance testing. Experiment 1 Who said “yum” and who said “yuck”? Yum!Yuck! Experiment 2 Who hadn’t tasted the fruits before? Figure 3. Experiments 1 and 2. In Experiment 1, after watching a knowledgeable and a naïve puppet choose identical fruits to eat, children were asked to infer who said “yum!” and who said “yuck!” In Experiment 2 children learned which puppet said “yum!” and which puppet said “yuck!” and were asked to infer who had tasted the fruits before. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1576 JARA-ETTINGER, FLOYD, TENENBAUM, AND SCHULZ agents choose the options with the highest expected rewards and that a naive agent’s choices may be governed by an inaccurate estimate of the actual reward. Experiment 2 Experiment 1 shows that children believe ignorant agents are more likely to make choices that lead to low rewards. However, in the real world we are rarely privy to the epistemic status of others. Instead, we often grapple with the opposite task: inferring what others know given how they act. In Experiment 2 we ask if children can infer which of two agents was ignorant based on the rewards they obtain. Children watched two puppets pick the same fruit to eat. After learning that one puppet said “Yum!” and the other puppet said “Yuck!” children were asked to decide which puppet had not tasted the fruits before (see Figure 3). We predict that children will infer that the puppet who said “Yuck!” had not tasted the fruits before. Method. Participants. Thirty-two participants (mean age (SD): 5.12 years (194 days), range 4.12–5.99 years) were recruited at an urban children’s museum. Sixteen participants were recruited for the original experiment, and 16 additional participants were recruited to conduct a replication (see Results). Four additional participants were recruited in the original experiment but excluded from anal- ysis and replaced for failing the inclusion questions (n  1), declining to complete the experiment (n  1), and declining to answer the test question (n  2). Three additional participants were recruited in the replication experiment but excluded from analysis for failing the inclusion questions (n  2), and declining to answer the test question (n  1). See Results. Stimuli. The stimuli were identical to those used in Experi- ment 1. Procedure. Participants were tested individually in a quiet room. As in Experiment 1, the experimenter introduced the two puppets and the fruits and explained that each puppet chose a fruit to eat. One section from Experiment 1 was omitted; here, one puppet was not more knowledgeable than the other. After both puppets chose a fruit, the experimenter said “Anne and Sally (or Arnold and Bob) both took a bite from their rambutans (or African cucumbers). Anne said ‘Yum!’ Sally said ‘Yuck!’” Next, the experimenter said, “But guess what? One of our friends didn’t know what rambutans tasted like until today.” Children were then asked to remember which puppet had said “Yum!” and which puppet had said “Yuck!” as inclusion questions. For the test question, the experimenter asked, “Can you tell me, which one of our friends didn’t know what rambutans tasted like until today?” (Actual fruits counterbalanced throughout.) The replication exper- iment used the same procedure as the original experiment with the exception that the inclusion questions were asked immediately after the puppets tasted the fruit in order to make the last part of the experiment more fluent. We independently counterbalanced (i) the fruits that the puppets chose, (ii) which puppet said yum, (iii) the puppets’ positions relative to the child, and (iv) which puppet’s behavior was introduced first. Results and discussion. Results were coded as in Experiment 1. Participants were coded as passing the inclusion if they could recall correctly which puppet said “Yum” and which puppet said “Yuck” (one participant was excluded on this basis). Participants were coded as responding correctly if they indicated that the puppet who said “Yuck!” was the one who had not tasted the fruits before today. Of the 16 participants who made a choice in the original experiment, 12 responded correctly (75%; 95% CI [56.25%–100%]; see Figure 4). These results suggest that children can use knowledge about the actual subjective rewards that differ- ent agents obtain to infer which agent is more likely to have been naïve in her estimate of the expected rewards. However, four children answered incorrectly and two were excluded from anal- ysis and replaced for failing to provide any answer to the test question. Thus, to ensure the validity of our interpretation we replicated the experiment. The replication yielded identical results. Out of the 16 participants who made a choice in the replication, 12 responded correctly (75%; 95% CI [56.25%–100%]; see Figure 4). 0 25 50 75 100 Exp. 1 Exp. 2 Original Exp. 2 Replication Exp. 3 Exp. 4 Exp. 5 Exp. 5 Control Exp. 6 Control Exp. 6 Exp. 7 Exp. 7 Control Experiment P er ce nt ag e of ch oi ce s Correct Incorrect Ignorant Knowledgeable Figure 4. Results from Experiments 1–7. The x-axis shows each condition and the y-axis shows children’s distribution of responses. Black vertical bars show 95% bootstrapped confidence intervals and the horizontal dotted line shows expected chance performance. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1577EXPECTED UTILITIES IN ACTION UNDERSTANDING Together, these experiments suggest that children can use knowl- edge about subjective rewards to infer knowledge. Experiment 3 In Experiment 3, children were introduced to a set of fruits and to a knowledgeable and an ignorant agent. Next, children saw both puppets pick the same kind of fruit and take a bite. Finally, children learned that one of the puppets changed her choice and they were asked to determine which puppet had changed her mind and which puppet had changed her choice (see Figure 5). If children believe both agents maximized actual rewards, they should perform at chance, but if they understand that agents were maximizing expected rewards, and that these estimates change as a function of experience, they should recognize that the ignorant agent was more likely to revise her choices. Method. Participants. Sixteen participants (mean age (SD): 5.16 years (241 days), range 4.01–5.96 years) were recruited at an urban children’s museum. One additional participant was recruited but excluded from the study and replaced because he declined to complete the task. Stimuli. The stimuli were identical to those used in Experi- ments 1–2. Procedure. The procedure was identical to the procedure in Experiment 1 except as follows: One of the puppets was intro- duced as having tasted the fruits and knowing what they tasted like, and neither puppet said “Yum!” or “Yuck!” Instead, after the puppets had tasted the fruits, the experimenter said, “Both of our friends took a bite from their fruit and one of them changed her mind and decided she wanted to eat a different fruit.” As an inclusion question, participants were asked “Can you remind me, which one of our friends knows all about these fruits? Sally or Anne?” or “Can you remind me, which one of our friends has never tried these fruits? Sally or Anne?” (see supplemental mate- rials for full script). For the test question, participants were asked, “Which one of our friends changed his/her mind?” We indepen- dently counterbalanced (i) the fruits that the puppets chose, (ii) which puppet was knowledgeable, (iii) the knowledgeable pup- pet’s position relative to the child, (iv) which puppet’s knowledge state was introduced first, and (v) the type of inclusion question. Results and discussion. Results were coded in the same way as Experiments 1–2. All participants passed the inclusion question and no participants were dropped due to experimenter error. Chil- dren were coded as responding correctly if they indicated that the naïve agent was the one who had changed her mind. Fifteen of the 16 children responded to the test question correctly (93.75%; 95% CI [87.5%–100%]; see Figure 4). Note that in contrast to Exper- iment 1, participants in Experiment 3 never obtained any informa- tion about the outcome of each puppet’s choice. Thus, it was possible that either or both puppets had liked or disliked their chosen fruit. Nevertheless, children were able to infer that naïve agents are more likely to make unstable choices. Furthermore, in this experiment participants couldn’t succeed by grouping together two features with a positive valence (such as knowledge and “yumminess” in Experiment 1). Together with Experiment 1, the results from this experiment suggest that 4- and 5-year-olds un- derstand that relative to knowledgeable agents, naïve agents are more likely to make choices that lead to low rewards, and thus that their choices are less likely to be stable over time. Experiment 4 Experiment 3 shows that children believe ignorant agents are more likely to revise their choices. In Experiment 4 we ask if children can infer which of two agents is more likely to be naive about their rewards when one shows stable preferences and one does not. Children watched two puppets choosing and tasting identical fruits. Next, one puppet announced that she wanted to eat the other kind of fruit instead while the other puppet wanted to stick to her choice. Children were asked which of the puppets had never tasted the fruits before (see Figure 5). We predict that children will infer that the puppet who changed her choice had not tasted the fruits before. Method. Sixteen participants (mean age (SD): 5.06 years (244 days), range 4.04–5.93 years) were recruited at an urban children’s museum. Three additional children were tested but excluded from the study because they failed to respond to the inclusion questions correctly. See Results. Stimuli. The stimuli were identical to those used in Experi- ments 1–3. Procedure. The procedure was identical to Experiment 2 ex- cept as follows: First, children were never given any information about whether the puppets said “Yum!” or “Yuck!” after tasting the fruits. Instead, after taking a bite from their fruit, the experi- menter said, “Anne kept eating the rambutan. Sally changed her mind and said she wanted an African cucumber instead.” As inclusion questions, participants were asked, “Can you remind me, which one of our friends kept eating the rambutan? Anne or Sally? And which one of our friends changed her mind and wanted an African cucumber instead? Anne, or Sallly?” As in Experiment 2, at test children were asked, “Can you tell me, which one of our friends didn’t know what rambutans tasted like until today?” We independently counterbalanced (i) the fruits that the puppets chose, (ii) which puppet was knowledgeable, (iii) the knowledgeable puppet’s position relative to the child, and (iv) which puppet’s knowledge state was introduced first. Results and discussion. All results were coded in the same way as Experiments 1–3. Participants were coded as passing the inclusion questions correctly if they responded to both questions Experiment 4 Who hadn’t tasted the fruits before? Experiment 3 Who changed her choice? Figure 5. Experiments 3 and 4. In Experiment 3, after watching a knowledgeable and a naïve puppet choose identical fruits to eat, children were asked to infer who changed her mind after tasting her fruit. In Experiment 4 children learned which changed her choice and were asked to infer who had not tasted the fruits before. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1578 JARA-ETTINGER, FLOYD, TENENBAUM, AND SCHULZ correctly, and they were marked as failing inclusion otherwise. Three children failed to respond to the inclusion questions cor- rectly and were therefore excluded from analysis and replaced. Children’s responses were coded as responding correctly if they indicated that the puppet who changed her mind was the one who had never tasted the fruits before. Of the 16 participants who made a choice, 13 responded correctly (81.25%; 95% CI [62.5%–100%]; see Figure 4). Together with Experiment 3, these results suggest children understand that relative to naïve agents, knowledgeable agents are more likely to stick to their choices. Moreover, children can infer which agents are more likely to be knowledgeable based on the stability of these choices. Children’s Understanding of How Knowledge of Utilities Influence Action Experiments 1–4 suggest that children understand that agents do not maximize rewards, but expected rewards. In these experiments, the costs were matched and negligible. In part 2 we test if children assume that agents maximize expected utilities when both costs and rewards are in play. In Experiments 5 and 6 we ask if children believe that agents who are aware of the costs make better choices, and whether they can infer relative knowledge or ignorance based on these choices. In Experiment 7 we look at whether children understand that agents who are ignorant about the costs are more likely to revise their choices in light of new information.2 Experiment 5 Experiment 5 is similar to Experiment 1 but focuses on utilities rather than rewards alone. Here we ask if children understand that agents who know the cost associated with different alternatives are more likely to maximize utilities. In Experiment 5a children watched two puppets choose between climbing a set of stairs to get a tomato (high-cost plan), or getting a piece of corn at no cost (low-cost plan). Critically, however, only one of the puppets knew about the set of stairs. After both puppets chose to get the tomato, children were asked which of the two puppets was more likely to really like tomatoes (see Figure 6). If children believe that the puppets were maximizing actual utilities, then they should con- clude that they both prefer tomatoes to corn (as they both chose the tomato at a high cost over corn at a low cost). However, if children believe that the puppets were maximizing expected utilities, they should only conclude that the puppet who was aware of the costs prefers tomatoes (as the ignorant agent did not know she was pursuing a plan with a higher cost). Experiment 5b is identical to Experiment 5a with the exception that both puppets now choose the low-cost plan (see Figure 6). Method. Participants. Thirty-two participants (mean age (SD): 4.75 years (206 days), range 4.06–5.73 years) were recruited at an urban children’s museum and assigned to the test of the control condition (N  16 per condition). Six additional participants were recruited but not included in the study due to family interference (n  1 participant), experiment error (n  2 participants), and failure to respond the inclusion questions correctly (n  3 partic- ipants; see Procedure). Stimuli. The stimuli consisted of two pairs of gender-matched puppets, a set of puppet-sized walls with doors (1 yellow and 1 red; 20.5” H, 12” W), a puppet-sized set of stairs (20 steps; 21.5” H, 4” W), a plastic tomato, and a plastic ear of corn. Procedure. Participants were tested individually in a quiet room in a children’s museum. The child and the experimenter sat on opposite sides of a small table. The red and yellow doors were placed on opposite sides of the table facing the child. In the test condition (see Figure 6) the experimenter first introduced the red and yellow doors and opened each of them to reveal that there was a set of stairs behind the red door, but not behind the yellow door. Next, the experimenter showed the participant the corn and the tomato and explained that she would place the corn right behind the yellow door, so if someone wanted to get it, they could just pick it right up. But the tomato is going to go all the way at the top of the stairs, so it’s way harder to get. The experimenter then introduced two puppets matched with the participant’s gender. The experimenter informed the puppets, “There’s a tomato behind the red door, and some corn behind the yellow door,” purposefully omitting information about the stairs, and then explained that the puppets were going to choose one of the foods, asking them, “Do you want the tomato or corn?” Next, the experimenter acted out one of the puppets peeking behind both doors, and told the participants, “One of the puppets peeked behind both of the doors and saw that there was a huge set of stairs behind the red door.” (Which puppet was knowledgeable, and her position relative to the child, were counterbalanced separately.) The exper- imenter then said, “It’s time for the puppets to choose one of the foods! Let’s see what they do!” and narrated while the puppets moved toward the red door, “Both of our friends chose the to- mato!” Participants were then asked inclusion questions to ensure the child remembered the critical information: “Can you remind me, who knew about the stairs behind the red door? And who didn’t know?” (question order counterbalanced). Finally, participants were asked, “Both of our friends chose the tomato door, but can you tell me who really likes tomatoes?” We independently counterbalanced (i) which puppet was knowledgeable, (ii) the knowledgeable puppet’s position relative to the child, and (iii) the order of the inclusion questions. The knowledgeable agent had peeked behind the doors before making her choice and was therefore more active during the puppet show, raising the possibility that children could arrive at the correct answer by attending to this superficial difference. To ensure this was not the case we ran a control condition, where everything was identical with the exception that the stairs were 2 The experimental design in our paper manipulates the direction of the inference (mental states to behavior, or behavior to mental states), the type of observed behavior (choice outcome or behavior stability), and type of uncertainty (with respect to rewards or utilities). These features create a 2  2  2 design with 8 conditions. We do not test the eighth condition—if children understand that agents who revise their choices are more likely to be ignorant about the utilities—because it is not possible in our stairs paradigm. In the reward scenarios agents could change their mind without revealing they made a poor choice because the rewards are unobservable. In contrast, in the utility scenario, the costlier choice is always observable. As such, it is not possible for the agent to revise her choice without revealing that her original choice was costlier. Therefore, experiments testing children’s understanding of stability with respect to utilities would necessarily include information about the quality of the choice, which, as Experiment 7 reveals, is sufficient for children to solve the task. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1579EXPECTED UTILITIES IN ACTION UNDERSTANDING placed behind the yellow door. As such, both puppets selected the low-cost plan over the high-cost plan (see Figure 6). As in the test condition, children watched the knowledgeable puppet peek, and both puppets selected the tomato (low-cost plan). Thus, if children were simply selecting the more active puppet, they should continue to judge that the knowledgeable agent is the one who really likes tomatoes. Results and discussion. Children who failed to respond cor- rectly to the inclusion questions were excluded from analysis and replaced (n  3). Results were coded in the same way as in Experiments 1–4 (n  2 participants were excluded due to exper- imenter error; n  1 participant excluded due to family interfer- ence). Fourteen of the 16 children in the test condition said the knowledgeable agent had the strong preference for tomatoes (87.5%; 95% CI [75%–100%]; see Figure 4). In the control con- dition, only 9 of the 16 children said the knowledgeable agent had the strong preference (56.25%; 95% CI [31.25%–81.25%]; see Figure 4). These conditions were not significantly different from each other (odds ratio  5.16; p  .11).3 Our control condition shows that children did not succeed in the test condition by simply selecting the more active puppet. Argu- ably, however, children should have recognized that the naïve puppet was pursuing what she likes best, whereas the knowledge- able agent may have only been avoiding the cost for climbing the stairs. This predicts that children should select the naïve puppet. To ensure this interpretation is plausible, we conducted an online survey with adults via Amazon Mechanical Turk’s platform.4 Like the children our study, adult participants judged that the knowl- edgeable agent had a stronger preference in the test condition (see Experiment 5b in supplemental materials), but, unlike children, they also judged that the ignorant agent in the control condition had a stronger preference (see Experiment 5b control in supple- mental materials). However, this inference is substantially more complicated than the one children had to draw in the test condition. Specifically, in the test condition, the knowledgeable agent could have only chosen the high-cost plan for one reason: She preferred tomatoes. However, in the control condition, the knowledgeable agent could have chosen the high-cost plan for three reasons: (1) She may have preferred tomatoes to corn, (2) she may have liked both foods equally and thus selected the option with the lowest- cost, or (3) she may have preferred corn, but chosen to get the tomato because its cost was lower. The results of our control condition show that children’s inferences in the test condition were not merely due to the differential salience of the two puppets: Children did not simply select the “more active” puppet. At the same time, children’s success in the test condition and failure to choose the knowledgeable agent in the control condition suggests that children are better able to entertain a single, fairly simple hypothesis consistent with a naïve utility calculus than entertain or integrate over many possible, more complex hypotheses consistent with the evidence. 3 The hypothesis that children select the right answer by selecting the more active puppet predicts that children should perform reliably above chance in both the test and the control conditions. As such, finding that children do not succeed in the control condition rules out this account. Note however that the control condition was designed not because the naïve utility calculus specifically predicts a difference between the two condi- tions, but only to rule out the alternative account. Although our account does not predict a difference, we present statistical comparisons across conditions as suggested by an anonymous reviewer. A similar logic applies to Experiments 6 or 7. 4 We thank an anonymous reviewer for this suggestion. Experiment 5 Who really likes tomatoes? Experiment 5 - Control Who really likes tomatoes? Experiment 6 - Test Who didn’t know about the stairs? Experiment 6 - Control Who didn’t know about the stairs? Figure 6. Experiments 5 and 6. Children watched two puppets choose between eating a tomato or corn. In Experiment 5 children learned which of the puppets knew about the set of stairs and were asked to infer who had a strong preference for tomatoes based on their actions. In Experiment 6 children watched the puppets make their choices and were asked to infer which puppet was knowledgeable. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1580 JARA-ETTINGER, FLOYD, TENENBAUM, AND SCHULZ However, it is also important to note that the probability of finding a false negative increases as a function of the number of total experiments in a study. As such it is possible that 4- and 5-year-olds are able to succeed in the control condition of Exper- iment 5, even if it is more complex than the rest of our experi- ments. Indeed, based on our power analyses, there is a 22% chance that at least one of the experiments would fail to reach significance (see supplemental information). Overall, the results from Experi- ment 5 show that children can make the relatively simple inference that agents who knowingly pursue high cost actions expect high rewards. Experiment 6 In Experiment 6 we ask if children can infer which of two puppets is more knowledgeable about the costs of their actions. In Experiment 6, children are introduced to two puppets and two doors with food behind them. One door has a tomato directly accessible (low-cost door), whereas the other door has a tomato at the top of a set of stairs (high-cost door). That is, the low-cost door is a better choice: It leads to the same reward as the high-cost door but without the need to incur the costs. Children saw one puppet choose the tomato behind the low-cost door and the other choose the tomato behind the high-cost door. Finally, children learned that one of the puppets knew beforehand about the set of stairs and were asked to determine which puppet already knew about the stairs (see Figure 6). The control condition was identical except that the tomato behind the high-cost door was placed directly next to the stairs, rather than at the top of the stairs (see Figure 6). If children understand that agents maximize expected utilities they should infer the puppet who choose the door with stairs was ignorant in the test condition, and this effect should go away in the control condition. Method. Participants. Thirty-two participants (mean age (SD): 5.04 years (181 days), range 4.07–5.94 years) were recruited at an urban children’s museum, and assigned to the test or the control condi- tions (N  16 per condition). Five additional participants were recruited for the experiment but excluded from analysis and re- placed for failing the inclusion questions (n  1), for family interference (n  2), because they did not speak English (n  1), and due to experimenter error (n  1). Stimuli. The stimuli were identical to those used in Experi- ment 5, except that two tomatoes were used instead of one corn and one tomato. Procedure. The procedure in the test condition was the same as Experiment 5, except that children were introduced to two identical tomatoes. One was placed at the top of the stairs behind the red door, and the other was placed directly behind the yellow door. Children were then introduced to two puppets (which were counterbalanced for side with respect to the child) and the exper- imenter announced to the puppets that there was a tomato behind each door, and that the puppets could choose one of the doors. Each of the puppets chose one of the doors (puppet choosing each door counterbalanced). That is, one puppet chose the high-cost tomato whereas the other puppet chose the low-cost tomato. Chil- dren were then asked two inclusion questions to ensure that they had paid attention to the story: “Can you remind me who chose the red door? And who chose the yellow door?” (order counterbal- anced). Finally, children were asked the test question: “It turns out that one of our friends didn’t know about the stairs behind the red door. Who didn’t know about the stairs behind the red door?” We independently counterbalanced (i) which puppet chose the red door, (ii) the order in which the puppets’ choices were introduced, (iii) the knowledgeable puppet’s position relative to the child, and (iv) the order of the inclusion questions. To ensure children didn’t choose the puppet who chose the red door because the test question mentioned “the red door,” we ran a control condition.5 This condition was similar to the test condition with the exception that the tomato behind the red door was placed behind the red door next to the beginning of the stairs. The procedure was identical to the test condition except that when the experimenter introduced the stairs she said, “. . .behind the red door, there’s a huge set of stairs, but they don’t matter” (see supplemental materials). Similarly, after the tomato was placed at the bottom of the stairs, the script was adjusted and the experi- menter said, “. . . I’m going to put the other tomato behind the red door, so if someone wanted to get it they could also just pick it up. So the stairs don’t matter.” As in the test condition, children were asked two inclusion questions: “Can you remind me who chose the red door? And who chose the yellow door?” (order counterbal- anced). The test question was identical to the one in the test condition: “It turns out that one of our friends didn’t know about the stairs behind the red door. Who didn’t know about the stairs behind the red door?” Results and discussion. Results were coded in the same way as Experiments 1–5. Participants were coded as passing the inclu- sion questions if they responded to both inclusion questions cor- rectly and were coded as failing inclusion otherwise. Five partic- ipants were excluded by decision of the coder because they failed to pass the inclusion questions (n  1), because of family inter- ference (n  2), because they did not speak English (n  1), and due to an experimenter error (n  1). Participants in the test condition were coded as responding correctly if they indicated that the puppet who chose the red door was the one who didn’t know about the stairs. Of the 16 participants who made a choice, 14 responded correctly (87.5%; 95% CI [75%–100%]; see Figure 4). Although, according to the Naïve Utility Calculus, there is no correct question in the control condition, for clarity, we coded children as responding correctly (as determined by the confound) if they indicated that that the puppet who chose the red door was the one who knew the location of the tomato. Of the 16 participants who made a choice, 10 responded correctly according to the confound (62.50%; 95% CI [37.50%–87.50%]; see Figure 4). The two conditions were not significantly different from each other (odds ratio  0.25; p  .22). Together, these results suggest that children believe that agents who fail to maximize utilities are more likely to have been ignorant about the costs. Experiment 7 In Experiment 7 we test if children believe that agents who are naive about the costs of different plans have less stable choices compared to knowledgeable agents. Children saw two agents 5 We thank an anonymous reviewer for the suggestion of this control condition. In our original manuscript we presented an alternative control condition that is now reported in the supplemental materials. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1581EXPECTED UTILITIES IN ACTION UNDERSTANDING choose between a low-cost and a high-cost plan. Both puppets chose the high-cost plan, but only one of them was aware of the cost. After the cost was revealed, children learned that one of the puppets changed her choice, and were asked to determine which puppet that was (see Figure 7). If children believe that agents choose what they like best, they should perform at chance. If instead children understand that learning about the costs is more likely to lead to a revision of their choice, then children should judge that the originally naive agent was more likely to have changed her mind. Method. Participants. Thirty-two participants (mean age: 4.84, SD: 0.49 years (178 days), range: 4.02–5.88 years) were recruited at an urban children’s museum and assigned to the test or the control condition (N  16 per condition). Six additional participants were recruited but not included in the study because they failed to respond to the inclusion questions correctly (n  2 in the test condition and n  4 in the control condition). Stimuli. The stimuli in Experiment 7 were identical to the ones used in Experiment 3. Procedure. The setup was identical to Experiment 3 (see Figure 8). As in Experiment 3, children in the test condition were introduced to the two foods and doors, as well as the differing costs behind the doors (big stairs behind red door, no stairs behind yellow door). The same two puppets were introduced. Both pup- pets were given a choice between the corn and tomato doors, and both puppets chose the tomato door. Crucially, neither of the puppets looked behind the doors prior to this, so they were un- aware of the differing costs when they made this choice. Partici- pants were then shown that one of the puppets peeked behind the red door “and saw that there was actually a huge set of stairs to climb to get to the tomato” (location of the puppet relative to each door was counterbalanced). Participants were then asked two in- clusion memory questions in a randomized order: “Can you re- mind me who doesn’t know about the stairs behind the red door? And who knows about the stairs behind the red door?” (order counterbalanced). Then, participants were told, “One of our friends changed his/her mind and said s/he wanted to go to the other door to get corn instead,” and were then asked the test question: “Which one of our friends changed his/her mind.” We independently counterbalanced (i) which puppet was knowledgeable, (ii) the knowledgeable puppet’s position relative to the child, and (iii) the order of the inclusion questions. Similar to Experiment 3, children’s answers may be driven by a preference for the more active puppet, so in the control condition, the procedure was identical, except that the stairs were placed behind the yellow door instead. Thus, in contrast to the test condition, where the active puppet saw that she had made a high-cost choice, in the control condition the active puppet saw that she had made a low-cost choice. Results and discussion. Results were videotaped and coded in the same way as Experiments 1–6. Participants were coded as passing the inclusion questions if they responded to both inclusion questions correctly and coded as failing inclusion otherwise. Six participants were excluded for failing the inclusion questions (n  2 in the test condition and n  4 in the control condition). Thirteen out of the 16 children in the test condition determined that the agent who peeked after making her choice was the one who changed her mind (81.25%; 95% CI [62.5%–100%]; see Figure 4). Experiment 7 Who changed her choice? Experiment 7 - Control Who changed her choice? Figure 7. Design of Experiment 7. Children watched two puppets—one who knew about the unobservable set of stairs and one who did not— choose the tomato over the corn (high-cost choice in Experiment 7a and low-cost choice in Experiment 7b). Children then learned that one puppet changed her choice after opening the door and were asked to infer who that was. See the online article for the color version of this figure. Experiment 5b according to “ignorance = error” account Who really likes tomatoes? Figure 8. Visual representation of the ignorant agent’s beliefs according to the “ignorance  error” account in Experiment 5b. According to this account the ignorant agent chose what she believes to be a high-cost plan, and children should therefore infer that she prefers tomatoes to corn. See the online article for the color version of this figure. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1582 JARA-ETTINGER, FLOYD, TENENBAUM, AND SCHULZ In the control condition, only 8 of the 16 children determined that the active agent had changed her mind (50%; 95% CI [25%–75%]; see Figure 4), showing that children did not arrive at the correct answer in the test condition by selecting the more active puppet. These conditions were not significantly different from each other (odds ratio  4.13; p  .14). Together with Experiment 3, the results from this experiment suggest that 4- and 5-year-olds understand that relative to knowl- edgeable agents, naïve agents are more likely to make choices that do not maximize actual utilities, and that, as such, their choices are more likely to change as they obtain more information about the world. Together with Experiment 5, the results from this experi- ment suggest that these expectations appear both with respect to uncertainty about the rewards, and the costs. General Discussion Across seven experiments we studied children’s understanding of how agents act when they do not know their own costs or rewards, and how these beliefs are updated over time. Our results suggest that 4- and 5-year-olds understand that, relative to naïve agents, knowledgeable agents are more likely to obtain high util- ities and are more likely to make stable choices. Collectively, these results build upon evidence that, from early childhood, we expect agents to maximize utilities (Jara-Ettinger et al., 2016; Jara -Ettinger, Gweon et al., 2015; Jara-Ettinger, Tenenbaum, &amp; Schulz, 2015), and suggest that, also from an early age, we understand that agents try to maximize the utilities they expect to obtain. This growing body of results shows how the naïve utility calculus supports reasoning about how other people act and learn through rational action and rational belief updating. Although our results were consistent with the idea that children were reasoning about expected utility maximization, an alternative account is that children solved these task by relying on simple heuristics. Specifically, a classic study suggests that children equate being ignorant with having a false belief (Ruffman, 1996). In these experiments children believed that an ignorant agent’s belief about the color of a hidden candy would be necessarily wrong. Similarly, children in our study may have simply assumed that whoever was ignorant necessarily made a poor choice (and vice versa). We believe this explanation is unlikely to account for the current results. Recent work casts doubt on whether children do indeed assume ignorance indicates wrongness, suggesting that minimally, this heuristic is extremely limited in its scope (Friedman &amp; Leslie, 2004a, 2004b; Friedman &amp; Petrashek, 2009; German &amp; Leslie, 2001). More importantly, the ignorant  wrong heuristic is qual- itatively inconsistent with some of our data: if ignorant agents always have false-beliefs, then the ignorant agent in Experiment 5b must have chosen a plan she believed was costly (see Figure 8). Thus, children should have judged that the ignorant agent had a strong preference. However, children responded at chance. To compare the accounts directly, we use modeling to compare the quantitative fit of the heuristic account with our expected utility account: The model of the expected utility maximization account provides a stronger fit to our empirical data. When the noise parameter is estimated from the percentage of children failing inclusion questions, our account is over one thousand times more likely than the heuristic account; when the noise is individually fit to each model, our account is 12 times more likely than the heuristic account and requires positing half the amount of noise that the heuristic model requires to explain the data (see Appendix in supplemental materials). Our results raise questions about the role of the Naïve Utility Calculus in the development of theory of mind. Research with infants has long suggested that infants understand that others minimize costs (Gergely, Bekkering, &amp; Király, 2002; Gergely &amp; Csibra, 2003; Gergely, Nádasdy, Csibra, &amp; Bíró, 1995; Jara- Ettinger et al., 2016; Liu &amp; Spelke, 2017). Research also suggests that infants understand that agents can have false beliefs about the world (Baillargeon, Scott, &amp; He, 2010; Kovács, Téglás, &amp; En- dress, 2010; Luo, 2011; Onishi &amp; Baillargeon, 2005). As such, it is also possible that infants also understand that agents can have incorrect knowledge or ignorance about their own costs and re- wards. Indeed, toddlers as young as 18 months old understand that different agents can have different preferences, showing evidence for an early understanding of differences in agents’ rewards (Re- pacholi &amp; Gopnik, 1997). In explicit theory of mind, research has revealed that children’s milestones follow a systematic trajectory: They first acquire desire diversity understanding, followed by belief diversity understanding, knowledge-access understanding, false-belief understanding, and, finally, hidden emotion under- standing (Wellman, Fang, and Peterson 2011; Kristen, Thoermer, Hofer, Aschersleben, &amp; Sodian, 2006; Peterson &amp; Wellman, 2009; Peterson, Wellman, &amp; Liu, 2005; Wellman, 2011; Wellman &amp; Liu, 2004; Wellman, Lopez-Duran, LaBounty, &amp; Hamilton, 2008).6 Our results show that 4- and 5-year-olds can understand uncer- tainty about preferences, but we do not know the earliest ages at which children can do so. Our findings also have implications for the broader literature. In primate theory of mind research, our work opens the question of whether nonhuman primates understand that agents can be uncer- tain about their own desires or overall utilities. Studies probing this may help shed light on the capacity and limits of nonhuman primates’ understanding of beliefs (Martin &amp; Santos, 2016). Our study also highlights a critical component that computational mod- els of theory of mind currently lack (Baker, Jara-Ettinger, Saxe, &amp; Tenenbaum, 2017), revealing how to build more powerful models of action interpretation. And in social cognition more broadly, our work can help solve the challenge of how our theory of mind can give rise to the complex explanations of the social interactions we witness in our everyday lives (Malle, 2004). Past research has focused on people’s ability to draw inferences connecting agents’ beliefs, desires, and actions (e.g., Baker et al., 2017; Wimmer &amp; Perner, 1983). Research into beliefs, however, has largely focused on beliefs about the world. The current study suggests that children understand that agents have beliefs not only about the world, but also about their own preferences: What they like (high rewards) and what they want (high utilities). Children understand that as agents gain knowledge about the world, their preferences can change as well. As scientists, we can use these findings to continue the development of more nuanced models of 6 A notable exception to this pattern comes from Chinese children, who master false-belief understanding before knowledge-access understanding (Wellman, Fang, Liu, Zhu, &amp; Liu, 2006). This difference may be caused by differences in mental state word availability and acquisition (Tardif &amp; Wellman, 2000). T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1583EXPECTED UTILITIES IN ACTION UNDERSTANDING theory of mind. Our intuitive psychology supports representations in which agents can reason about the contents of their own minds. References Baillargeon, R., Scott, R. M., &amp; He, Z. (2010). False-belief understanding in infants. Trends in Cognitive Sciences, 14, 110–118. http://dx.doi.org/ 10.1016/j.tics.2009.12.006 Baker, C. L., Jara-Ettinger, J., Saxe, R. R., &amp; Tenenbaum, J. B. (2017). Rational quantitative attribution of beliefs, desires and percepts in hu- man mentalizing. Nature Human Behaviour, 0064. Bartsch, K., &amp; Wellman, H. M. (1995). Children talk about the mind. New York, NY: Oxford University Press. Cantlon, J. F., Piantadosi, S. T., Ferrigno, S., Hughes, K. D., &amp; Barnard, A. M. (2015). The origins of counting algorithms. Psychological Sci- ence, 26, 853–865. http://dx.doi.org/10.1177/0956797615572907 Cohen, J. (1994). The earth is round (p . 05). American Psychologist, 49, 997–1003. http://dx.doi.org/10.1037/0003-066X.49.12.997 Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25, 7–29. Dennett, D. C. (1989). The intentional stance. Cambridge, MA: MIT Press. Flavell, J. H., Flavell, E. R., Green, F. L., &amp; Moses, L. J. (1990). Young children’s understanding of fact beliefs versus value beliefs. Child Development, 61, 915–928. http://dx.doi.org/10.2307/1130865 Friedman, O., &amp; Leslie, A. M. (2004a). A developmental shift in processes underlying successful belief-desire reasoning. Cognitive Science, 28, 963–977. http://dx.doi.org/10.1207/s15516709cog2806_4 Friedman, O., &amp; Leslie, A. M. (2004b). Mechanisms of belief-desire reasoning: Inhibition and bias. Psychological Science, 15, 547–552. http://dx.doi.org/10.1111/j.0956-7976.2004.00717.x Friedman, O., &amp; Petrashek, A. R. (2009). Children do not follow the rule “ignorance means getting it wrong.” Journal of Experimental Child Psychology, 102, 114–121. http://dx.doi.org/10.1016/j.jecp.2008.07.009 Gergely, G., Bekkering, H., &amp; Király, I. (2002). Developmental psychol- ogy: Rational imitation in preverbal infants. Nature, 415, 755. http://dx .doi.org/10.1038/415755a Gergely, G., &amp; Csibra, G. (2003). Teleological reasoning in infancy: The naıve theory of rational action. Trends in cognitive sciences, 7, 287–292. Gergely, G., Nádasdy, Z., Csibra, G., &amp; Bíró, S. (1995). Taking the intentional stance at 12 months of age. Cognition, 56, 165–193. http:// dx.doi.org/10.1016/0010-0277(95)00661-H German, T. P., &amp; Leslie, A. M. (2001). Children’s inferences from “know- ing” to “pretending” and “believing.” British Journal of Developmental Psychology, 19, 59–83. http://dx.doi.org/10.1348/026151001165967 Goodman, N. D., Baker, C. L., Bonawitz, E. B., Mansinghka, V. K., Gopnik, A., Wellman, H., . . . Tenenbaum, J. B. (2006). Intuitive theories of mind: A rational approach to false belief. In Proceedings of the twenty-eighth annual conference of the Cognitive Science Society (pp. 1382–1387). Gopnik, A., &amp; Meltzoff, A. N. (1997). Words, thoughts, and theories. Cambridge, MA: MIT Press. Heider, F., &amp; Simmel, M. (1944). An experimental study of apparent behavior. The American Journal of Psychology, 57, 243–259. Jara-Ettinger, J., Gweon, H., Schulz, L. E., &amp; Tenenbaum, J. B. (2016). The Naïve Utility Calculus: Computational principles underlying com- monsense psychology. Trends in Cognitive Sciences, 20, 589–604. http://dx.doi.org/10.1016/j.tics.2016.05.011 Jara-Ettinger, J., Gweon, H., Tenenbaum, J. B., &amp; Schulz, L. E. (2015). Children’s understanding of the costs and rewards underlying rational action. Cognition, 140, 14–23. http://dx.doi.org/10.1016/j.cognition.2015 .03.006 Jara-Ettinger, J., Tenenbaum, J. B., &amp; Schulz, L. E. (2015). Not so innocent: Toddlers’ inferences about costs and culpability. Psychologi- cal Science, 26, 633–640. http://dx.doi.org/10.1177/0956797615572806 Jara-Ettinger, J., Schulz, L. E., &amp; Tenenbaum, J. B., (2017). The naïve utility calculus as a foundation for action understanding. Manuscript submitted for publication. Johnson, S. G., &amp; Rips, L. J. (2015). Do the right thing: The assumption of optimality in lay decision theory and causal judgment. Cognitive Psy- chology, 77, 42–76. http://dx.doi.org/10.1016/j.cogpsych.2015.01.003 Kovács, Á. M., Téglás, E., &amp; Endress, A. D. (2010). The social sense: Susceptibility to others’ beliefs in human infants and adults. Science, 330, 1830–1834. http://dx.doi.org/10.1126/science.1190792 Kristen, S., Thoermer, C., Hofer, T., Aschersleben, G., &amp; Sodian, B. (2006). Skalierung von “theory of mind” aufgaben [Scaling of theory of mind tasks]. Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie, 38, 186 –195. http://dx.doi.org/10.1026/0049-8637.38.4 .186 Kruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Waltham, MA: Academic Press. Liu, S., &amp; Spelke, E. S. (2017). Six-month-old infants expect agents to minimize the cost of their actions. Cognition, 160, 35–42. http://dx.doi .org/10.1016/j.cognition.2016.12.007 Lucas, C. G., Griffiths, T. L., Xu, F., Fawcett, C., Gopnik, A., Kushnir, T., . . . Hu, J. (2014). The child as econometrician: A rational model of preference understanding in children. PloS ONE, 9(3), e92160. Luo, Y. (2011). Do 10-month-old infants understand others’ false beliefs? Cognition, 121, 289–298. http://dx.doi.org/10.1016/j.cognition.2011.07 .011 Malle, B. F. (2004). How the mind explains behavior: Folk explanations, meaning, and social interaction. Cambridge, MA: MIT Press. Martin, A., &amp; Santos, L. R. (2016). What cognitive representations support primate theory of mind? Trends in Cognitive Sciences, 20, 375–382. http://dx.doi.org/10.1016/j.tics.2016.03.005 Miller, S. A. (2009). Children’s understanding of second-order mental states. Psychological Bulletin, 135, 749–773. http://dx.doi.org/10.1037/ a0016854 Onishi, K. H., &amp; Baillargeon, R. (2005). Do 15-month-old infants under- stand false beliefs? Science, 308, 255–258. http://dx.doi.org/10.1126/ science.1107621 Peterson, C. C., &amp; Wellman, H. M. (2009). From fancy to reason: Scaling deaf and hearing children’s understanding of theory of mind and pre- tence. British Journal of Developmental Psychology, 27, 297–310. http://dx.doi.org/10.1348/026151008X299728 Peterson, C. C., Wellman, H. M., &amp; Liu, D. (2005). Steps in theory-of- mind development for children with deafness or autism. Child Devel- opment, 76, 502–517. http://dx.doi.org/10.1111/j.1467-8624.2005 .00859.x Repacholi, B. M., &amp; Gopnik, A. (1997). Early reasoning about desires: Evidence from 14- and 18-month-olds. Developmental Psychology, 33, 12–21. http://dx.doi.org/10.1037/0012-1649.33.1.12 Robert, C., &amp; Casella, G. (2013). Monte Carlo statistical methods. Berlin, Germany: Springer Science &amp; Business Media. Ruffman, T. (1996). Do children understand the mind by means of simu- lation or a theory? Evidence from their understanding of inference. Mind &amp; Language, 11, 388–414. http://dx.doi.org/10.1111/j.1468-0017.1996 .tb00053.x Tardif, T., &amp; Wellman, H. M. (2000). Acquisition of mental state language in Mandarin- and Cantonese-speaking children. Developmental Psychol- ogy, 36, 25–43. http://dx.doi.org/10.1037/0012-1649.36.1.25 Wellman, H. M. (1990). The child’s theory of mind (Vol. 37). Cambridge, MA: MIT press. Wellman, H. M. (2011). Developing a theory of mind. The Wiley-Blackwell Handbook of Childhood Cognitive Development, 2, 258–284. Wellman, H. M. (2014). Making minds: How theory of mind develops. New York, NY: Oxford University Press. http://dx.doi.org/10.1093/acprof: oso/9780199334919.001.0001 T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1584 JARA-ETTINGER, FLOYD, TENENBAUM, AND SCHULZ Wellman, H. M., Cross, D., &amp; Watson, J. (2001). Meta-analysis of theory- of-mind development: The truth about false belief. Child Development, 72, 655–684. http://dx.doi.org/10.1111/1467-8624.00304 Wellman, H. M., Fang, F., Liu, D., Zhu, L., &amp; Liu, G. (2006). Scaling of theory-of-mind understandings in Chinese children. Psychological Science, 17, 1075–1081. http://dx.doi.org/10.1111/j.1467-9280.2006 .01830.x Wellman, H. M., Fang, F., &amp; Peterson, C. C. (2011). Sequential progressions in a theory of mind scale: Longitudinal perspectives. Child Development, 82, 780 –792. http://dx.doi.org/10.1111/j.1467- 8624.2011.01583.x Wellman, H. M., &amp; Liu, D. (2004). Scaling of theory-of-mind tasks. Child Development, 75, 523–541. http://dx.doi.org/10.1111/j.1467-8624.2004 .00691.x Wellman, H. M., Lopez-Duran, S., LaBounty, J., &amp; Hamilton, B. (2008). Infant attention to intentional action predicts preschool theory of mind. Developmental Psychology, 44, 618–623. http://dx.doi.org/10.1037/ 0012-1649.44.2.618 Wimmer, H., &amp; Perner, J. (1983). Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children’s understand- ing of deception. Cognition, 13, 103–128. http://dx.doi.org/10.1016/ 0010-0277(83)90004-5 Woodward, A. L., Sommerville, J. A., &amp; Guajardo, J. J. (2001). How infants make sense of intentional action. In B. Malle, L. Moses, &amp; D. Baldwin (Eds.), Intentions and intentionality: Foundations of social cognition (pp. 149–169). Cambridge, MA: MIT Press. Received July 21, 2016 Revision received April 17, 2017 Accepted May 23, 2017  Call for Nominations The Publications and Communications (P&amp;C) Board of the American Psychological Association has opened nominations for the editorships of the Journal of Experimental Psychology: Animal Learning and Cognition, Neuropsychology, and Psychological Methods for the years 2020 to 2025. Ralph R. Miller, PhD, Gregory G. Brown, PhD, and Lisa L. Harlow, PhD, respectively, are the incumbent editors. Candidates should be members of APA and should be available to start receiving manuscripts in early 2019 to prepare for issues published in 2020. Please note that the P&amp;C Board encourages participation by members of underrepresented groups in the publication process and would partic- ularly welcome such nominees. Self-nominations are also encouraged. Search chairs have been appointed as follows: ● Journal of Experimental Psychology: Animal Learning and Cognition, Chair: Stevan E. Hobfoll, PhD ● Neuropsychology, Chair: Stephen M. Rao, PhD ● Psychological Methods, Chair: Mark B. Sobell, PhD Candidates should be nominated by accessing APA’s EditorQuest site on the Web. Using your browser, go to https://editorquest.apa.org. On the Home menu on the left, find “Guests/Supporters.” Next, click on the link “Submit a Nomination,” enter your nominee’s information, and click “Submit.” Prepared statements of one page or less in support of a nominee can also be submitted by e-mail to Sarah Wiederkehr, P&amp;C Board Editor Search Liaison, at swiederkehr@apa.org. Deadline for accepting nominations is Monday, January 8, 2018, after which phase one vetting will begin. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 1585EXPECTED UTILITIES IN ACTION UNDERSTANDING</p>
        </div>
      </section>
    </article>
  </body>
</html>
