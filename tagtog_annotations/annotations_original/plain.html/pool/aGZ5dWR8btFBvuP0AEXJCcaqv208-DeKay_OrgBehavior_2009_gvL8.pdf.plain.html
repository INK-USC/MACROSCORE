<!DOCTYPE html >
<html id="aGZ5dWR8btFBvuP0AEXJCcaqv208-DeKay_OrgBehavior_2009_gvL8.pdf" data-origid="DeKay_OrgBehavior_2009_gvL8.pdf" class="anndoc" data-anndoc-version="3.6" lang="" xml:lang="" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="UTF-8"/>
    <meta name="generator" content="net.tagtog.anndoc.v3.parsers.general.StubPdfParser_v1_0_0"/>
    <title>aGZ5dWR8btFBvuP0AEXJCcaqv208-DeKay_OrgBehavior_2009_gvL8.pdf</title>
  </head>
  <body>
    <article>
      <section data-type="">
        <div class="content">
          <p id="s1p1">Organizational Behavior and Human Decision Processes 109 (2009) 79–92Contents lists available at ScienceDirect Organizational Behavior and Human Decision Processes journal homepage: www.elsevier .com/ locate/obhdpDistortion of probability and outcome information in risky decisions Michael L. DeKay a,*, Dalia Patiño-Echeverri b, Paul S. Fischbeck c,d a Department of Psychology, The Ohio State University, 224 Lazenby Hall, 1827 Neil Avenue, Columbus, OH 43210, USA b Nicholas School of the Environment and Earth Sciences, Duke University, USA c Department of Social and Decision Sciences, Carnegie Mellon University, USA d Department of Engineering and Public Policy, Carnegie Mellon University, USA a r t i c l e i n f oArticle history: Received 23 December 2005 Accepted 2 December 2008 Available online 24 January 2009 Accepted by Scott Highhouse Keywords: Information distortion Bidirectional reasoning Implied dominance Decision analysis Expected utility theory Consequentialism Ambiguity Multilevel modeling0749-5978/$ - see front matter  2008 Elsevier Inc. A doi:10.1016/j.obhdp.2008.12.001 * Corresponding author. Fax: +1 614 688 3984. E-mail address: dekay.3@osu.edu (M.L. DeKay).a b s t r a c t Substantial evidence indicates that information is distorted during decision making, but very few studies have assessed the distortion of probability and outcome information in risky decisions. In two studies involving six binary decisions (e.g., banning blood donations from people who have visited England, because of ‘‘mad cow disease”), student and nonstudent participants distorted their evaluations of prob- ability and outcome information in the direction of their preferred decision alternative and used these biased evaluations to update their preferences. Participants also evaluated the utilities of possible out- comes more positively when the outcomes could follow only from the preferred alternative and more negatively when they could follow only from the competing alternative. Such circular reasoning is anti- thetical to the normative consequentialist principles underlying decision analysis. Presenting numerical information as precise values or as ranges of values did not significantly affect information distortion, apparently because the manipulation did not affect perceived ambiguity as intended.  2008 Elsevier Inc. All rights reserved.Introduction &amp; Read, 2004), medical decisions (Levy &amp; Hershey, 2006, 2008;A central premise of normative decision making is that choices should be made on the basis of unbiased assessments of relevant information. Depending on the context, such information may con- sist of product attributes, legal evidence, medical symptoms, or the behavior of others. In risky decisions, relevant information includes descriptions of possible outcomes and the probabilities of those outcomes. Although these considerations do inform many decisions, infer- ences also operate in the opposite direction. Specifically, when one decision alternative is favored over another, information is often evaluated as being more consistent with the preferred alternative than is warranted. Such information distortion or bidirectional rea- soning has been observed in consumer decisions (Bond, Carlson, Meloy, Russo, &amp; Tanner, 2007; Carlson, Meloy, &amp; Russo, 2006; Russo, Carlson, &amp; Meloy, 2006; Russo, Carlson, Meloy, &amp; Yong, 2008; Russo, Medvec, &amp; Meloy, 1996; Russo, Meloy, &amp; Medvec, 1998; Russo, Meloy, &amp; Wilks, 2000), professional decisions (Russo et al., 2000), personnel and scholarship decisions (Bond et al., 2007; Simon, Krawczyk, &amp; Holyoak, 2004), legal decisions (Carlson &amp; Russo, 2001; Holyoak &amp; Simon, 1999; Hope, Memon, &amp; McGeorge, 2004; Simon, Pham, Le, &amp; Holyoak, 2001; Simon, Snow,ll rights reserved.Wallsten, 1981), and military decisions (Adelman, Bresnick, Christian, Gualtieri, &amp; Minionis, 1997). Brownstein (2003) provided a thorough review. Such biases are thought to reflect motivated reasoning (Kunda, 1990), particularly the motivations to separate alternatives (Montgomery, 1983; Svenson, 1992) and to achieve consistency (Holyoak &amp; Simon, 1999; Russo et al., 2008; Simon et al., 2001; Simon, Krawczyk et al., 2004; Simon, Snow, et al., 2004). They are also consistent with research on the affect heuristic (Finucane, Alhakami, Slovic, &amp; Johnson, 2000; Slovic, Finucane, Peters, &amp; MacGregor, 2002) and the risk-as-feelings model (Loewen- stein, Weber, Hsee, &amp; Welch, 2001), which indicate that early affec- tive reactions to hazards and other stimuli influence subsequent judgments and decisions. Distortion of probability and outcome information The above studies provide convincing evidence for the distor- tion of many types of information, but the possible distortion of probability and outcome information in risky decisions has been largely overlooked until very recently. Levy and Hershey (2006, 2008) observed that participants who were motivated to justify a preference for or against a medical treatment distorted the proba- bility of treatment success in the direction of that preference. Such distortions reflect backward reasoning, as the authors noted: ‘‘From a normative point of view, probability should inform desire, 1 Camerer and Weber (1992) noted that uncertainty about outcomes corresponds either to risk (if outcome probabilities are known) or to ambiguity about probabilities (if the probabilities are not known). Although this distinction is critical in expected- utility models, it is not particularly important for the research reported here. 80 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92but desire should not inform probability” (Levy &amp; Hershey, 2006, p. 57). Bond et al. (2007) reported one study involving a hypothetical gamble, in which participants’ evaluations of the low probability of winning (.025) and the large prize ($200) depended on the order of evaluation. For example, participants’ responses to the question, ‘‘How valuable would the $200 be to you?” indicated that knowl- edge of the low probability reduced estimates of the utility of the outcome. DeKay, Patiño-Echeverri, and Fischbeck (in press) reported four studies in which participants distorted the utilities of possible out- comes in risky nonmonetary decisions. In several scenarios (e.g., responding to a dam-failure warning), participants often evaluated costly false positives (e.g., evacuating when the dam did not fail) as better than true negatives (e.g., not evacuating when the dam did not fail). This utility ordering (UFP &gt; UTN) implies that the more pro- tective option dominates the less protective option (e.g., that one should evacuate no matter how low the probability of dam failure). Written explanations and patterns of outcome ratings indicated that participants often based their evaluations of possible out- comes on the decisions that might lead to them. For example, false positives were viewed as better than true negatives because only the former outcome could follow from the preferred course of ac- tion (e.g., evacuation). Accordingly, the prevalence of implied dom- inance decreased substantially when the emphasis on decisions was reduced. DeKay et al. noted that their results were more con- sistent with an information-distortion account than with regret theory (Bell, 1982; Loomes &amp; Sugden, 1982), disappointment the- ory (Bell, 1985; Loomes &amp; Sugden, 1986), or decision affect theory (Mellers, 2000; Mellers, Schwartz, &amp; Ritov, 1999). In regret theory, for example, a person who did not evacuate might feel rejoicing if the dam did not fail (thereby raising UTN), whereas a person who evacuated might feel regret (thereby lowering UFP). These changes would increase (rather than decrease or reverse) the difference be- tween a true negative and a false positive, UTN  UFP. Because these theories of anticipated emotion do not include links from initial decision preferences to evaluations of possible outcomes, they do not predict utility orderings that imply dominance. Such links are a central feature of the information-distortion account, however. In other studies of information distortion, biases are typically as- sessed by asking participants to indicate the extent to which a par- ticular information item favors one decision alternative or the other. Although distortions of such favorability judgments may sometimes be harmless, Russo et al. (2006) showed that they can also lead participants to choose options that they themselves judge to be inferior, a result that the authors described as ‘‘a strong viola- tion of rational decision making” (p. 899). Evidence that probabili- ties and outcomes are also distorted can strengthen the argument that information distortion is nonnormative. Indeed, because prob- abilities and utilities are considered as inputs in decision analysis (Baron, 2008; Clemen, 1996; von Winterfeldt &amp; Edwards, 1986) and other consequentialist theories of decision making (Frisch &amp; Clemen, 1994; Sinnott-Armstrong, 2007), distorted probability and utility judgments may raise normative issues more forcefully than distorted favorability judgments do. The evidence cited above suggests that similar distortion processes may be at work, but more data are needed. In particular, it would be useful to assess more di- rectly DeKay et al.’s (in press) claim that preference-induced distor- tions can lead to patterns of utilities that imply dominance. Ambiguity and information distortion Information about probabilities and outcomes is often impre- cise or uncertain. Uncertainty about probabilities is usually called ambiguity (Camerer &amp; Weber, 1992; Frisch &amp; Baron, 1988), although that term is also used to describe other information that is inexact, conflicting, or open to interpretation. Some authors (e.g.,Ho, Keller, &amp; Keltyka, 2002; Schweitzer &amp; Hsee, 2002) have referred to the ambiguity of outcomes as well as probabilities, which is con- sistent with Frisch and Baron’s definition of ambiguity as ‘‘the sub- jective experience of missing information relevant to a prediction” (p. 152). We also use the term in this broad manner.1 The role of ambiguity in information distortion has been largely neglected. Indeed, no variables related to ambiguity (e.g., conflict- ing sources of information, numerical versus verbal information, precise versus imprecise numerical information) appeared in Brownstein’s (2003) list of 18 possible moderators of biased prede- cision processing. Most studies of information distortion have in- volved complex qualitative stimuli with wide latitude for interpretation. For example, Holyoak and Simon (1999) described their case materials as ‘‘fraught with ambiguity” (p. 5). Other authors (e.g., Carlson et al., 2006; Russo et al., 2000) have strived to present participants with neutral or equivocal information, in part because Russo et al. (1998) observed greater distortion for less diagnostic product attributes. On the other hand, Bond et al. (2007) reported that distortion can also occur for precise quantitative probability and payoff information. Levy and Hershey (2006) also observed distortion of a precise numerical probability (40% chance), but the amount of distortion was less than that for a vague verbal equivalent in a different study that used the same scenario (‘‘small probability” had a mean estimated value of 41% in Levy &amp; Hershey, 2008). Most recently, Russo and Yong (in press) reported nearly identical levels of distortion for numerical and verbal infor- mation in decisions about hotel investments and vehicle safety. As is often the case, however, the attributes being evaluated were rich paragraphs containing several numerical or verbal subattributes. Although the above findings are inconclusive, Russo et al.’s (1998) and Levy and Hershey’s (2006, 2008) results suggest that less diagnostic or less precise information may exacerbate infor- mation distortion by allowing more ‘‘wiggle room” for biased pro- cessing. Similarly, Hsee (1995, 1996) reported that participants were more likely to base decisions on unjustifiable (irrelevant) but tempting information when relevant information was ambigu- ous. Ambiguity (elasticity in Hsee’s terms) was varied in several ways (e.g., by presenting numerical information as ranges, by pre- senting attribute information as a mix of good and bad features). Hsee (1995, 1996) also noted several other studies that used very different ambiguity manipulations. For example, Dunning, Meyero- witz, and Holzberg (1989) reported that participants gave more favorable self-evaluations when considering traits that could refer to many behaviors or characteristics (e.g., sophisticated) than when considering traits that required more narrow interpretations (e.g., punctual). Despite substantial differences in the operational- ization of ambiguity, the results of such studies are broadly consis- tent with the wiggle-room hypothesis: greater bias is observed when materials are more open to interpretation. Repeated measures and multilevel modeling Participants in information-distortion studies typically judge several information items (e.g., product attributes, legal argu- ments) in sequence over the course of making a decision. However, researchers have not always employed repeated-measures meth- ods in the analyses of such data. In some studies, repeated judg- ments have been treated as separate, independent observations even though doing so inflates sample sizes and affects inferential statistics, and even though the resulting coefficients reflect both between-participant and within-participant variation. More com- M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 81monly, judgments have been averaged within participants. Such averaging ignores potentially interesting within-participant varia- tion, however, and relationships that are evident in between-par- ticipant analyses may not hold for any individual participants. Repeated-measures analysis of variance (ANOVA) provides one legitimate solution to these issues. For example, one could divide participants according to their initial or final preferences, with evaluations of the various information items serving as the (repeated) dependent measure. Simon et al. (2001; Holyoak &amp; Simon, 1999; Simon, Krawczyk, et al., 2004) took this approach, although they still averaged several judgments within each phase of their studies. Alternatively, one might use a participant’s emerg- ing preference to code the evaluation of each information item as distorted in the direction of that preference or in the opposite direction. Russo et al. (e.g., 1998) used such a signed distortion metric, but not in a repeated-measures analysis. One limitation of the ANOVA approach is that it considers only the direction, not the strength, of participants’ preferences when predicting evaluations of information items. Using continuous strength-of- preference measures requires a regression approach. Multilevel regression modeling (Raudenbush &amp; Bryk, 2002; Snijders &amp; Bosker, 1999) is appropriate for hierarchical data in which observations are nested within higher-level groups or con- texts, as when students are nested within classrooms or schools. In studies of information distortion, repeated judgments are often nested within participants. In a relatively simple multilevel mod- el, the relationship between an evaluation of a new information item (the dependent variable) and an existing preference for a decision alternative (the predictor variable) might be expressed as follows: Information Evaluationij ¼ b0j þ b1j Preferenceij þ rij; ð1Þ where i indicates the level-1 unit (judgment), j indicates the level-2 unit (participant), and rij is the error term. Note that there is a sep- arate regression equation for each participant. Participants’ inter- cepts and slopes are often modeled as varying randomly about the average values b0j ¼ c00 þ u0j; ð2aÞ b1j ¼ c10 þ u1j; ð2bÞ where c00 and c10 are the average intercept and slope, respectively, u0j is the error or deviation of participant j’s intercept from the aver- age intercept, and u1j is the error or deviation of participant j’s slope from the average slope. Substituting Eqs. (2a) and (2b) into Eq. (1) yields the following reduced-form model: Information Evaluationij ¼ c00 þ c10Preferenceij þ ðu0j þ u1jPreferenceij þ rijÞ: ð3Þ The cs and us are considered fixed and random effects, respectively, with the extent of random variation in the intercept and slope de- scribed by the variances r2u0 and r 2 u1 . More complex models might include additional within-partici- pant predictors in Eq. (1) (e.g., codes to distinguish different infor- mation items) or between-participant predictors in Eq. (2a) (e.g., demographic variables or codes for experimental conditions). Cross-level interactions between level-1 predictors and level-2 predictors (e.g., between Preference and a demographic variable) can be modeled by including the level-2 predictor in Eq. (2b), for example. With appropriate centering procedures, a level-1 variable like Preference (which is likely to vary both between and within participants) can be split into two parts: a level-2 variable for assessing the between-participant relationship between Preference and Information Evaluation and a level-1 variable for assessing the within-participant relationship.Thus, the multilevel approach has a number of desirable fea- tures for the study of information distortion. In particular, it can incorporate both continuous and binary predictors while still treat- ing repeated observations appropriately. This flexibility allows one to assess (or control for) the effects of different information items, scenarios, or experimental conditions and to assess whether the magnitude of information distortion varies across experimental conditions, participant characteristics, or other variables. In addi- tion, the approach allows for the simultaneous assessment of infor- mation distortion at the between-participant and within- participant levels, without fitting a completely separate regression for each participant, which would be less efficient. Given that most previous analyses of information distortion have averaged judg- ments over information items prior to analysis, the ability to assess information distortion within participants is particularly attractive. Overview of studies The two studies reported here were designed to address the is- sues raised in the three sections above. The primary goal of both studies was to assess the distortion of probability and outcome information in risky decisions. Using a variety of scenarios, we as- sessed participants’ initial and emerging preferences and partici- pants’ evaluations of probability and outcome information using methods similar to those of Russo et al. (e.g., 1996, 1998, 2000). In addition to assessing the distortion of favorability judgments for both probabilities and outcomes, we also assessed the distor- tion of outcome utilities by asking participants to compare the rel- ative desirability of the possible outcomes. Another key goal in both studies was to demonstrate the usefulness of multilevel mod- els and other repeated-measures analyses in the study of informa- tion distortion. Because we investigated information distortion in a relatively unstudied domain (risky decisions) using a relatively novel analyt- ical technique (multilevel modeling), we addressed potential con- cerns about generalizability by using two different groups of participants. Study 1 involved mostly students, whereas Study 2 involved older nonstudents from several community organiza- tions. In Study 2, we also attempted to assess the effect of ambigu- ity on the extent of distortion by presenting probability and outcome information either as precise numerical values or as ranges of values. We expected greater distortion for ranges than for precise values.Study 1 Method Participants One hundred two people (40 undergraduates and 20 graduate students from Carnegie Mellon University and 42 nonstudents from a Pittsburgh community organization) participated for $30 cash or an equivalent donation to their organization. One nonstu- dent was dropped for not completing the study. The remaining participants were 18–61 years old (M = 27.4); 50.5% were female. Materials and procedures After considering a practice scenario about the decision to carry an umbrella, participants in this computer-based study considered six other scenarios involving risky decisions, presented in the fol- lowing order: (A) responding to a dam-failure warning, (B) banning the use of cellular phones by automobile drivers, (C) evacuating an airport because a screening machine had failed a reliability check, (D) avoiding milk from hormone-treated cows, (E) banning blood donations from people who have visited England, because of the 82 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92risk of ‘‘mad cow disease,” and (F) banning genetically modified potatoes. Each scenario consisted of a short vignette that described the situation and five ‘‘new information” items (see Appendix A for complete scenario text). One information item gave the probability of the adverse event (e.g., the likelihood of dam failure in Scenario A). The other four items provided information about the possible outcomes of the binary decision: a true positive (e.g., you evacuate and the dam fails), a false positive (e.g., you evacuate, but the dam does not fail), a true negative (e.g., you do not evacuate and the dam does not fail), and a false negative (e.g., you do not evacuate, but the dam fails). Note that a positive decision is defined as taking the precautionary action (e.g., evacuating in Scenario A). The first computer screen for each scenario presented the short vignette. For example, the situation in Scenario E was described as follows: Mad cow disease is a fatal disease that killed many cows in Eng- land during the 1980’s and 1990’s. The disease may be trans- mitted to people who eat infected beef. The disease is also fatal to humans, but it may take years or decades for symptoms to emerge. Although it is theoretically possible for a person to become infected by receiving a transfusion of contaminated blood from an infected person, there is no evidence that the dis- ease has ever been transmitted from person to person in this way, and the risk of such transmission is not known. Imagine that you are the chief administrator at the U.S. Food and Drug Administration. You must decide whether to ban blood donations from Ameri- cans who have spent 6 months or more in England since 1980, because they might be infected with mad cow disease without knowing it. After reading the vignette, participants indicated the strength of their initial preference for a course of action by dragging a marker on a continuous scale with endpoints labeled I strongly prefer not banning it and I strongly prefer banning it (for Scenario E). The pre- cautionary option appeared on the right, and the variable was scored 50 to 50. The second screen retained the vignette and added a series of five questions corresponding to the five information items. Labels for these items (e.g., probability, false negative) were not shown to participants. For Scenario E, these questions (and answers, which were revealed only later) were as follows: Probability. What is the chance that mad cow disease can be transmitted through blood transfusions? The chance that mad cow disease can be transmitted through blood transfusions is 2%. False negative. What happens if mad cow disease can be trans- mitted through blood transfusions and you have not banned blood donations from people who have visited England? If mad cow disease can be transmitted through blood trans- fusions and you have not banned blood donations from peo- ple who have visited England, then one or two people per year get infected with mad cow disease through blood trans- fusions, and die several years later. True positive. What happens if mad cow disease can be trans- mitted through blood transfusions and you have banned blood donations from people who have visited England? If . . ., then the blood supply is reduced by about 10%, leading to cancellation of some scheduled surgeries and insufficient blood in emergencies. There are no cases of mad cow disease due to blood transfusions. True negative. What happens if mad cow disease cannot be transmitted through blood transfusions and you have not banned blood donations from people that have visited England? If . . ., then nothing unusual happens.False positive. What happens if mad cow disease cannot be transmitted through blood transfusions and you have banned blood donations from people who have visited England? If . . ., then the blood supply is reduced by about 10%, leading to cancellation of some scheduled surgeries and insufficient blood in emergencies. There are no cases of mad cow disease due to blood transfusions. In this particular scenario, the descriptions of a true positive and a false positive were identical because the precautionary ac- tion was assumed to negate the adverse event, but this was not true in all scenarios (e.g., evacuating does not negate dam failure in Scenario A). Some information items (particularly true nega- tives, but occasionally true positives and false positives) con- tained little if any new information. These items were included to stress the four possible outcomes of the decision and to reiter- ate important information that might be overlooked in the vign- ette (e.g., the cost or inconvenience associated with the precautionary action). In Study 2, all information items except true negatives contained information that was not presented in the vignette (see Appendix A). The probability item always re- ferred to the likelihood of the adverse event (e.g., the chance of dam failure in Scenario A), but descriptions of false negatives sometimes included probabilities as well (e.g., the chance of dy- ing in the flood in Scenario A). Participants viewed the information items by clicking on the questions in any order they wished (the text for each question ap- peared in a shaded box that functioned as a button). The answer to the selected question then appeared on the screen under the head- ing, ‘‘Here is the new information that you requested.” Participants evaluated the item by answering the question, ‘‘To what extent does this information favor one alternative (banning or not ban- ning)” on a continuous scale from Strongly favors not banning it to Strongly favors banning it (for Scenario E). The information item was then moved up the screen to join the vignette and any previ- ously viewed information. Participants updated their strength of preference for a course of action and then selected one of the remaining questions to view a new information item. After viewing and evaluating all five information items, partic- ipants evaluated the relative desirability (utility) of the four possi- ble decision outcomes (A = false negative, B = true positive, C = true negative, and D = false positive) by dragging the letters onto a con- tinuous scale from Worst possible outcome to Best possible outcome (coded 0–100). We collected these utility ratings at the end of the scenario rather than immediately after each information item was evaluated because we wanted participants to compare the four outcomes directly. Finally, participants chose their preferred course of action (a binary decision) and indicated whether they would change their mind if the probability of the adverse event were different. For example, we asked: ‘‘When the chance of per- son-to-person transmission of mad cow disease was 2%, you said that you would [not] ban the blood donations of people who have visited England. Would any chance make you change your deci- sion?” We interpreted ‘‘No” responses to mean that participants viewed their preferred course of action as dominant. Results and discussion We analyzed the data from this study in several ways. In our main analyses, we assessed whether evaluations of probability and outcome information were distorted to favor the preferred decision alternative and whether the patterns of such evaluations reflected consistent preferences within each scenario. Because information distortion might be considered inconsequential if it did not affect subsequent judgments, we also examined whether distorted evaluations were carried forward via updated prefer- M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 83ences. Finally, to determine whether information distortion ex- tends beyond favorability judgments, we assessed whether the utilities of the four possible outcomes were also distorted in the direction of the preferred decision alternative and whether such distortions were large enough to imply that one alternative domi- nated the other.Distortion of probability and outcome information Participants each made 30 judgments of the extent to which information favored the precautionary option (5 information items  6 scenarios). We modeled these judgments as a function of participants’ preferences for the precautionary alternative while controlling for viewing order, information item, and scenario. In our primary analysis, we used preference judgments that were made immediately before the information item in question was viewed. For example, when modeling evaluations of the third information item, we used preference judgments collected after the second information item had been evaluated. Because judg- ments of the extent to which information favored the precaution- ary option were not independent within participants (intraclass correlation = .08), we took a multilevel approach. Specifically, we fit the following reduced-form model, which allowed us to assess information distortion between participants and within partici- pants simultaneously: Information Favors Precautionij ¼ c00 þ c01Prefers Precaution Before ðMeanÞj þ c10Prefers Precaution Before ðDeviationÞij þ c20Orderi þ X6 k¼3 ck0Information Itemi þ X11 l¼7 cl0Scenarioi þ X31 m¼12 cm0Information Itemi  Scenarioi þ u0j þ u1jPrefers Precaution Before ðDeviationÞij þ rij; ð4Þ where i and j indicate judgments and participants, as in Eqs. (1), (2a), (2b), and (3), and k, l, and m index sets of comparisonsTable 1 Multilevel model results for predicting judgments that information favors precaution. Study 1 Parameter estimate Fixed effects Intercept 0.81 Prefers Precaution Before (Mean) 0.55 Prefers Precaution Before (Deviation) 0.25 Range Range  Prefers Precaution Before (Mean) Range  Prefers Precaution Before (Deviation) Order 1.90 Information Item Scenario Information Item  Scenario Random effects (variance components) Intercept 26.13 Prefers Precaution Before (Deviation) 0.03 Residual 433.62 R2 Level 1 .46 Level 2 .60 Note. Unstandardized coefficients and statistical tests are from maximum likelihood covariance structures. For Prefers Precaution Before (Mean), participants’ means were cen were centered relative to individual participants’ means. Order (the participant’s viewin used for all categorical variables. Empirical standard errors were used for all t tests. v2 t values are for models without random slopes, as suggested by Snijders and Bosker (199 ** p &lt; .01.involving information items and scenarios. Prefers Precaution Before (Mean) is the average of each participant’s 30 preference judgments, collected immediately prior to the information evaluations (these participant means were also centered relative to the overall mean). Prefers Precaution Before (Deviation) is the deviation of a preference judgment from the participant’s mean. Order is the order in which an information item was viewed (coded 1–5, then centered). Infor- mation Item and Scenario are sets of orthogonal contrast codes, mul- tiplied to create the Information Item  Scenario interaction terms. In multilevel terms, Prefers Precaution Before (Mean) is a level-2 pre- dictor that varied only between participants; Prefers Precaution Be- fore (Deviation), Order, and the codes for Information Item, Scenario, and Information Item  Scenario are level-1 predictors that varied within participants; u0j is the deviation of participant j’s intercept from the average intercept (b0j = c00 + u0j); u1j is the devi- ation of participant j’s slope from the average slope (b1j = c10 + u1j); and rij is the level-1 error term. Results appear in Table 1. The coefficient for Prefers Precaution Before (Mean), ĉ01 ¼ 0:55, indicates that participants who preferred the precautionary option were more likely to report that new information favored that option. Although smaller, the coefficient for Prefers Precaution Before (Deviation), ĉ10 ¼ 0:25, indicates that this relationship also held within participants. Because the vari- ance associated with Prefers Precaution Before (Deviation), r̂2u1 ¼ 0:03, was relatively small compared to ĉ10, almost all partic- ipants had positive slopes. These results, which are also evident in the model predictions depicted in the left panel of Fig. 1, provide clear evidence for information distortion in risky decisions. We expected participants’ information judgments to be more strongly related to the preferences that participants held immedi- ately before viewing the information than to the preferences that they held when they initially read the vignette. When initial pref- erences were used in place of immediately prior preferences in Eq. (4), the coefficients for Prefers Precaution Initial (Mean) and Prefers Precaution Initial (Deviation) were significant, ĉ ¼ 0:39, t(99) = 5.59, p &lt; .01, and ĉ ¼ 0:18, t(2888) = 6.86, p &lt; .01, respectively, but smaller than those in the original model (models with initial pref- erences are not shown in Table 1). When both sets of predictorsStudy 2 Significance test Parameter estimate Significance test t(99) = 1.28 5.98 t(93) = 10.09** t(99) = 7.47** 0.74 t(93) = 13.27** t(2896) = 10.19** 0.33 t(2781) = 12.42** 0.77 t(93) = 0.65 0.16 t(93) = 1.47 0.05 t(2781) = 0.94 t(2896) = 3.16** 0.25 t(2781) = 0.42 v2(4) = 811.3** v2(4) = 546.2** v2(5) = 75.8** v2(5) = 23.0** v2(20) = 642.6** v2(20) = 642.6** v2(1) = 73.9** 16.42 v2(1) = 25.1** v2(1) = 63.8** 0.04 v2(1) = 79.0** 527.79 .42 .84 multilevel models fit using PROC MIXED in SAS, assuming variance-component tered relative to the overall mean. For Prefers Precaution Before (Deviation), values g order) was centered relative to the overall mean. Orthogonal contrast codes were ests for fixed effects were conducted by comparing deviances of nested models. R2 9, p. 105). -50 -25 0 25 50 In fo rm at io n Fa vo rs P re ca ut io n Study 1 -50 -25 0 25 50 -50 -25 0 25 50 Study 2 Prefers Precaution Before Fig. 1. Predicted judgments of the extent to which information favors the precautionary option (Information Favors Precaution) as functions of participants’ immediately prior preferences for the precautionary option (Prefers Precaution Before), based on the results of the multilevel models in Table 1. There is a separate line for each participant, with the endpoints depicting the participant’s minimum and maximum values for Prefers Precaution Before and with the open circle depicting the participant’s mean value for Prefers Precaution Before. As is customary in multilevel modeling, each participant’s predicted line is a weighted average of the line based on only that participant’s data and the line based on the full sample. Predictions for Study 2 reflect the nonsignificant effects of Range and its interactions. Order was centered and the contrast codes for Information Type and Scenario were set to zero for these plots. 84 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92were included in a single model for the last four information items viewed (the Deviation predictors were redundant for the first item), immediately prior preferences were much better predictors than were initial preferences, ĉ01 ¼ 0:64 versus ĉ ¼ 0:12 for the be- tween-participant effect and ĉ10 = 0.23 versus ĉ ¼ 0:06 for the within-participant effect. Additional models included several more interaction terms to assess whether the two effects of prior preferences (c01 and c10 in Eq. (4)) varied as functions of Information Item and Scenario. Omnibus tests indicated significant variation over scenarios, v2(10) = 25.8, p &lt; .01, but not over information items, v2(8) = 10.9, p = .21. The between-participant and within-partici- pant slopes were positive for all scenarios and all information items, including the relatively uninformative true-negative items. These results suggest that the distortion of probability and out- come information is a general phenomenon that is likely to affect such judgments in a wide variety of risky decisions. Several studies have indicated that information distortion re- sults from the motivation to achieve consistency among one’s judgments. For example, Holyoak and Simon (1999) and Simon et al. (2001) reported that the consistency among ratings of agree- ment with legal arguments increased sharply as participants con- sidered materials in a complex case. In Simon et al.’s (2001) three studies, Cronbach’s a increased from near zero at pretest to about .75 after all information had been considered and to .80 after a decision had been made. Although there was no pretest in our study (it is hard to imagine a truly decision-free test involving the Information Favors Precaution variables), a values for consis- tency among ratings of the five information items ranged from .62 to .74, depending on the scenario. In our view, these relatively high values for ratings made during the decision process are in ac- cord with the consistency account. In summary, participants’ evaluations of probability and out- come information were distorted in the direction of the preferred decision alternative. This relationship persisted when initial pref- erences were controlled, it was observed for all five information items and all six scenarios, and it resulted in consistent ratings of information items within scenarios.Effects of information evaluations on subsequent preferences The above analyses provide convincing evidence for the distor- tion of probability and outcome information, but such distortionsmight be unimportant if not carried forward in the decision pro- cess. We assessed whether distorted evaluations affected partici- pants’ subsequent preferences for decision alternatives by fitting the following multilevel model: Prefers Precaution Afterij ¼ c00 þ c01Information Favors Precaution ðMeanÞj þ c10Information Favors Precaution ðDeviationÞij þ c02Prefers Precaution Before ðMeanÞj þ c20Prefers Precaution Before ðDeviationÞij þ c30Orderi þ X7 k¼4 ck0Information Itemi þ X12 l¼8 cl0Scenarioi þ X32 m¼13 cm0Information Itemi  Scenarioi þ u0j þ u1jInformation Favors Precaution ðDeviationÞij þ u2jPrefers Precaution Before ðDeviationÞij þ rij: ð5Þ In words, participants’ preferences immediately after evaluating an information item were predicted based on the extent to which that item was judged to favor the precautionary option, controlling for participants’ prior preferences. The intercept was allowed to vary randomly across participants (b0j = c00 + u0j), as were the coef- ficients for Information Favors Precaution (Deviation) (b1j = c10 + u1j) and Prefers Precaution Before (Deviation) (b2j = c20 + u2j). The coefficients for Information Favors Precaution (Mean) and Information Favors Precaution (Deviation) were both positive, although only the latter (within-participant) effect was significant, ĉ01 ¼ 0:05; t(98) = 1.22, p = .22, and ĉ10 ¼ 0:35, t(2895) = 15.00, p &lt; .01, respectively. These results partially validate our evaluation data, but they do not provide additional evidence of biased pro- cessing because new information generally should be used to up- date preferences. Even so, repeated updating on the basis of biased evaluations could create positive feedback loops that main- tain or strengthen participants’ initial preferences. Effects of initial preferences on outcome utilities In addition to affecting judgments of the extent to which infor- mation favors one decision alternative over the other, initial pref- erences may also distort judgments of the desirability (utility) of the decision outcomes themselves (DeKay et al., in press). Shortly, M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 85we will present a single multilevel model for the utilities of true positives, false positives, true negatives, and false negatives. How- ever, the full model is easier to interpret if we first present separate models for the four outcomes. In each model, we predicted partic- ipants’ utilities for the outcome in question (e.g., a true positive) on the basis of Prefers Precaution Initial (Mean) and Prefers Precaution Initial (Deviation), controlling for scenario. We used initial rather than updated preferences for consistency across the four models and because fair tests of the effect of preferences on outcome util- ities require that preference judgments be collected before out- come information is presented. Partial results appear in Table 2. On average, participants rated false negatives as worst (M = 8.2) and true negatives as best (M = 87.6), which makes sense. The ordering of true positives (M = 60.3) and false positives (M = 43.5) was surprising, however. Given that the precautionary action is taken (e.g., milk from hor- mone-treated cows is avoided in Scenario D), participants pre- ferred the occurrence of the adverse event (e.g., milk from such cows causes cancer) over its nonoccurrence. This apparent prefer- ence for being ‘‘correct” held for five of the six scenarios. Of the eight tests for the effect of initial preferences on outcome utilities (two for each possible outcome), five were significant at the p &lt; .05 level and one was nearly significant (see Table 2). Although the signs of the coefficients were positive in four tests and negative in four others, these results actually tell a very consis- tent story. True positives and false positives could follow only from the more protective option, whereas true negatives and false neg- atives could follow only from the less protective option. If outcome utilities are distorted in the direction of one’s preferred course of action, then evaluations of true positives and false positives are ex- pected to be positively related to initial preferences for precaution, whereas evaluations of true negatives and false negatives are ex- pected to be negatively related to initial preferences for precaution (DeKay et al., in press). This is exactly the pattern of results observed. To assess this interaction between initial preferences and possi- ble outcomes directly, we constructed a single multilevel model (not shown) in which outcome utilities were predicted on the basis of Prefers Precaution Initial (Mean), Prefers Precaution Initial (Devia- tion), the usual codes for Scenario, and nine additional predictors. One new contrast code compared true positives and false positives with true negatives and false negatives (TPFP versus TNFN), whereas two other contrasts made orthogonal comparisons (TPTable 2 Partial multilevel model results for predicting the desirability (utility) of possible outcom Fixed effects Possible outcome True positive Study 1 Intercept 60.31 Prefers Precaution Initial (Mean) 0.25** Prefers Precaution Initial (Deviation) 0.05 Study 2 Intercept 55.82 Prefers Precaution Initial (Mean) 0.13 Prefers Precaution Initial (Deviation) 0.17** Range 0.47 Range  Prefers Precaution Initial (Mean) 0.10 Range  Prefers Precaution Initial (Deviation) 0.09 Note. Multilevel models were fit as described in Table 1, with a separate model for eac centered relative to the overall mean. For Prefers Precaution Before (Deviation), values were used for Range and for Scenario, which was controlled in each model. Intercepts give the m reported because they would not be meaningful. Random effects for the intercepts and f corresponding variances are not reported here.  p &lt; .10. * p &lt; .05. ** p &lt; .01.versus FP, TN versus FN). Each of these contrasts was interacted with the two Prefers Precaution Initial variables. In the comparisons of interest, the two interactions involving TPFP versus TNFN were both positive and significant, ĉ ¼ 0:36, t(2300) = 4.32, p &lt; .01 for TPFP versus TNFN  Prefers Precaution Initial (Mean) and ĉ ¼ 0:24, t(2300) = 5.50, p &lt; .01 for TPFP versus TNFN  Prefers Precaution Ini- tial (Deviation), indicating that the relationship between initial preferences and outcome utilities depended on whether the out- come could follow from the preferred decision. These results dem- onstrate that information-distortion processes affect not only favorability judgments (as illustrated previously), but utility judg- ments as well. Effects of initial preferences on implied dominance DeKay et al. (in press) reported that shifts in utility evaluations can sometimes be large enough to imply that one decision alterna- tive dominates the other. In particular, initial preferences for the precautionary option can lead participants to evaluate false posi- tives as being better than true negatives, thereby implying that the precautionary option should be chosen regardless of the prob- ability of the adverse event. Similarly, initial preferences for the nonprecautionary option might lead participants to evaluate false negatives as being better than true positives, implying that the nonprecautionary option should always be chosen. Of the 606 util- ity patterns in this study (101 participants  6 scenarios), 40 im- plied that the nonprecautionary option was weakly dominant (UTN P UFP and UFN P UTP, with at least one inequality), 489 im- plied that neither option was dominant (UTN &gt; UFP and UTP &gt; UFN), 73 implied that the precautionary option was weakly dominant (UFP P UTN and UTP P UFN, with at least one inequality), and 4 were of some other type. We assessed the effects of initial preferences on implied domi- nance using a separate ordinal logistic regression model for each scenario, with the first three utility patterns above in order of increasing preference for precaution. The coefficient for Prefers Pre- caution Initial was positive in all six scenarios (see Table 3), indicat- ing that stronger initial preferences for precaution were associated with higher probabilities that the precautionary option was domi- nant and lower probabilities that the nonprecautionary option was dominant. For a typical odds ratio of 1.03, a 25-point difference in initial preference for precaution (less than one SD) corresponds to an odds ratio of 1.0325 = 2.09, which reflects a sizable between-par- ticipant effect. Repeated-measures binary logistic regressions (notes. False positive True negative False negative 43.49 87.63 8.23 0.14 0.18* 0.13 0.22** 0.10** 0.07** 47.84 86.27 6.83 0.15 0.21* 0.17** 0.11** 0.12** 0.05* 1.72 5.41 5.85** 0.10 0.29 0.08 0.12 0.08 0.00 h possible outcome. For Prefers Precaution Initial (Mean), participants’ means were centered relative to individual participants’ means. Orthogonal contrast codes were ean utility ratings for the four outcomes. Statistical tests of these intercepts are not or the coefficient of Prefers Precaution Initial (Deviation) were also included, but the Table 3 Parameter estimates and odds ratios from ordinal logistic regression models for predicting implied dominance in each scenario. Scenario Responding to dam-failure warning Banning use of cell phones by drivers Evacuating airport for security reasons Avoiding milk from hormone- treated cows Banning blood donors from England Banning genetically modified potatoes or peaches Study 1 Intercept 1 2.39** 1.94** 2.50** 1.22** 3.36** 2.59** Intercept 2 4.03** 3.78 3.82** 3.35** 1.39** 3.26** Prefers Precaution Initial 0.02 0.04** 0.03* 0.02* 0.02** 0.03* (1.02) (1.04) (1.03) (1.02) (1.02) (1.03) Distribution of implied dominance 2, 87, 9 4, 80, 17 3, 87, 10 4, 72, 24 22, 74, 4 5, 87, 9 Study 2 Intercept 1 1.14** 1.67** 1.99** 0.95** 2.10** 1.99** Intercept 2 4.20** 1.83** 3.51** 3.62** 1.82** 3.47** Prefers Precaution Initial 0.03* 0.01 0.03** 0.02* 0.01 0.03** (1.03) (1.01) (1.03) (1.02) (1.01) (1.03) Range 0.39 0.27 0.32 0.32 0.38 1.58** (0.67) (1.31) (0.73) (1.38) (1.46) (0.21) Range  Prefers Precaution Initial 0.01 0.00 0.02 0.02 0.00 0.02 (1.01) (1.00) (0.98) (0.98) (1.00) (1.02) Distribution of implied dominance 2, 66, 24 13, 63, 15 4, 75, 14 3, 63, 28 14, 68, 11 5, 72, 14 Note. A separate model was fit for each scenario, with participant as the unit of analysis. The proportional odds assumption could not be rejected at p &lt; .05 in any model. Prefers Precaution Initial was centered relative to the mean, separately in each scenario. A contrast code was used for Range. The distribution of implied dominance gives the number of participants whose outcome utility ratings implied that the nonprecautionary option was weakly dominant, that neither alternative was dominant, or that the precautionary option was weakly dominant. Odds ratios appear in parentheses. Ratios greater than 1.0 mean that higher values of the independent variables were associated with higher probabilities that the precautionary option was dominant and lower probabilities that the nonprecautionary option was dominant. Wald v2 tests were used for statistical significance.  p &lt; .10. * p &lt; .05. ** p &lt; .01. 86 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92shown) yielded similar results within participants. Consistent with DeKay et al.’s (in press) results, participants’ initial preferences for decision alternatives apparently led to distorted utility evaluations that implied that the preferred alternative was dominant. Response patterns implying dominance were not accidental, at least when precaution was dominant. When asked whether their preferred alternative would change if the probability of the adverse event were higher or lower, participants said ‘‘No” in 179 out of 606 cases. According to this explicit measure, the nonprecautionary op- tion was dominant in 19 cases, neither option was dominant in 427 cases, and the precautionary option was dominant in 160 cases. Summary As anticipated, participants distorted their evaluations of prob- ability and outcome information to favor the currently preferred alternative and used these biased evaluations to update their pref- erences. They also evaluated the utilities of possible outcomes more positively when the outcomes could follow only from the preferred decision alternative and more negatively when the out- comes could follow only from the competing alternative. These dis- torted evaluations frequently implied that one alternative dominated the other. Study 2 In our second study, we attempted to replicate the above findings in a sample of older nonuniversity participants. In addition, we investigated whether the magnitude of distortion depended on whether information was presented as precise numerical values or as ranges of values. Although ambiguity may be manipulated in many ways, ranges have often been used to convey ambiguous prob- ability information (Curley &amp; Yates, 1985; Kuhn, 1997) and ambigu- ous nonprobability information such as investment returns (Ho et al., 2002), profits (Schweitzer &amp; Hsee, 2002), wage rates (Hsee, 1995), sunk costs (van Dijk &amp; Zeelenberg, 2003), prices of forgone options (van Putten, Zeelenberg, &amp; van Dijk, 2006), and otherattributes of choice alternatives (Hsee, 1995; Schweitzer &amp; Hsee, 2002) (see Footnote 1). Most authors have used within-participant manipulations (particularly in studies of ambiguity aversion), but some have used between-participant manipulations successfully (Hsee, 1996; Schweitzer &amp; Hsee, 2002; van Dijk &amp; Zeelenberg, 2003; van Putten et al., 2006). In this study, we varied range in a be- tween-participant manner in order to limit the complexity of the materials and analyses (several factors already varied within partic- ipants). Although the materials in other studies have often described the sources of numerical ranges (e.g., differing opinions among pro- ject staff in Ho et al., 2002), we did not provide such explanations be- cause we thought that they would become tedious and because they would be confounded with information items and scenarios. Method Participants One hundred two people from 10 Pittsburgh-area community organizations participated for $30 cash or an equivalent donation to their organization. Five participants were dropped for not com- pleting the study. Those remaining were 29–87 years old (M = 45.9); 57.3% were female and 96.9% were nonstudents. Materials and procedures Participants were randomly assigned to one of two conditions: point or range. Information about probabilities, true positives, false positives, and false negatives was presented either as precise numerical values (e.g., ‘‘4 people per year get infected with mad cow disease”) or as ranges (e.g., ‘‘between 1 and 7 people per year get infected”). In other cases, 3% became 1–5%, 80% became 70– 90%, 500 deaths became 200–800 deaths, and so on (see Appendix A). Information about true negatives was identical in the two con- ditions. In one case (a false negative in Scenario F), the text referred to ‘‘some” non-pests and plants in the point condition and to ‘‘an unknown number of” non-pests and plants in the range condition. We also added information about the economic costs of restricting M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 87the use of cellular phones in Scenario B. Except for such differences, the experimental procedures were identical to those in Study 1. Results and discussion The analyses in this study parallel those in Study 1: the only dif- ferences involve comparisons of the point and range conditions. Before proceeding to the main analyses, we report the results of a separate manipulation check for range (conducted after Study 2 was complete). Manipulation check for range Two hundred twenty-six members of the Carnegie Mellon Uni- versity community received $2 for their participation in a 6 (Sce- nario)  2 (Range) between-participant computer-based study. Participants read one of the six scenarios (including the five infor- mation items) and indicated their preferred decision. They then pro- vided overall evaluations of the information on twelve 7-point scales (e.g., ‘‘In your opinion, how vague were the five pieces of information?” with endpoints labeled Not at all vague (1) and Extre- mely vague (7)). Seven of these scales assessed perceived ambiguity (vague, specific, open to interpretation, exact, uncertain, ambiguous, and precise); the other five were fillers (realistic, relevant to your decision, surprising, interesting, and useful). Finally, participants indicated how the numerical information had been presented, by choosing one of five options ranging from All or almost all was pre- sented using single numbers (coded as 1) and All or almost all was pre- sented using ranges of numbers (coded as 5). This question was asked last so that it would not affect responses to the perceived-ambiguity questions. The fully between-participant design allowed for the evaluation of each scenario without alerting participants to the po- tential importance of range and perceived ambiguity. Participants correctly recalled that more information had been presented as ranges in the range condition than in the point condi- tion, M = 3.62 and M = 2.00, respectively, t(224) = 12.20, p &lt; .01, d = 1.63. After reversing responses to three questions (specific, ex- act, and precise), we averaged the seven perceived-ambiguity questions to form a single scale (a = 0.82). Contrary to expecta- tions, perceived ambiguity was essentially identical in the range and point conditions, M = 3.77 and M = 3.87, respectively, t(224) = 0.72, p = .47, d = 0.10. These results held for all six sce- narios. So although participants noticed how numerical informa- tion was presented, this knowledge did not translate into differences in perceived ambiguity in this between-participant assessment. We therefore refer to the manipulated variable as Range rather than Ambiguity in Study 2. Distortion of probability and outcome information As in Study 1, our main analyses concerned the relationship be- tween participants’ emerging decision preferences and their evalua- tions of new probability and outcome information. In this study, however, we were also interested in whether such distortion effects were moderated by Range. To the multilevel model in Eq. (4), we added a contrast-coded Range variable (range = 0.5, point = 0.5) and the interactions of this variable with Prefers Precaution Before (Mean) and Prefers Precaution Before (Deviation). The effects of Range and its interactions were not significant (see Table 1), probably be- cause the variable did not have the intended effect on perceived ambiguity. Other results in Table 1 and Fig. 1 indicate that partici- pants’ evaluations of information as favoring one option or the other were positively related to their immediately prior preferences, ĉ01 ¼ 0:74 for Prefers Precaution Before (Mean) and ĉ10 ¼ 0:33 for Pre- fers Precaution Before (Deviation). As before, these coefficients re- mained large and significant when initial preferences were added to the model. Additional models indicated that the effects were po- sitive for all information items (10 coefficients) and all scenarios(12 coefficients). Twenty of these 22 coefficients were larger in Study 2 than in Study 1. Cronbach’s a for consistency among the five Infor- mation Favors Precaution ratings ranged from .71 to .78, depending on the scenario. For five of the six scenarios, a was greater than in Study 1. The above results suggest that information distortion was greater in Study 2 than in Study 1, but they do not provide a test of this difference. To this end (and despite differences between the materials in the two studies), we conducted a short series of exploratory analyses in which we considered both studies simul- taneously. Specifically, we added a contrast-coded Study variable (Study 2 = 0.5, Study 1 = 0.5) and the interactions of this variable with Prefers Precaution Before (Mean) and Prefers Precaution Before (Deviation) to the model in Eq. (4). Study was not a significant pre- dictor, but both of the interactions were, ĉ ¼ 0:20, t(194) = 2.16, p = .03, and ĉ ¼ 0:08, t(5708) = 2.08, p = .04, respectively, indicat- ing greater information distortion in Study 2. To investigate possible sources of these between-study differ- ences, we added Age (centered), Education (coded 1–6, then cen- tered), Sex (female = 0.5, male = 0.5), and the interactions of these variables with the two Prefers Precaution Before variables to the model. The Study  Prefers Precaution Before (Mean) interaction dropped to about a third of its former size, ĉ ¼ 0:07, t &lt; 1, appar- ently mediated by Age (more distortion for older participants, p = .01 for the Age  Prefers Precaution Before (Mean) interaction) and Education (less distortion for more educated participants, p = .01 for the Education  Prefers Precaution Before (Mean) interac- tion). However, none of the demographic variables interacted sig- nificantly with Prefers Precaution Before (Deviation); the Study  Prefers Precaution Before (Deviation) interaction maintained its original size, ĉ ¼ 0:09, t(5589) = 1.95, p = .05. Thus, demographic differences between participants in the two studies were related to the difference in information distortion as assessed between participants, but not as assessed within participants. The be- tween-participant results are consistent with Carlson and Russo’s (2001) finding that distortion of evidence in a mock trial was greater among prospective jurors (who were older and probably less educated) than among undergraduate participants. Effects of information evaluations on subsequent preferences As in the previous study, it was important to assess whether distorted evaluations of probability and outcome information af- fected subsequent preference judgments. To answer this question, and to assess whether such effects differed in the range and point conditions, we added Range and its interactions with the two Infor- mation Favors Precaution variables to the model in Eq. (5). These ef- fects of Range were not significant. As before, the coefficients for Information Favors Precaution (Mean) and Information Favors Pre- caution (Deviation) were both positive, though the former was not quite significant, ĉ01 ¼ 0:10, t(92) = 1.76, p = .08, and ĉ10 ¼ 0:43, t(2780) = 17.68, p &lt; .01, respectively. These results pro- vide additional evidence that distorted evaluations are carried for- ward in the decision process. Effects of initial preferences on outcome utilities To assess the effects of initial preferences on utility judgments (rather than favorability judgments), and to determine whether such effects were moderated by Range, we added Range and its interactions with the two Prefers Precaution Initial variables to the four separate multilevel models for predicting outcome utili- ties. Six of the eight coefficients for initial preferences were signif- icant at the p &lt; .05 level (see Table 2). As before, the four coefficients for true positives and false positives were positive and the four coefficients for true negatives and false negatives were negative. False negatives were viewed as worse when quantitative information was presented as ranges, ĉ ¼ 5:85, 88 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92t(93) = 3.07, p &lt; .01, but the effects of initial preferences were not moderated by Range. As in Study 1, we also used a single multilevel model to assess the interactions between initial preferences and possible outcomes in predicting outcome utilities. The two interactions involving TPFP versus TNFN were again positive and significant, ĉ ¼ 0:33, t(2215) = 3.47, p &lt; .01 for TPFP versus TNFN  Prefers Precaution Ini- tial (Mean) and ĉ ¼ 0:26, t(2215) = 5.38, p &lt; .01 for TPFP versus TNFN  Prefers Precaution Initial (Deviation), indicating that the relationship between initial preferences and outcome desirability depended on whether the outcome could follow from the preferred decision. Like the corresponding results of Study 1, these results demonstrate that utility assessments are distorted in the direction of the preferred decision alternative. Effects of initial preferences on implied dominance Finally, to assess whether distortions of utility assessments were severe enough to imply that one decision alternative domi- nated the other, we categorized and tallied participants’ utility pat- terns as in Study 1. As expected, these utility patterns again implied a dominant decision alternative in many instances. Of the 582 patterns in this study, 41 implied that the nonprecaution- ary option was weakly dominant, 407 implied that neither option was dominant, 106 implied that the precautionary option was weakly dominant, and 28 were of some other type (in 26 of these, UTN = UFP and UTP = UFN, implying that one’s course of action did not matter). We added Range and Range  Prefers Precaution Initial to the ordinal logistic regression models for predicting implied domi- nance. As before, the coefficient for Prefers Precaution Initial was positive in all six scenarios (see Table 3). The effect of Range was significant in only one scenario, and in no scenario did Range mod- erate the effect of initial preferences. Repeated-measures binary lo- gistic regressions again yielded similar results for within- participant effects. As in Study 1, these results indicate that partic- ipants’ initial preferences for decision alternatives can lead to dis- torted assessments of possible outcomes, such that those assessments imply that the initially preferred alternative is dominant. When asked directly about their preferred alternative, partici- pants indicated that the nonprecautionary option was dominant in 18 cases, that neither option was dominant in 326 cases, and that the precautionary option was dominant in 237 cases. Summary The results of this study were remarkably similar to those of Study 1. Indeed, information distortion was greater in Study 2, with the larger between-participant effect (but not the larger within-participant effect) being related to differences in age and education (distortion was greater for older, less educated participants). There were no important effects of the Range manipulation, presumably because it did not affect perceived ambiguity as intended.General discussion The results of both studies demonstrate that probability and outcome information in risky decisions is distorted to favor the preferred alternative and that these distorted evaluations are sub- sequently used to update preferences. These findings extend previ- ous research on information distortion and bidirectional reasoning to this important class of decisions. Our results also indicate that utility judgments depend on the relationships between outcomes and decision alternatives. Specifically, outcomes that can follow only from the preferred alternative are evaluated more positively,whereas outcomes that can follow only from the competing alter- native are evaluated more negatively. In extreme cases, such eval- uations can imply that one alternative dominates the other. These findings bolster DeKay et al.’s (in press) conclusions regarding the role of initial decision preferences in the assessment of outcome utilities. Our multilevel analyses illustrate the usefulness of teasing apart between-participant and within-participant effects in studies of information distortion. As Table 1 shows, the effect of prior prefer- ences on the evaluation of information was large and significant at both levels of analysis. Interestingly, however, the between-partic- ipant effect was about twice the size of the within-participant ef- fect in both studies. Despite this difference, distorted evaluations had a significant effect on subsequent preferences only when as- sessed within participants, again in both studies (results in text). This state of affairs can be summarized as follows: participants who generally favored (disfavored) taking precautionary actions generally interpreted new information as favoring (disfavoring) such actions, but these biased evaluations had little effect on par- ticipants’ overall attitudes toward precaution. Within participants, preferences for (against) specific precautionary actions affected the evaluation of new information about those actions to a lesser ex- tent, but these biased evaluations were more likely to be carried forward to maintain or strengthen participants’ preferences for (against) the actions in question. Thus, distorted evaluations of new information may affect individuals’ attitudes about specific risks without necessarily changing their attitudes about risks more generally. Another intriguing finding is that the between-participant effect of emerging preferences on evaluations of probabilities and out- comes (the relationship illustrated by the open circles in Fig. 1) was moderated by age and education, whereas the analogous with- in-participant effect (the relationship illustrated by the lines in Fig. 1) was not. The between-participant results—that information distortion was greater for older and less educated participants— echo a similar difference between student and nonstudent samples of mock jurors in studies by Carlson and Russo (2001). In Study 2, our range manipulation had almost no effect on par- ticipants’ judgments. In retrospect, the impact of the manipulation was probably lessened by two design choices. First, we presented range information rather authoritatively (e.g., ‘‘the blood supply is reduced by 5% to 15%”), with no verbal qualification and no men- tion of the source of uncertainty. Alternative presentations like the following would surely have made uncertainty more salient: ‘‘There is a great deal of uncertainty regarding potential decreases in the blood supply, in part because there has been so little re- search on the topic. Agency staff members think that the blood supply would decrease by about 5% to 15%, but this is only a rough estimate.” Second, we manipulated range between participants rather than within participants. Although between-participant manipulations have been successful for some effects of ambiguity (Hsee, 1996; Schweitzer &amp; Hsee, 2002; van Dijk &amp; Zeelenberg, 2003; van Putten et al., 2006), other effects may require the com- parative context provided by within-participant designs (Fox &amp; Tversky, 1995). Because our materials precluded direct compari- sons of precise and imprecise values, participants had no obvious way to assess relative uncertainty. Consistent with this explana- tion, Russo et al. (1998) reported a negative relationship between information distortion and diagnosticity in a within-participant design, and Russo and Yong (in press) reported very similar levels of distortion for numerical and verbal information in a between- participant design. For now, whether more ambiguous information is more susceptible to distortion remains an open question. Ambi- guity is not a prerequisite for distortion, however, as the distorted evaluations of precise numerical information in our studies and those of others illustrate (Bond et al., 2007; Levy &amp; Hershey, 2006). M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 89Alternative explanations The consistency of our results across studies, scenarios, and information items might lead one to wonder whether they are due solely to uninteresting between-participant differences involv- ing scale usage. If some participants gave higher or lower ratings across the board, these response patterns might create positive relationships between preferences for alternatives and evaluations of information. However, this explanation cannot account for the within-participant differences evident in Table 1 and Fig. 1. Nor can it account for the fact that immediately prior preferences were better predictors of information evaluations than were initial pref- erences, or the fact that relationships between initial preferences and outcome utilities were negative for true negatives and false negatives (results that were observed both within and between participants). Moreover, the average participant used 83% of the re- sponse scale for preference judgments and 90% of the response scale for favorability judgments, making it difficult to argue that our findings reflect participants’ use of consistently high or low ratings. Another possible explanation for our results is that participants may have considered other relevant consequences (not explicitly mentioned in our scenarios) that were consistent with their pre- ferred decision alternatives. For example, a person who is politi- cally opposed to government intervention in personal affairs and markets might also imagine additional costs associated with true positives and false positives in Scenario B (banning cellular phone use by automobile drivers) and Scenario F (banning genetically modified foods). Such considerations could potentially lead to in- creased consistency between preferences and outcome evalua- tions, thereby mimicking information distortion both within and between participants. If so, these effects might be viewed as reflecting legitimate preference heterogeneity across scenarios and participants. Consideration of additional relevant conse- quences could also lead to implied dominance in some instances. For example, if participants reasoned that evacuations provided valuable practice in Scenarios A and C, or that hormones had addi- tional negative effects on cows or humans in Scenario D, then it might be logical for participants to evaluate ‘‘false” positives as better than ‘‘true” negatives. Although it is certainly possible that some participants imagined such consequences in some circum- stances, we do not think that this account provides a general expla- nation for our results. Our analyses indicate that preferences were positively associated with evaluations of information in all scenar- ios, for all information items, and for almost all participants in both studies. It seems very unlikely that consideration of additional con- sequences would be so widespread, or that it would provide such systematic support for the preferred alternative. In particular, it is difficult for us to imagine what sorts of other considerations might be incorporated into evaluations of true negatives and prob- abilities. Moreover, when DeKay et al.’s (in press) participants were asked to explain utility ratings that implied dominance in versions of these and other scenarios, they did not provide reasons like those mentioned above. Instead, they typically referred to their preferred decision alternative or to their desire to avoid a false neg- ative. Both explanations are consistent with DeKay et al.’s pro- posed information-distortion model for implied dominance. As noted in the introduction, regret theory, disappointment theory, and decision affect theory cannot explain utility patterns that imply dominance. Unlike information-distortion accounts, these theories of anticipated emotion do not include a mechanism for reducing or reversing the difference between the utilities of two outcomes that result from different actions (e.g., evacuating or not) when a given state of the world occurs (e.g., when the dam does not fail). Indeed, the theorized effects of anticipated emotion work against dominance by increasing UTN  UFP andUTP  UFN (for details, see DeKay et al., in press). If such effects were present in our studies (which is certainly possible), informa- tion distortion would have had to clear an even higher hurdle in order to create utility patterns that implied dominance. Finally, we note that although disappointment and decision affect theo- ries allow probabilities to influence outcome utilities, the theories have no mechanism for distorting probabilities to favor an ini- tially preferred alternative. In our view, coupling theories of anticipated emotion with theories of information distortion and bidirectional reasoning should be a high priority for future re- search on risky choice. Normative considerations In some circumstances, information distortion may be adaptive: it can simplify decisions by reducing or eliminating tradeoffs and it can lessen the tendency to second-guess decisions once they are made. Choices that appear to be supported by all or most of the data are both easier to make and easier to justify. However, if one’s goal is to make a good choice rather than an easy choice (when these differ), there is something very troubling about distorting information that is ostensibly used as the basis for choice in a man- ner that supports one’s initial or emerging preference. This is espe- cially true when early preferences are based on unjustifiable attributes (Hsee, 1995, 1996) or on normatively irrelevant factors such as information order (Carlson et al., 2006; DeKay &amp; Stone, 2007). Information distortion can also lead to choices that choosers themselves judge to be inferior, as demonstrated by Russo et al. (2006). Distortions of legal evidence are particularly disturbing. In- deed, Simon (2004) suggested that jurors be instructed to ‘‘take some time to seriously consider the possibility that the opposite side has the better case” (p. 544), in hopes of moderating such dis- tortions (in one study, this manipulation reduced distortions by about half). The case that information distortion is nonnormative is also strong when the information in question consists of probabilities and outcome utilities (DeKay et al., in press). In a medical context, for example, Levy and Hershey (2006) noted that probability dis- tortions ‘‘can lead to misperceptions of the decision options and therefore, to suboptimal medical decisions” (p. 56). Although prob- ability distortions often correspond to wishful thinking or false hope, they can also inflate the likelihood of adverse events, leading to excessive worry or unwarranted precaution. Of course, misper- ceptions of outcomes can also lead to poor decisions. According to expected utility theory and other consequentialist approaches to decision making (Frisch &amp; Clemen, 1994; Sinnott-Armstrong, 2007), both probabilities and outcome utilities are rightly treated as inputs to (rather than outputs of) the decision process. From this perspective, allowing one’s preferences among choice options to affect judgments of the likelihood and desirability of the possible consequences of those options renders the decision process circu- lar. Backward inferences from preferences to probabilities and util- ities are antithetical to the consequentialist principles on which much of modern decision theory is built. Not all normative decision theories are consequentialist, how- ever. Most notably, deontological ethics (Alexander &amp; Moore, 2008) requires that actions be consistent with rules based on du- ties, obligations, or the rights of others (e.g., a rule against harming the innocent), without regard to consequences. Although such rules might account for some participants’ initial preferences in our scenarios, nothing in deontological theories suggests that con- sequences should or should not be evaluated in accordance with those preferences. Thus, deontology is silent regarding the norma- tive status of our participants’ distorted evaluations of probabilities and outcomes; the most one can infer is that deontological rules do not forbid such distortions. 90 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92In our view, good decision processes require unbiased assess- ments of relevant information, including information about the likelihood and desirability of possible outcomes. Undistorted assessments are particularly important in high-stakes risky deci- sions like those described in several of our scenarios. As a practical matter, the circular reasoning processes documented here and elsewhere can undermine individuals’ ability to achieve their own goals and undermine the usefulness of decision analysis as a method for making difficult decisions involving risk. Acknowledgments This research was supported by a grant from the Center for the Study and Improvement of Regulation at Carnegie Mellon Univer- sity and by National Science Foundation Grant SES-0112005. We thank Judy Hartman for assistance with programming, Nathanial Peterson for assistance with data collection, and Mike Edwards, Jennifer Lerner, Don Moore, and Jay Russo for helpful comments on earlier versions of this article. Appendix A The text for the six scenarios appears below. Text that appeared in only one or two versions is indicated by parentheses () for Study 1, brackets [] for the point condition of Study 2, and curly brackets {} for the range condition of Study 2. Labels for information items (e.g., probability, false negative) were not shown to participants. A.1. Scenario A: responding to a dam-failure warning Imagine that you own a home on the bank of a creek in a steep- walled canyon. About 20 miles upstream, there is a dam that holds back a medium-sized reservoir. A sheriff’s deputy pulls up and tells you that the dam may fail. You must decide whether to evacuate or not. Probability. The chance of dam failure is [(10%)] {between 5% and 15%}. False negative. If the dam fails and you have not evacuated your home, then your home is severely damaged and there is a [(5%)] {2% to 8%} chance that you die in the flood. True positive. If the dam fails and you have evacuated your home then you incur the hassle and expense associated with evacuating [the area for four hours].2 Your home is severely damaged, but you are safe. True negative. If the dam does not fail and you have not evacu- ated your home then nothing unusual happens. Later, officials indi- cate that the risk has passed. False positive. If the dam does not fail and you have evacuated, then you incur the hassle and expense associated with evacuating {[the area for [four] {2 to 6} hours]}. Later, officials indicate that the risk has passed. A.2. Scenario B: banning the use of cellular phones by automobile drivers Preliminary studies suggest that the risk of automobile acci- dents is substantially higher when the driver is using a cellular phone, but critics argue that these results are not conclusive. Imag- ine that you are the chief administrator at the U.S. Department of Transportation.2 In the range condition of Study 2, the text ‘‘the area for 2 to 6 hours” was inadvertently omitted from the description of a true positive in Scenario A. This text did appear in the description of a false positive.You must decide whether to ban the use of cellular phones by automobile drivers. Probability. The chance that cell phones substantially increase the risk of accidents is [(40%)] {between 30% and 50%}. False negative. If cell phones substantially increase the risk of accidents and you have not banned them, then (about) 40,000 peo- ple per year are killed in auto accidents. [(500)] {Between 200 and 800} of these deaths are due to cell phones. True positive. If cell phones substantially increase the risk of accidents and you have banned them, then drivers are inconve- nienced by not being able to use their cell phones. {[As a result, productivity in the U.S. decreases, causing economic losses of [600] {300 to 900} million dollars per year.]} (About) [(39,500)] {Between 39,200 and 39,800} people per year are killed in auto accidents. True negative. If cell phones do not substantially increase the risk of accidents and you have not banned them, then (about) 40,000 people per year are killed in auto accidents, but almost none of these deaths are due to cell phones. False positive. If cell phones do not substantially increase the risk of accidents and you have banned them, then drivers are inconvenienced by not being able to use their cell phones. {[As a result, productivity in the U.S. decreases, causing economic losses of [600] {300 to 900} million dollars per year.]} (About) 40,000 people per year are killed in auto accidents, but almost none of these deaths are due to cell phones. A.3. Scenario C: responding to a failure of airport security At the nearby international airport, travelers must pass through one of 12 airport security-screening machines. One of the security machines has just failed a reliability check. It has been determined that for the past 20 minutes, the machine was not functioning properly, and if travelers had been carrying illegal weapons, they would not have been detected. Forty-five people have been checked by the machine during the 20 minutes and have pro- ceeded to the gates. Imagine that you are the official in charge of airport security. You must decide whether to evacuate the terminal of all 4,500 people so that all travelers can be re-screened. Probability. The chance that an illegal weapon has been smug- gled through security by a terrorist is (0.001% (1 in 100,000)) [2 in a million] {between 1 in a million and 3 in a million}. False negative. If an illegal weapon has been smuggled through security by a terrorist and you have not evacuated the terminal, then the chance of a terrorist attack is [(80%)] {between 70% and 90%}. True positive. If an illegal weapon has been smuggled through security by a terrorist and you have evacuated the terminal, then the 4,500 travelers incur the hassle and expense associated with (delayed flights) {[flight delays of [3] {1 to 5} hours]}, but the terrorist would leave the airport. True negative. If an illegal weapon has not been smuggled through security by a terrorist and you have not evacuated the ter- minal, then nothing unusual happens. False positive. If an illegal weapon has not been smuggled through security by a terrorist and you have evacuated the ter- minal, then the 4,500 travelers incur the hassle and expense associated with (delayed flights) {[flight delays of [3] {1 to 5} hours]}. A.4. Scenario D: buying milk from hormone-treated cows Companies have developed hormones that increase the milk production of dairy cows. These increases result in lower milk prices for consumers. Some consumer and environmental groups M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92 91claim that drinking milk from hormone-treated cows may cause cancer in humans, but the evidence is inconclusive. Imagine that the U.S. Food and Drug Administration requires that all milk from hormone-treated cows be labeled ‘‘This product comes from cows treated with hormones.” Also imagine that you are married and have two children, and that you are the person who does the gro- cery shopping for your family. You must decide whether to buy milk from ‘‘hormone-treated” cows. Probability. The chance that milk from hormone-treated cows causes cancer is (1%) [2%] {between 1% and 3%}. False negative. If milk from hormone-treated cows causes cancer and you have bought this milk, then for each member of your fam- ily, the chance that they would get cancer at some point in their life increases by (1 in 100,000) [4 in a million] {between 2 in a million and 6 in a million}. True positive. If milk from hormone-treated cows causes cancer and you have not bought this milk, then you incur (the cost of buy- ing the more expensive milk) {[an extra cost of [$0.75] {$0.50 to $1.00} per gallon for buying the milk]} that is not from hormone- treated cows. The risk of cancer does not increase for members of your family. True negative. If milk from hormone-treated cows does not cause cancer and you have bought this milk, then the risk of cancer does not increase for members of your family. False positive. If milk from hormone-treated cows does not cause cancer and you have not bought this milk, then you incur (the cost of buying the more expensive milk) {[an extra cost of [$0.75] {$0.50 to $1.00} per gallon for buying the milk]} that is not from hormone-treated cows. The risk of cancer does not in- crease for members of your family. A.5. Scenario E: banning blood donations from people who (have) visited England Mad cow disease is a fatal disease that killed many cows in Eng- land during the 1980’s and 1990’s. The disease may be transmitted to people who eat infected beef. The disease is also fatal to humans, but it may take years or decades for symptoms to emerge. Although it is theoretically possible for a person to become in- fected by receiving a transfusion of contaminated blood from an in- fected person, there is no evidence that the disease has ever been transmitted from person to person in this way, and the risk of such transmission is not known. Imagine that you are the chief admin- istrator at the U.S. Food and Drug Administration. You must decide whether to ban blood donations from Ameri- cans who have spent 6 months or more in England since 1980, be- cause they might be infected with mad cow disease without knowing it. Probability. The chance that mad cow disease can be transmitted through blood transfusions is (2%) [3%] {between 1% and 5%}. False negative. If mad cow disease can be transmitted through blood transfusions and you have not banned blood donations from people who have visited England, then (one or two) [4] {between 1 and 7} people per year get infected with mad cow disease through blood transfusions, and die several years later. True positive. If mad cow disease can be transmitted through blood transfusions and you have banned blood donations from people who have visited England, then the blood supply is reduced by (about) [(10%)] {5% to 15%}, leading to cancellation of some scheduled surgeries and insufficient blood in emergencies. There are no cases of mad cow disease due to blood transfusions. True negative. If mad cow disease cannot be transmitted through blood transfusions and you have not banned blood dona- tions from people that have visited England, then nothing unusual happens.False positive. If mad cow disease cannot be transmitted through blood transfusions and you have banned blood donations from people who have visited England, then the blood supply is re- duced by (about) [(10%)] {5% to 15%}, leading to cancellation of some scheduled surgeries and insufficient blood in emergencies. There are no cases of mad cow disease due to blood transfusions. A.6. Scenario F: banning genetically modified crops and foods Companies have developed methods to genetically modify (potatoes) {[peaches]} in order to make them more resistant to pests (and more nutritious). (The increased pest resistance results in lower prices for consumers.) However, it has been suggested that genetically modified (potatoes) {[peaches]} may cause envi- ronmental damage. Imagine that you are the chief administrator at the U.S. Food and Drug Administration. You must decide whether to ban genetically modified (pota- toes) {[peaches]}. Probability. The chance that genetically modified (potatoes) {[peaches]} cause environmental damage is (15%) [12%] {between 8% and 16%}. False negative. If genetically modified (potatoes) {[peaches]} cause environmental damage and you have not banned them, then genetically modified (potatoes) {[peaches]} replace traditional varieties (, and are grown without pesticides). [(Some)] {An un- known number of} non-pests such as butterflies are harmed, and [(some)] {an unknown number of} {(other)} plants such as weeds become pest-resistant (, with unpredictable environmental consequences). True positive. If genetically modified (potatoes) {[peaches]} cause environmental damage and you have banned them, then tra- ditional varieties of (potatoes) {[peaches]} are grown (using pesti- cides). {Other plants and animals are not affected.} {[Consumers have to pay [$0.80] {between 60 cents and 1 dollar} more per pound to offset the losses due to pests.]} [Other plants and animals are not affected.] True negative. If genetically modified (potatoes) {[peaches]} do not cause environmental damage and you have not banned them, then genetically modified (potatoes) {[peaches]} [(replace tradi- tional varieties)] (, and are grown without pesticides) {are grown}. Other plants and animals are not affected. False positive. If genetically modified (potatoes) {[peaches]} do not cause environmental damage and you have banned them, then traditional varieties of (potatoes) {[peaches]} are grown (using pes- ticides). {[Consumers have to pay [$0.80] {between 60 cents and 1 dollar} more per pound to offset the losses due to pests.]} [Other plants and animals are not affected.]References Adelman, L., Bresnick, T. A., Christian, M., Gualtieri, J., &amp; Minionis, D. (1997). Demonstrating the effect of context on order effects for an army air defense task using the Patriot simulator. Journal of Behavioral Decision Making, 10, 327–342. Alexander, L., &amp; Moore, M. (2008). Deontological ethics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (spring 2008 ed.). &lt;http://plato.stanford.edu/ archives/spr2008/entries/ethics-deontological/&gt; Retrieved 31.07.08. Baron, J. (2008). Thinking and deciding (4th. ed.). New York: Cambridge University Press. Bell, D. E. (1982). Regret in decision making under uncertainty. Operations Research, 30, 961–981. Bell, D. E. (1985). Disappointment in decision making under uncertainty. Operations Research, 33, 1–27. Bond, S. D., Carlson, K. A., Meloy, M. G., Russo, J. E., &amp; Tanner, R. J. (2007). Information distortion in the evaluation of a single option. Organizational Behavior and Human Decision Processes, 102, 240–254. Brownstein, A. (2003). Biased predecision processing. Psychological Bulletin, 129, 545–568. Camerer, C., &amp; Weber, M. (1992). Recent developments in modeling preferences: Uncertainty and ambiguity. Journal of Risk and Uncertainty, 5, 325–370. 92 M.L. DeKay et al. / Organizational Behavior and Human Decision Processes 109 (2009) 79–92Carlson, K. A., Meloy, M. G., &amp; Russo, J. E. (2006). Leader-driven primacy: Using attribute order to affect consumer choice. Journal of Consumer Research, 32, 513–518. Carlson, K. A., &amp; Russo, J. E. (2001). Biased interpretation of evidence by mock jurors. Journal of Experimental Psychology: Applied, 7, 91–103. Clemen, R. T. (1996). Making hard decisions: An introduction to decision analysis (2nd. ed.). Belmont, CA: Duxbury Press. Curley, S. P., &amp; Yates, J. F. (1985). The center and range of the probability interval as factors affecting ambiguity preferences. Organizational Behavior and Human Decision Processes, 36, 273–287. DeKay, M. L., &amp; Stone, E. R. (2007 November). Distortion of payoffs and probabilities in mixed monetary gambles. Poster presentation at the annual meeting of the Society for Judgment and Decision Making, Long Beach, CA. DeKay, M. L., Patiño-Echeverri, D., &amp; Fischbeck, P. S. (in press). Better safe than sorry: Precautionary reasoning and implied dominance in risky decisions. Journal of Behavioral Decision Making. Dunning, D., Meyerowitz, J., &amp; Holzberg, A. (1989). Ambiguity and self-evaluation: The role of idiosyncratic trait definitions in self-serving assessments of ability. Journal of Personality and Social Psychology, 57, 1082–1090. Finucane, M. L., Alhakami, A., Slovic, P., &amp; Johnson, S. M. (2000). The affect heuristic in judgments of risk and benefit. Journal of Behavioral Decision Making, 13, 1–17. Fox, C. R., &amp; Tversky, A. (1995). Ambiguity aversion and comparative ignorance. Quarterly Journal of Economics, 110, 585–603. Frisch, D., &amp; Baron, J. (1988). Ambiguity and rationality. Journal of Behavioral Decision Making, 1, 149–157. Frisch, D., &amp; Clemen, R. T. (1994). Beyond expected utility theory: Rethinking behavioral decision research. Psychological Bulletin, 116, 46–54. Ho, J. L. Y., Keller, L. R., &amp; Keltyka, P. (2002). Effects of outcome and probabilistic ambiguity on managerial choices. Journal of Risk and Uncertainty, 24, 47–74. Holyoak, K. J., &amp; Simon, D. (1999). Bidirectional reasoning in decision making by constraint satisfaction. Journal of Experimental Psychology: General, 128, 3–31. Hope, L., Memon, A., &amp; McGeorge, P. (2004). Understanding pretrial publicity: Predecisional distortion of evidence by mock jurors. Journal of Experimental Psychology: Applied, 10, 111–119. Hsee, C. K. (1995). Elastic justification: How tempting but task-irrelevant factors influence decisions. Organizational Behavior and Human Decision Processes, 62, 330–337. Hsee, C. K. (1996). Elastic justification: How unjustifiable factors influence judgments. Organizational Behavior and Human Decision Processes, 66, 122–129. Kuhn, K. M. (1997). Communicating uncertainty: Framing effects on responses to vague probabilities. Organizational Behavior and Human Decision Processes, 71, 55–83. Kunda, Z. (1990). The case for motivated reasoning. Psychological Bulletin, 108, 480–498. Levy, A. G., &amp; Hershey, J. C. (2006). Distorting the probability of treatment success to justify treatment decisions. Organizational Behavior and Human Decision Processes, 101, 52–58. Levy, A. G., &amp; Hershey, J. C. (2008). Value-induced bias in medical decision making. Medical decision making, 28, 269–276. Loewenstein, G. F., Weber, E. U., Hsee, C. K., &amp; Welch, E. S. (2001). Risk as feelings. Psychological Bulletin, 127, 267–286. Loomes, G., &amp; Sugden, R. (1982). Regret theory: An alternative theory of rational choice under uncertainty. Economic Journal, 92, 805–824. Loomes, G., &amp; Sugden, R. (1986). Disappointment and dynamic consistency in choice under uncertainty. Review of Economic Studies, 53, 271–282. Mellers, B. A. (2000). Choice and the relative pleasure of consequences. Psychological Bulletin, 126, 910–924.Mellers, B. A., Schwartz, A., &amp; Ritov, I. (1999). Emotion-based choice. Journal of Experimental Psychology: General, 128, 332–345. Montgomery, H. (1983). Decision rules and the search for a dominance structure: Towards a process model of decision making. In P. Humphreys, O. Svenson, &amp; A. Vari (Eds.), Analysing and aiding decision processes (pp. 343–369). Amsterdam: North-Holland. Raudenbush, S. W., &amp; Bryk, A. S. (2002). Hierarchical linear models: Applications and data analysis methods (2nd. ed.). Thousand Oaks: Sage. Russo, J. E., &amp; Yong, K. (in press). The distortion of information to support an emerging assessment of risk. Journal of Econometrics.. Russo, J. E., Carlson, K. A., &amp; Meloy, M. G. (2006). Choosing an inferior alternative. Psychological Science, 17, 899–904. Russo, J. E., Carlson, K. A., Meloy, M. G., &amp; Yong, K. (2008). The goal of consistency as a cause of information distortion. Journal of Experimental Psychology: General, 137, 456–470. Russo, J. E., Medvec, V. H., &amp; Meloy, M. G. (1996). The distortion of information during decisions. Organizational Behavior and Human Decision Processes, 66, 102–110. Russo, J. E., Meloy, M. G., &amp; Medvec, V. H. (1998). Predecisional distortion of product information. Journal of Marketing Research, 35, 438–452. Russo, J. E., Meloy, M. G., &amp; Wilks, T. J. (2000). Predecisional distortion of information by auditors and salespersons. Management Science, 46, 13–27. Schweitzer, M. E., &amp; Hsee, C. K. (2002). Stretching the truth: Elastic justification and motivated communication of uncertain information. Journal of Risk and Uncertainty, 25, 185–201. Simon, D. (2004). A third view of the black box: Cognitive coherence in legal decision making. The University of Chicago Law Review, 71, 511–586. Simon, D., Krawczyk, D. C., &amp; Holyoak, K. J. (2004). Construction of preferences by constraint satisfaction. Psychological Science, 15, 331–336. Simon, D., Pham, L. B., Le, Q. A., &amp; Holyoak, K. J. (2001). The emergence of coherence over the course of decision making. Journal of Experimental Psychology: Learning, Memory, and Cognition, 27, 1250–1260. Simon, D., Snow, C. J., &amp; Read, S. J. (2004). The redux of cognitive consistency theories: Evidence judgments by constraint satisfaction. Journal of Personality and Social Psychology, 86, 814–837. Sinnott-Armstrong, W. (2007). Consequentialism. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (spring 2007 ed.). &lt;http://plato.stanford.edu/ archives/spr2007/entries/consequentialism/&gt; Retrieved 31.07.08. Slovic, P., Finucane, M. L., Peters, E., &amp; MacGregor, D. G. (2002). The affect heuristic. In T. Gilovick, D. Griffin, &amp; D. Kahneman (Eds.), Heuristics and biases: The psychology of intuitive judgment (pp. 397–420). New York: Cambridge University Press. Snijders, T. A. B., &amp; Bosker, R. J. (1999). Multilevel analysis: An introduction to basic and advanced multilevel modeling. Thousand Oaks, CA: Sage. Svenson, O. (1992). Differentiation and consolidation theory of human decision making: A frame of reference for the study of pre- and post-decision processes. Acta Psychologica, 80, 143–168. van Dijk, E., &amp; Zeelenberg, M. (2003). The discounting of ambiguous information in economic decision making. Journal of Behavioral Decision Making, 16, 341–352. van Putten, M., Zeelenberg, M., &amp; van Dijk, E. (2006). Decoupling the past from the present attenuates inaction inertia. Journal of Behavioral Decision Making, 20, 65–79. von Winterfeldt, D., &amp; Edwards, W. (1986). Decision analysis and behavioral research. London: Cambridge University Press. Wallsten, T. (1981). Physician and medical student bias in evaluating diagnostic information. Medical Decision Making, 1, 145–164.</p>
        </div>
      </section>
    </article>
  </body>
</html>
