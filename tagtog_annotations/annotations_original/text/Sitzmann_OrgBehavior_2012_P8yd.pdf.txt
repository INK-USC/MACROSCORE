Sitzmann_OrgBehavior_2012_P8yd.pdf
a2r8chMie1L1SjIDR_iXBdTr.Wom-Sitzmann_OrgBehavior_2012_P8yd.pdf.plain.html

Organizational Behavior and Human Decision Processes 117 (2012) 192–207Contents lists available at SciVerse ScienceDirect Organizational Behavior and Human Decision Processes journal homepage: www.elsevier .com/ locate /obhdpWhen is ignorance bliss? The effects of inaccurate self-assessments of knowledge on learning and attrition Traci Sitzmann ⇑, Stefanie K. Johnson University of Colorado Denver, School of Business, PO Box 173364, Campus Box 165, Denver, CO 80217–3364, United States a r t i c l e i n f oArticle history: Received 8 June 2010 Accepted 7 November 2011 Available online 7 December 2011 Accepted by Paul Levy Keywords: Attrition Feedback Self-assessment of knowledge Self-enhancement theory Self-verification theory Training0749-5978/$ - see front matter Published by Elsevier doi:10.1016/j.obhdp.2011.11.004 ⇑ Corresponding author. E-mail addresses: Traci.Sitzmann@ucdenver.edu (T @ucdenver.edu (S.K. Johnson).a b s t r a c t Two studies were conducted to examine the implications of inaccurate self-appraisals in online training. Self-assessment of knowledge moderated the effects of trainees’ performance on subsequent performance and attrition. Performance was highest after uniformly positive ratings (i.e., high self-assessment and high performance), followed by underestimation, overestimation, and uniformly negative ratings, respectively. Attrition was lowest after uniformly positive ratings, followed by underestimation, uniformly negative ratings, and overestimation, respectively. Effort had a more positive effect on performance following low than high self-assessments and this interaction fully mediated the self-assessment/performance interac- tion on subsequent performance. Commitment had a more negative effect on subsequent attrition follow- ing low than high self-assessments and this interaction fully mediated the self-assessment/performance interaction on subsequent attrition. Finally, trainee conscientiousness affected their behavior when their performance and self-assessments were inconsistent—overestimating and underestimating performance increased attrition more for trainees low in conscientiousness and impaired performance more for trainees high in conscientiousness. Published by Elsevier Inc.Introduction Employees consistently receive feedback in a variety of organi- zational contexts with the expectation that feedback will result in positive behavior change. However, three meta-analyses on the effects of feedback have shown that feedback generally leads to positive outcomes, but the effects of feedback on outcomes are quite variable (Bangert-Drowns, Kulik, & Morgan, 1991; Hattie & Timperley, 2007; Kluger & DeNisi, 1996). Atwater, Waldman, Atwater, and Cartier (2000) found that only 50% of managers showed improvement following feedback, and Kluger and DeNisi (1996) found that in up to a third of cases, feedback had a negative effect on performance. In an effort to understand the effects of feedback, researchers have found that positive feedback is generally perceived to be more accurate and is more accepted than negative feedback (Halperin, Snyder, Shenkel, & Houston, 1976; Stone & Stone, 1985). Positive feedback also results in increased motivation whereas negative feedback results in decreased motivation (Venables & Fairclough, 2009). In addition, negative feedback may be perceived as threaten- ing and result in harmful emotional reactions (Taylor, Fisher, & Ilgen, 1984; van Dijk, van der Pligt, & Zeelenberg, 1999). As a result, the popular press and practitioners have suggested that positive feed-Inc. . Sitzmann), Stefanie.Johnsonback can be used to increase performance (Miller, Wang, Sandel, & Cho, 2002; Seligman, Reivich, Jaycox, & Gillham, 1995). However, control theory suggests that positive feedback may not be beneficial for initiating behavior change (Carver & Scheier, 1981). Employees need to know their actual performance in order to adjust their effort. Also, feedback that is inconsistent with employees’ self-appraisals may result in negative reactions and the perception that feedback is less accurate than feedback that is consistent with their self-appraisals (Bernstein & Lecomte, 1979; Meyer, 1980; Shrauger, 1975; Swann, 1990). The most common finding is that negative outcomes arise when feedback is lower than expected (Brett & Atwater, 2001). Positive feedback should improve performance, but this improvement will be greatest for those who also self-assess positively (Atwater & Yammarino, 1997). Although feedback is pertinent to a variety of contexts, the cur- rent study examines the implications of a lack of fit between self- appraisals and actual performance in online training. Specifically, in two studies, we examine whether the interaction between train- ees’ self-assessments of knowledge and actual performance pre- dicted subsequent performance and attrition in courses that provided frequent performance feedback. Best practices in training suggest that learners should receive frequent feedback on their performance (Cascio & Aguinis, 2005; Kraiger, 2003; Sitzmann, Kraiger, Stewart, & Wisher, 2006). But this convention fails to acknowledge that feedback can have a negative effect on subsequent performance (Kluger & DeNisi, 1996). Thus, we ques- tion the assumption that performance feedback is uniformly bene- T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 193ficial and propose that the effect of performance on subsequent performance and attrition is contingent upon trainees’ self-assess- ments of knowledge. Our two-study approach allows us to demonstrate both the internal and external validity of the self-assessment/actual perfor- mance interaction on subsequent performance and attrition. In Study 1, we focus on adults participating in voluntary online self- development in order to strengthen the conclusion that the results apply to work-related training. We expect that the potentially neg- ative effects of performance feedback are exacerbated in voluntary online training because trainees have tremendous discretion over their behavior—they self-select into the course so they are not required to learn the material and can leave the training environ- ment if they are dissatisfied with their learning experience. The voluntary nature of the course also ensures that there is tremendous variability in the amount of effort exerted to learn the course mate- rial. Thus, we utilize mediated moderation to examine whether the amount of time spent reviewing the course material explains the process by which trainees’ self-assessments and actual performance interact to produce changes in subsequent performance. In Study 2, we extend these findings by examining the extent to which our results are influenced by trainee conscientiousness. That is, do trainees high and low in conscientiousness differ in how they be- have after receiving performance feedback that is inconsistent with their self-assessments of knowledge? Furthermore, we examine the role of commitment to training in explaining the self-assessment/ actual performance interaction when predicting subsequent attrition. We carry out these tests in Study 2 using a controlled laboratory setting in order to enhance the internal validity of the findings. In the following sections, we review the extant literature on feedback and self-assessments, as well as their potential interac- tions. Then we present hypotheses for how trainees’ self-assess- ments and actual performance interact to influence subsequent performance and attrition from training.Effects of self-assessments and feedback in training environments Self-assessments of knowledge refer to the evaluations that people make about their current knowledge levels in a particular do- main (Sitzmann, Ely, Brown, & Bauer, 2010). Self-assessment plays an essential role in self-regulated learning, including decisions regarding which material to focus on and how much effort to exert (Bell & Federman, 2010; Carver & Scheier, 1990, 2000; Sitzmann, Ely, Brown et al., 2010). But, self-assessing one’s knowledge is cogni- tively complex (DeNisi, Cafferty, & Meglino, 1984; Dunning, Heath, & Suls, 2004). Trainees must be able to form a cognitive representation of the training domain and understand what it means to be knowl- edgeable about a topic (Campbell & Lee, 1988). They must then judge how well their knowledge meets the standard for mastering the course content. Limitations in human information processing may cause trainees to simplify the process and rely on well-developed schemas regarding their personal attributes when rating their knowledge levels (Campbell & Lee, 1988; Newell & Simon, 1972; Shore, Shore, & Thornton, 1992). As a result, trainees’ self-assess- ments are not always consistent with their actual performance. In order to increase learning and guide behavior, trainees are of- ten given feedback on their performance (Bangert-Drowns et al., 1991; Hattie & Timperley, 2007; Kluger & DeNisi, 1996). Despite the fact that feedback is expected to improve performance, there is evidence that the positivity of feedback can influence how it is received (Ilgen, Fisher, & Taylor, 1979). Generally, positive feedback is perceived to be more accurate and is more accepted than negative feedback (Halperin et al., 1976; Stone & Stone, 1985). Moreover, both feedback intervention theory (Ilgen et al., 1979; Kluger & DeNisi,1996) and self-enhancement theory (Allport, 1937; Leary, 2007; Shrauger, 1975) suggest that there may be negative repercussions if individuals are provided with performance feedback that is lower than their self-assessments of knowledge. In contrast, self-verifica- tion theory suggests that individuals prefer to confirm their self- appraisals, even if those appraisals are negative (Lecky, 1945; Swann, 1983). As such, positive feedback that is inconsistent with one’s negative self-appraisal is less beneficial than positive feedback that is consistent with one’s positive self-appraisal. Drawing from the feedback and self-assessment literatures, we propose that self-assessment moderates the relationship between trainees’ actual performance and subsequent performance and attrition. Specifically, trainees’ performance should be positively related to future performance and negatively related to future attrition, but the strength of this relationship should be contingent upon trainees’ self-assessments of knowledge. We explain the theoretical rationale for this relationship and develop hypotheses in the sections that follow.Interactive effects of performance and self-assessments Research on 360-degree feedback has demonstrated that the match between employees’ self-assessments and objective assess- ments can influence the outcomes of performance feedback. Yammarino and Atwater (1997) proposed that each time individuals complete a 360-degree performance assessment, their ratings place them in one of four categories: (1) uniformly positive ratings, indi- cating that they have high performance and high self-assessments; (2) uniformly negative ratings, indicating that they have low perfor- mance and low self-assessments; (3) overestimation, indicating that they have low performance but high self-assessments; (4) underes- timation, indicating that they have high performance but low self- assessments. Based on Yammarino and Atwater’s findings, the highest performance occurs following uniformly positive ratings, whereas the lowest performance occurs following overestimating one’s performance or uniformly negative ratings. Moderate perfor- mance occurs after employees underestimate their performance. We follow these distinctions in developing our hypotheses for the interactive effects of self-assessment and actual performance when predicting subsequent performance and attrition.Uniformly positive ratings There are several reasons to expect that high self-assessments paired with high performance should result in high performance and low attrition from the subsequent module. Although strong agreement between self-assessments and performance were once seen as universally beneficial, Dunnette (1993) noted that knowl- edge of one’s actual performance is only beneficial when individu- als are also performing well (see also Atwater & Yammarino, 1997). Kruger and Dunning (1999) proposed that trainees who perform well and know that they are performing well are likely to possess strong metacognitive skills, which enable high performance (Bell & Kozlowski, 2008; Keith & Frese, 2005; Sitzmann & Ely, 2010, 2011). Further, individuals with accurate self-assessments are not threa- tened by diagnostic performance information (Dweck, 2006), par- ticularly when their performance is high (Kwang & Swann, 2010). As a result, when individuals perform well and know that they are performing well, they are likely to use feedback to maintain high performance (Försterling & Morgenstern, 2002; Hong, Chiu, Dweck, Lin, & Wan, 1999), making them particularly successful at self-regulated learning (Kim, Chiu, & Zou, 2010). Therefore, we ex- pect that when trainees experience universally positive ratings, they will attain a high level of performance and have a low proba- bility of dropping out of training during the subsequent module. 194 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207Uniformly negative ratings Although accuracy in self-assessment signifies self-awareness, accuracy should not lead to improved performance when individuals correctly assess that their performance is poor (Yammarino & Atwater, 1997). Dunnette (1993) suggests that self-awareness is not beneficial when people know that their performance is poor. Individ- uals who are performing poorly and recognize it are often unwilling or unable to change their poor performance, even though they recognize their deficiencies (Fleenor, Smither, Atwater, Braddy, & Sturm, 2010). When individuals believe that they cannot improve their perfor- mance, negative feedback hurts their self-worth and decreases their motivation to change (Atwater, Ostroff, Yammarino, & Fleenor, 1998), resulting in taking few actions to improve (see Atwater, Roush, & Fischthal, 1995; Atwater & Yammarino, 1997; Smircich & Chesser, 1981; Yammarino & Atwater, 1997). Indeed, research on self- enhancement suggests that individuals prefer positive feedback, even if their performance is poor (Kwang & Swann, 2010). Thus, we expect that when trainees receive uniformly negative ratings, they will have low performance and high attrition from the subsequent module.Overestimating performance Trainees overestimate their performance when their self- assessments are high but their actual performance is low. Although negative feedback is generally expected to result in negative reac- tions and emotions (Cianci, Schaubroeck, & McGill, 2010; Ilies, De Pater, & Judge, 2007), it is likely to have a particularly negative ef- fect when individuals had perceived themselves as performing well (Brett & Atwater, 2001). When people overestimate their per- formance, they possess a low level of competence and their lack of awareness of it makes them less likely to change the behavior that led to poor performance (Kruger & Dunning, 1999). Unskilled indi- viduals suffer a dual burden: their incompetence causes them to perform poorly and robs them of the metacognitive skills required to realize their incompetence (Kruger & Dunning, 1999). Overesti- mations of performance are also associated with low resilience and high defensiveness (Kwan, John, Robins, & Kuang, 2008). Thus, when individuals overestimate their performance, we predict that there will be negative repercussions from informing them that they performed poorly; they will have low performance and a high probability of dropping out of the subsequent module.Underestimating performance Underestimation occurs when trainees’ self-assessments are low but their actual performance is high. Research on 360-degree feedback has provided mixed results for underestimating one’s performance—although some employees improve following positive feedback, others do not (Atwater & Brett, 2005; Atwater & Yammarino, 1997; Fleenor et al., 2010). On one hand, self-enhance- ment theory suggests that people generally prefer to receive positive feedback, regardless of their self-views, because they are motivated to increase their feelings of personal worth (Allport, 1937; Bell & Arthur, 2008; Leary, 2007; Shrauger, 1975). In contrast, meta-ana- lytic evidence suggests that people’s cognitive reactions to feedback are more favorable when they receive self-verifying information (Kwang & Swann, 2010). Underestimating can be detrimental be- cause people tend to believe feedback that is consistent with their self-assessments even when those assessments are negative (Lecky, 1945; Swann, 1987). Thus, some individuals improve after underes- timating their performance whereas others let their performance slip and, on average, the literature on 360-degree evaluations suggests that subsequent performance will be moderate following feedback (Fleenor et al., 2010). Likewise, we suggest that when indi-viduals underestimate their performance, subsequent performance and attrition will be moderate. Summary In sum, we expect that trainees’ self-assessments of knowledge will moderate the effects of their actual performance on subse- quent performance and attrition in a course that provides frequent performance feedback. When trainees receive uniformly positive ratings, their subsequent performance should be highest and attri- tion lowest, relative to when trainees underestimate, overestimate, or receive uniformly negative ratings. The lowest performance and highest attrition should be observed following either uniformly negative ratings or overestimations of performance. When trainees underestimate their performance, subsequent performance and attrition should fall in between these two extremes. H1. There will be a two-way interaction between trainees’ self- assessments of knowledge and actual performance when predict- ing performance in the subsequent module. Performance will be highest following uniformly positive ratings and lowest following overestimations of performance or uniformly negative ratings. Performance will fall between these two extremes following underestimations of performance.H2. There will be a two-way interaction between trainees’ self- assessments of knowledge and actual performance when predict- ing attrition from the subsequent module. The probability of dropping out will be lowest following uniformly positive ratings and highest following overestimations of performance or uni- formly negative ratings. Attrition will fall between these two extremes following underestimations of performance.Effort Thus far, we have argued that the effects of performance on subsequent performance will be moderated by trainees’ self- assessments in a manner consistent with research on 360-degree performance evaluations. Although there is ample theory to ex- plain this interaction, there is very little research that has isolated the explanatory mechanisms for this effect. As such, we examine why self-assessment moderates the effect of performance on sub- sequent performance. We argue that the amount of effort that trainees invest in learn- ing should explain this effect (Fig. 1). Effort refers to the amount of time that trainees devote to reviewing the training material (Sitz- mann & Ely, 2011). Specifically, we expect that when trainees achieve high performance they should invest more effort in the subsequent module than when they perform poorly. High levels of effort should then lead to improved performance (Sitzmann & Ely, 2010; Vancouver & Kendall, 2006; VandeWalle, Cron, & Slocum, 2001). Moreover, we expect the interaction between self-assessment and effort will fully mediate the self-assessment/ performance interaction on subsequent performance, such that the positive effect of effort on performance should be greater following a low than high self-assessment. Trainees should perform at a high level in the subsequent module when their self-assessments are high, and effort should have little ef- fect on performance. Trainees’ pretraining knowledge of the course topic, prior academic success, and cognitive ability are among the strongest predictors of self-assessment of knowledge (Falchikov & Boud, 1989; Jung & McCroskey, 2004; Rubin & Graham, 1988; Wright, 2000). These factors predispose trainees to have high self- assessments and perform well in training, mitigating the effect of effort on performance. In contrast, following a low self-assessment, Actual Performance Effort Actual Performance Self-Assessment of Knowledge t +1 t +1 Fig. 1. Mediated moderated model of the effects of trainees’ self-assessments of knowledge, actual performance, and effort on performance in the subsequent module. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 195effort should have a substantial effect on performance. Low self- assessments are an indicator that trainees’ performance is less than their goals (Sitzmann, Ely, Brown et al., 2010) and they must exert substantial effort to eliminate goal-performance discrepancies (Carver & Scheier, 1990, 2000). This is consistent with Fleenor et al.’s (2010) review indicating that when individuals believe they are performing at a low level but are unable or unwilling to change their behavior, they are likely to have low subsequent performance. However, trainees who exert substantial effort following low self- assessments should observe a considerable payoff in terms of high performance in the subsequent module. H3. The self-assessment/effort interaction will fully mediate the effect of the self-assessment/performance interaction on subsequent performance. Effort will have a more positive effect on performance following low than high self-assessments of knowledge.2 We tested for measurement invariance in the self-assessment measure over time using AMOS and following the procedure specified by Vandenberg and Lance (2000). We took full advantage of the time structured nature of the data and simultaneously examined the six measurement occasions. The fit indices indicated that configural invariance was a good fit for the data (v2 = 420.14, df = 362; IFI = .98; TLI = .97; CFI = .98; RMSEA = .05). Support for this model indicates that trainees were employ- ing the same conceptual frame of reference when rating the self-assessment questions across modules and it is reasonable to compare data over time. Next, we tested for metric invariance and the fit indices indicated that this model was a decent fit for the data (v2 = 487.22, df = 383; IFI = .96; TLI = .94; CFI = .96; RMSEA = .06).Method Participants Four-hundred sixteen adults were recruited online and received free training in exchange for research participation. However, 123 people dropped out before completing the first self-assessment and performance measures at the end of module 1. Thus, 293 train- ees are included in this research.1 The majority of participants were employed full- or part-time (76%), whereas 18% were unemployed, 4% were retired, and 2% were students. There was also variability in participants’ educational backgrounds: 1% had not completed high school, 11% had a high school diploma or GED, 23% had completed some college, 17% had an associate’s or technical degree, 29% had a bachelor’s degree, and 19% had a graduate or professional degree. The average age of participants was 43 years (SD = 8.8; ages ranged from 18 to 52) and 50% were female. Experimental design and procedure Advertisements for free Microsoft Excel training were posted on online community sites to recruit research participants. The adver- tisements discussed some of the topics that would be covered in the course, the length of the course, and that trainees would be re- quired to complete online surveys in exchange for free training. Participants who responded to an advertisement were sent a user- name, password, and a link to the learning management system where the course was hosted. The training consisted of a four-hour online course that was divided into six modules and covered a vari- ety of Excel functions including formulas, graphing, and macros. The instruction was text-based and included screen shots demon- strating how to perform various functions in Excel. The data used1 We ran chi-square and t-tests to examine whether trainees who completed the course differed from those who dropped out. There was not a significant difference between completers and dropouts in terms of employment status (v2(4) = 1.11), education (v2(7) = 4.63), age (t(404) = 1.22), or sex (v2(1) = 0.77).in the examples were available for trainees, and they were encour- aged to practice as the functions were demonstrated in training. Trainees were given control over the pace of instruction—they could determine the amount of time spent on each module and choose to complete the course in a single day or spread it out over several weeks. However, trainees were required to review all of the modules in a predetermined order. After finishing each module, trainees completed a multiple-choice test to assess their knowl- edge of the material and reviewed feedback that provided the correct answers to all of the test questions and explained why the answers were correct. Measures After finishing each module, trainees completed a self-assess- ment of knowledge survey, followed by an exam. Effort and attri- tion were captured by the learning management system. Self-assessment of knowledge The self-assessment of knowledge scales consisted of between four and six items per module, depending on the number of broad topics covered in the module. Trainees were asked to predict the number of test questions that they would answer correctly out of 12 on the exam that they were about to take. Trainees also self- assessed their knowledge of each of the topics covered in the module (e.g., I am knowledgeable about filtering data and I am knowledgeable about PivotTables) on a 5-point Likert scale (1 = strongly disagree to 5 = strongly agree). Principle component factor analyses for each of the modules established that trainees’ predicted performance on the exams and ratings of their knowledge of each of the topics covered in the course loaded on the same factor. This suggests that these items comprise a single scale. The self-assessment of knowledge responses were converted to a 100-point scale ranging from 0.00 to 1.00 to aid comparison with the learning measure. Reliabilities across the six modules ranged from .84 to .92.2 Actual performance A 12-item multiple-choice assessment of declarative and proce- dural knowledge was administered to trainees at the conclusion of each module. Some questions assessed trainees’ ability to recallHowever, the change in chi-square values indicated that the model fit was significantly worse than the previous model (v2 = 67.08, df = 21). This is not surprising given that the self-assessment items differed slightly across measurement occasions. Overall, these analyses revealed that changing the target of the questions resulted in measurement invariance, but the infraction was not too great to preclude an analysis of changes in trainees’ self-assessments over time. 3 We tested for a two-way interaction between self-assessment of knowledge and module when predicting performance in order to examine whether the effect of trainees’ self-assessments of knowledge on performance differed over time. The interaction was not significant (Y = .01), suggesting that the relationship between self-assessment and performance did not significantly improve as trainees progressed through the course. 196 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207factual information presented during training whereas others as- sessed trainees’ ability to recall sequences of actions for executing Excel functions or how such actions affect the appearance of an Excel spreadsheet. Attrition Data from the learning management system was used to assess attrition. Trainees received a 0 in modules that they completed and a 1 in the module if they dropped out. Effort Effort reflected the number of hours that trainees spent review- ing the course material. Time spent reviewing the material in each module was captured by the learning management system. Data analysis Hierarchical linear modeling with full maximum likelihood esti- mates was used to analyze the within-subject results for perfor- mance and effort, whereas hierarchical generalized linear modeling was used to analyze the within-subject results for attri- tion. Both analysis techniques account for the nonindependence that arises from having trainees contribute multiple data points over time. The data comprises two levels. Level 1 captures the var- iance within-trainees and consists of the repeated, within-individ- ual measures of self-assessment of knowledge, performance, and effort. Level 2 captures the variance between-trainees or the differ- ence in the effects across trainees. A distinguishing feature of the analysis techniques is hierarchical linear modeling assumes the random effects are normally distributed, which is a widely applica- ble assumption when the outcome variable is continuous (Rauden- bush, Bryk, Cheong, Congdon, & du Toit, 2004). However, the assumption of normality is not realistic with binary outcomes, leading to the use of hierarchical generalized linear modeling when predicting attrition. We followed the model building procedure specified by Bliese and Ployhart (2002) when predicting performance and effort. The first step involved running the unconditional means (null) model to examine the variance in the outcomes before accounting for any predictors. This model allowed for the calculation of an intra- class correlation coefficient (ICC), which partitions the variance into within- and between-subjects components. The ICC for perfor- mance was .42, indicating that 42% of the variance was due to be- tween-subjects differences and 58% was due to within-subject variability over time. The ICC for effort was .28, indicating that 28% of the variance was due to between-subjects differences and 72% was due to within-subject variability over time. Next, we added module as a covariate because time dependent analyses can be sensitive to order effects (Vancouver & Kendall, 2006). We also determined the variability in the growth parameters. Including a random effect for module significantly improve the model fit when predicting performance (Dv2 = 8.1) but not effort (Dv2 = 0); thus, a random effect for module was only included in the model when predicting performance. We also specified alterna- tive error structures while testing for improvements in model fit to account for potential autocorrelation and non-independence among observations. The error structure of the baseline model was com- pared against first-order autoregressive, autoregressive and hetero- geneous, and unstructured error structures. We used the change in deviance statistics to decide which error structure provided the best fit for the data and chose autoregressive and heterogeneous when predicting performance and effort (Dv2 = 18.9, 104.8, respectively, p < .05). All of the predictors, except for module, were grand mean cen- tered. Module was centered such that the intercept represents scores at module one. Due to the directional nature of the hypoth-eses and reduced statistical power caused by the high attrition rate, we interpreted significance at the p < .10 level. Consistent with the recommendation of Cohen, Cohen, West, and Aiken (2003), we used the significance values from the Type III sums of squares when interpreting main effects. However, we used the sig- nificance values from the Type I sums of squares when interpreting interactions. The Type I significance values permit an examination of the unique contribution of the interaction terms over the main effects in the model.Results Descriptive statistics and correlations among study measures are presented in Table 1. Self-assessment of knowledge was posi- tively correlated with actual performance at the within- and be- tween-subjects levels of analysis (r = .19, .34, respectively, p < .05). Trainees who dropped out had higher self-assessments of knowledge (r = .16, p < .05). Trainees’ self-assessments of knowl- edge decreased over time from modules one (M, SD = 0.80, .13) through five (M, SD = 0.66, .20) and then increased again at module six (M, SD = 0.73, .18); trainees’ actual performance decreased over time from modules one (M, SD = 0.72, .17) through four (M, SD = 0.59, .22) and then increased toward the end of the course.3 This is likely due to differences in the difficulty of the course material across training modules. The vast majority of trainees dropped out before completing all six modules. One third of trainees (N = 123) dropped out before making it to the end of the first module. These trainees were not included in this report because they dropped out before complet- ing the first self-assessment and performance measures. An addi- tional 110 trainees dropped out in module two, 39 dropped out in module three, 27 dropped out in module four, 15 dropped out in module five, and 2 dropped out in module six. Thus, 100 (24%) trainees who started the voluntary online Microsoft Excel course also completed the course. Next we tested Hypothesis 1—there will be a two-way interac- tion between trainees’ self-assessments of knowledge and actual performance when predicting performance in the subsequent module. Subsequent performance will be highest when trainees have uniformly positive ratings, lowest when trainees overesti- mate their performance or have uniformly negative ratings, and fall between these two extremes when trainees underestimate their performance. Trainees’ self-assessments of knowledge and actual performance had positive effects on performance in the sub- sequent module, Y = 0.18, 0.35, respectively, p < .05 (see Table 2). There was also a significant two-way interaction between trainees’ self-assessments and their actual performance (see Fig. 2), Y = 0.47. In order to interpret the interaction, we compared train- ees’ self-assessments and actual performance when they scored one standard deviation above and below the mean. Consistent with Hypothesis 1, performance in the subsequent module was highest when trainees had uniformly positive ratings, followed by when trainees underestimated their performance, overestimated their performance, and had uniformly negative ratings, respectively. Hypothesis 2 predicted that the probability of dropping out of the subsequent module will be lowest when trainees have uni- formly positive ratings, moderate when trainees underestimate their performance, and highest when trainees overestimate their performance or have uniformly negative ratings. The results sug- Table 1 Descriptive statistics and correlations among study variables at the within- and between-subjects levels of analysis for Study 1. Variable M1 M2 M3 M4 M5 M6 1 2 3 4 1. Self-assessment of knowledge 0.80 (0.13) 0.77 (0.13) 0.71 (0.16) 0.70 (0.18) 0.66 (0.20) 0.73 (0.18) – .19* – .24* 2. Performance 0.72 (0.17) 0.66 (0.17) 0.67 (0.17) 0.59 (0.22) 0.72 (0.21) 0.70 (0.21) .34* – – .11* 3. Attrition 0.30 (0.46) 0.38 (0.49) 0.21 (0.41) 0.19 (0.39) 0.13 (0.34) 0.02 (0.14) .16* .06 – – 4. Effort 0.42 (0.43) 1.07 (0.81) 0.73 (0.52) 0.86 (0.69) 0.60 (0.46) 0.45 (0.35) .03 .17* .11 – Note: Columns M1 through M6 report the mean (first number) and standard deviation (in parentheses) for self-assessment, performance, attrition, and effort for modules one through six. For attrition, the number represents the percent of trainees who started but did not complete the module. Between-subjects correlations are below the diagonal and within-subject correlations are above the diagonal. For the between-subjects correlations, attrition is coded such that 0 indicates that trainees completed the course and 1 indicates that trainees withdrew from the course. * p < .05. Table 2 Results examining the effects of trainees’ self-assessments of knowledge and actual performance on performance, attrition, and effort in the subsequent module for Study 1. Hypothesis 1 Hypothesis 2 Hypothesis 3 Hypothesis 3 Performance (subsequent module)a Performance (subsequent module)b Attrition (subsequent module)a Attrition (subsequent module)b Effort (subsequent module)a Performance (subsequent module)b Intercept 0.63* (0.01) 0.63* (0.01) 0.58* (0.12) 0.54* (0.12) 0.93* (0.04) 0.61* (0.01) Module 0.02* (0.00) 0.02* (0.00) 0.61* (0.09) 0.61* (0.09) 0.11* (0.01) 0.03* (0.00) Self-assessment of knowledge 0.18* (0.05) 0.16* (0.05) 0.08 (0.65) 0.34 (0.67) 0.41* (0.16) 0.18* (0.05) Performance 0.35* (0.04) 0.37* (0.04) 2.15* (0.52) 2.19* (0.52) 0.21 ** (0.12) 0.36* (0.04) Effort (in subsequent module) 0.04* (0.01) Self-assessment of knowledge  Performance 0.47* (0.21) 5.55** (3.21) 0.23 (0.22) Effort  Self-assessment of knowledge 0.24* (0.07) Note: Hierarchical linear modeling was used to predict performance and effort; for these results, the top number is the fixed effect and the bottom number is the standard error. Hierarchical generalized linear modeling was used to predict attrition; for these results, the top number is the logit and the bottom number is the standard error. Attrition was coded such that 0 indicates that trainees completed the module and 1 indicates that trainees dropped out in the module. * p < .05. ** p < .10. a Analyses with main effects. b Analyses with main effects and interactions. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 197gest that actual performance had a negative effect on subsequent attrition, logit = 2.15, p < .05. The probability of dropping out of training was 10% points greater following low than high perfor- mance. There was also a significant two-way interaction between trainees’ self-assessments of knowledge and actual performance (see Fig. 3), logit = 5.55. Supporting Hypothesis 2, the probability of dropping out of the subsequent module was greatest when trainees overestimated their performance, followed by when they had uniformly negative ratings, underestimated their performance, and had uniformly positive ratings, respectively.4 Finally, we tested Hypothesis 3—the self-assessment/effort interaction will fully mediate the effect of the self-assessment/per- formance interaction on subsequent performance, such that effort will have a more positive effect on performance following low than high self-assessments of knowledge. We followed the steps for testing for mediated moderation outlined by Muller, Judd, and Yzerbyt (2005). Three conditions must be met to establish medi- ated moderation. First, self-assessment and actual performance must interact when predicting performance in the subsequent module. This interaction was established in support of Hypothesis 1. Second, performance must have a significant main effect on effort in the subsequent module. Performance had a significant, positive effect on subsequent effort (Y = 0.21), such that trainees spent 4.81 more minutes reviewing following high than low per- formance. Third, self-assessment must interact with subsequent4 We ran post hoc analyses to examine whether the implications of a misfit between trainees’ self-assessments and actual performance differed over time. The three-way interaction between self-assessment, performance, and module was not significant when predicting either performance or attrition from the subsequent module, Y = 0.16, logit = 0.95.effort when predicting performance and the self-assessment/ performance interaction must be reduced in magnitude to estab- lish partial mediated moderation or be non-significant to establish full mediated moderation. Effort significantly interacted with trainees’ self-assessments of knowledge (Y = 0.24), such that ef- fort had a more positive effect on performance when trainees’ self-assessments were low rather than high in the previous module (see Fig. 4). Furthermore, the self-assessment/actual performance interaction was reduced in magnitude (Y = 0.23; formerly Y = 0.47) and was no longer significant when the self-assess- ment/effort interaction was added to the equation. Thus, the re- sults support Hypothesis 3 and suggest that the self-assessment/ effort interaction fully mediated the self-assessment/performance interaction on subsequent performance. Following a high self- assessment, trainees performed well regardless of the amount of effort devoted to learning. Following a low self-assessment, effort had a strong, positive effect on performance.Discussion Providing extensive feedback is considered a best practice in training because it leads to positive behavior change (Cascio & Aguinis, 2005; Kraiger, 2003; Sitzmann et al., 2006). However, trainees’ behavior after receiving feedback is not as straight for- ward as previously presumed. Rather, trainees’ performance is pos- itively related to future performance and negatively related to future attrition, but the strength of this relationship is contingent upon trainees’ self-assessments of knowledge. Corroborating our prediction, performance was highest after uniformly positive rat- ings, followed by underestimation, overestimation, and uniformly Fig. 2. Graph of the interaction between self-assessment of knowledge and actual performance when predicting performance in the subsequent module in Study 1. Fig. 3. Graph of the interaction between self-assessment of knowledge and actual performance when predicting attrition from the subsequent module in Study 1. Fig. 4. Graph of the interaction between self-assessment of knowledge and effort in the subsequent module when predicting performance in Study 1. 198 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207negative ratings, respectively. Attrition was lowest after uniformly positive ratings, followed by underestimation, uniformly negative ratings, and overestimation, respectively. The self-assessment by effort interaction fully explained the process by which self-assessment and performance interact to influence subsequent performance. Trainees’ self-assessments of knowledge and actual performance both had main effects on effort in the subsequent module, such that trainees spent more time reviewing when they self-assessed favorably and performed at a high level. Moreover, the effect of trainees’ self-assessments on subsequent performance was influenced by the level of effort thatthey devoted to training after receiving feedback on their perfor- mance. Following a high self-assessment, trainees performed at a high level in the subsequent module regardless of the amount of effort devoted to learning. This is consistent with research demon- strating that pretraining knowledge of the course topic, prior aca- demic success, and cognitive ability predispose trainees to have high self-assessments and high performance (Jung & McCroskey, 2004; Ree, Carretta, & Teachout, 1995; Rubin & Graham, 1988; Wright, 2000), mitigating the effect of effort on performance. In contrast, following low self-assessments of knowledge, effort had a strong, positive effect on performance. This is consistent with control theory’s assertion that individuals must exert considerable effort following low self-assessments if they are going to improve their performance over time (Carver & Scheier, 1990, 2000).Study 2 In Study 1, we found that self-assessment interacted with actual performance to influence subsequent performance and attrition. In Study 2, we extend these findings and examine whether the self- assessment/performance interaction differs for trainees high and low in conscientiousness and whether adding commitment to the model will explain the self-assessment/performance interaction on subsequent attrition (see Fig. 5). As Cianci, Klein, and Seijts (2010) note, it is important to understand the individual differences that impact how people behave following performance feedback. Among personality variables, conscientiousness has the strongest and most consistent effect on performance (Barrick & Mount, 1991) and has been shown to impact performance following feed- back (Cianci, Klein et al., 2010). As such, we build on past research by examining the role of conscientiousness in understanding the interaction between self-assessment and performance. In addition, we test a mediated moderated model for attrition and propose that commitment to training explains the self-assess- ment/actual performance interaction when predicting subsequent attrition and seek to replicate the mediated moderation effect of effort when predicting subsequent performance. Commitment is a strong predictor of attrition from training (Bean & Metzner, 1985; Robbins et al., 2004; Sitzmann, in press; Tinto, 1975), and is likely to determine whether trainees drop out following low self-assessments. Finally, although relying on work-related train- ing enhanced the external validity of the findings in Study 1, we seek to balance that with greater internal validity by using a labo- ratory setting in Study 2.Conscientiousness Conscientiousness may affect how self-assessment and perfor- mance interact to predict subsequent performance and attrition. Conscientiousness is a personality trait associated with being dependable, careful, thorough, responsible, disciplined, organized, hardworking, persevering, and achievement-oriented (Barrick & Mount, 1991; Digman, 1990). Trainees high in conscientiousness are more motivated to learn training material (Colquitt, LePine, & Noe, 2000) and work harder and persist longer than trainees low in conscientiousness (Barrick, Mount, & Strauss, 1993). Based on situation strength theory (Mischel, 1977), we suggest that consci- entiousness should affect subsequent behavior following underes- timations and overestimations of performance, but not following uniformly positive and uniformly negative ratings. Uniformly positive and uniformly negative ratings represent strong situations, which Mischel (1977) describes as situations that most individuals interpret the same way, because there is no ambi- guity regarding trainees’ performance when their self-assessments are consistent with their actual performance. Strong situations Attrition Commitment to Training Actual Performance Self-Assessment of Knowledge t +1 t +1 Conscientiousness Fig. 5. Mediated moderation model of the effects of trainees’ self-assessments of knowledge, actual performance, commitment to training, and conscientiousness on attrition from the subsequent module. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 199mask the effect of personality on behavior (Haaland & Christiansen, 2002), so our predictions for those high and low in conscientious- ness are the same as Study 1—uniformly positive ratings should result in high subsequent performance and low subsequent attrition, whereas uniformly negative ratings should result in low subsequent performance and high subsequent attrition. In contrast, the appropriate response is ambiguous when the situation is weak (Mischel, 1977), such as when trainees’ self- assessments of knowledge are inconsistent with their performance. Thus, trainees high and low in conscientiousness may diverge in how much they learn and whether they drop out of training following underestimations and overestimations of performance. Meta-analytic evidence suggests that people’s cognitive reactions to feedback are more negative when they receive information that is inconsistent with their self-appraisals (Kwang & Swann, 2010). This negative reaction may result in low conscientious trainees dropping out. However, high conscientious trainees have a tendency to follow through on their obligations (Barrick, Stewart, & Piotrow- ski, 2002). This predisposition should result in high conscientious trainees having a lower probability of dropping out of training fol- lowing underestimations and overestimations of performance than low conscientious trainees. The fact that high conscientious individuals are particularly achievement-oriented may cause them to experience substantial tension and cognitive interference when their performance is inconsistent with their self-assessments, negatively impacting subsequent performance. Cianci, Klein et al. (2010) demonstrated that conscientious individuals experienced a lot of tension as a result of negative feedback and tension leads to lower levels of per- formance. Thus, overestimation should result in lower subsequent performance for trainees high than low in conscientiousness. Con- scientious trainees may also experience cognitive interference when they underestimate their performance (Kwang & Swann, 2010) as they attempt to decipher why feedback was inconsistent with their self-assessments. Cognitive interference, in turn, sub- stantially impairs performance (Kanfer & Ackerman, 1996; Sitz- mann & Ely, 2011). Thus, high conscientious trainees should perform at a lower level than low conscientious trainees following underestimations or overestimations of performance. In summary, our predictions for uniformly positive and uni- formly negative ratings are the same as Study 1. Regardless of trainee conscientiousness, performance will be high and attrition low following uniformly positive ratings and performance will be low and attrition high following uniformly negative ratings. Fol- lowing underestimations and overestimations of performance, high conscientious trainees should have lower attrition and worse performance than low conscientious trainees. H4. There will be a three-way interaction between conscientious- ness, self-assessment of knowledge, and actual performance when predicting performance in the subsequent module. For traineeshigh and low in conscientiousness, performance will be high following uniformly positive ratings and low following uniformly negative ratings. Underestimating and overestimating perfor- mance will result in lower subsequent performance for trainees high than low in conscientious.H5. There will be a three-way interaction between conscientious- ness, self-assessment of knowledge, and actual performance when predicting attrition from the subsequent module. For trainees high and low in conscientiousness, the probability of dropping out will be low following uniformly positive ratings and high following uni- formly negative ratings. Underestimating and overestimating per- formance will result in lower subsequent attrition for trainees high than low in conscientious.Commitment to Training Goal commitment refers to one’s dedication to reaching a goal (Locke & Latham, 1990), whereas training commitment refers to the determination to complete a training course. We expect that an interaction between trainees’ self-assessments and commitment to training may explain the conscientiousness/self-assessment/per- formance interaction on subsequent attrition (see Fig. 5). Perfor- mance should be positively related to commitment, such that trainees who perform well will be more committed to training (Locke, Frederick, Lee, & Bobko, 1984). Furthermore, commitment should have a negative effect on attrition from the subsequent mod- ule, based on evidence that commitment predicts attrition from col- lege and work-related training (Bean & Metzner, 1985; Robbins et al., 2004; Sitzmann, in press; Tinto, 1975). We also expect that the effect of commitment on subsequent attrition will be moderated by trainees’ self-assessments and this effect will fully mediate the conscientiousness/self-assessment/performance interaction. We rely on control theory to explain why the effect of commit- ment on subsequent attrition should be contingent upon trainees’ self-assessments. Commitment should have a more negative effect on subsequent attrition when trainees’ self-assessments are low than high. Control theory suggests that individuals periodically monitor their performance to determine whether they are making adequate goal progress (Carver & Scheier, 1990). High self-assess- ments indicate that trainees are on track to achieve their goals (Sitzmann, Ely, Brown et al., 2010). If their progress is adequate, trainees are likely to continue goal pursuit uninterrupted and com- mitment to training should only have a weak effect on attrition. In contrast, low self-assessments indicate that trainees are not on track to achieve their goals (Sitzmann, Ely, Brown et al., 2010). When goal progress is inadequate, individuals rely on a variety of factors—including their goal commitment—to decide whether to continue goal pursuit (Carver & Scheier, 1990). Thus, trainees must be highly committed if they are going to continue to pursue the 200 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207goal of successfully completing the course. As a result, when train- ees’ self-assessments are low, commitment should have a strong effect on attrition from the subsequent module. H6. The self-assessment/commitment interaction will fully medi- ate the relationship between the conscientiousness/self-assess- ment/performance interaction and subsequent attrition. Commitment will have a more negative effect on attrition follow- ing low than high self-assessments of knowledge.5 We tested for a two-way interaction between self-assessment of knowledge and module when predicting performance in order to examine whether the effect of trainees’ self-assessments of knowledge on performance differed over time. The interaction was not significant (Y = 0.06), suggesting that the relationship between self-assessment and performance did not significantly change as trainees progressed through the course.Method Participants College students at a public urban university near the Rocky Mountains were recruited from a variety of business and psychol- ogy courses. Two-hundred and fifty-three students participated; 47% were male and 53% were female. The average age of partici- pants was 27 years (SD = 7.8; ages ranged from 19 to 66). Thirty- eight percent of participants indicated that this was their first online course; 16% had participated in one previous online course; 14%—two previous courses; 6%—three previous courses; 26%—four or more previous courses. Experimental Design and Procedure Participants either received course credit or extra credit for par- ticipating in a two-hour laboratory experiment. When they arrived at the experiment, they were assigned a computer and given a link to the learning management system that hosted the Microsoft Excel course. The training was divided into four modules that covered formulas, graphing, pivot tables, and macros, and utilized a similar format as the course in Study 1, although fewer topics were covered. Before proceeding to the next module, trainees viewed a message indicating that, ‘‘This study is designed to assess the characteristics of training that cause people drop out. You should feel free to drop out at any time if you feel you are not benefitting from the course. If you choose to drop out, you will still receive full credit for your participation.’’ Participants were given the option of studying or surfing the internet until the two-hour time requirement for the experiment lapsed. Measures Conscientiousness was measured pretraining. After finishing each module, trainees completed a measure of their self-assess- ment of knowledge, followed by a performance measure. They then received feedback on their exam performance and completed a measure of their commitment to training. In addition, effort and attrition were captured by the learning management system in the same manner as Study 1. Conscientiousness. Saucier’s (1994) Mini-Markers scale, con- sisting of 8 adjectives (e.g., efficient, systematic), was used to as- sess conscientiousness. Trainees indicated on a 5-point Likert scale how accurately or inaccurately each adjective described them. The coefficient alpha reliability was .79. Self-assessment of knowledge Self-assessment of knowledge was assessed with four items. Trainees rated their ‘‘level of competence with regards to the mate- rial taught in the previous module’’ (1 = not at all competent to 5 = very competent) and indicated whether they were ‘‘capable of performing the skills that were just demonstrated in this module’’ (1 = strongly disagree to 5 = strongly agree) on 5-point Likert scales. They also indicated how knowledgeable they are about the topic(e.g., formulas, macros) that was just covered (1 = not at all to 5 = very) and predicted how many multiple-choice items out of six they believed they would answer correctly regarding the Excel module they just completed. The self-assessment of knowledge responses were converted to a 100-point scale ranging from 0.00 to 1.00 to aid comparison with the performance measure. Reliabilities across the four modules ranged from .85 to .90. Performance A 6-item multiple-choice test was administered to trainees at the end of each module. The exam assessed trainees’ ability to remember the factual information presented during training and trainees’ memory of the steps required to perform the procedures that were demonstrated. Commitment to training Commitment to training was assessed with three items adapted from Klein, Molloy, and Brinsfield’s (in press) measure of commit- ment to workplace activities. Trainees responded to the items (e.g., I am committed to finishing this course and I care whether I finish the entire course) on a 5-point Likert scale ranging from strongly disagree to strongly agree. Reliabilities across the four modules ranged from .92 to .95. Pretraining knowledge of Excel Pretraining knowledge of Excel was included as a control vari- able in the analyses because previous research has demonstrated it is a strong predictor of success in online training (Sitzmann, Ely, Bell, & Bauer, 2010). Familiarity with the topic was measured with three items (e.g., How knowledgeable are you about Microsoft Excel? and How many classes have taken in which you learned or actively used Microsoft Excel?). The reliability was .76. Data analysis Similar to Study 1, hierarchical linear modeling was used to pre- dict the continuous outcomes, whereas hierarchical generalized linear modeling was used to predict attrition. The ICCs were .35 for performance, .46 for effort, and .75 for commitment to training. In order to limit the Type I error rate, main effects were interpreted at the p < .05 level. However, Snijders and Bosker (1999) suggest that the power to detect cross-level interactions in multilevel re- search is low because of reduced parameter reliabilities. Thus, con- sistent with previous research (Yeo & Neal, 2004, 2006, 2008), we set the criterion for interactions at the p < .10 level. Results Descriptive statistics and correlations among study measures are presented in Table 3. Self-assessment of knowledge was posi- tively correlated with actual performance at the within- and be- tween-subjects levels of analysis (r = .36, .44, respectively, p < .05).5 Attrition was much lower in Study 2, such that 79.4% (N = 201) of trainees completed the course. Of the 52 trainees who dropped out, 13 dropped out in module 1, 17 in module 2, 14 in module 3, and 8 in module 4. We began by replicating the mediating role of effort in understanding the self-assessment/performance interaction when predicting subsequent performance (Hypothesis 3). Consistent Table 3 Descriptive statistics and correlations among study variables at the within- and between-subjects levels of analysis for Study 2. Variable M1 M2 M3 M4 1 2 3 4 5 6 7 1. Pretraining knowledge of Excel 2.40 (0.77) – – – – – – – – – – 2. Conscientiousness 4.10 (0.50) – – – .21* – – – – – – 3. Self-assessment of knowledge 3.85 (0.77) 3.65 (0.78) 3.08 (0.90) 3.14 (0.98) .44* .13* – .36* – .28* .25* 4. Performance 0.74 (0.21) 0.59 (0.21) 0.50 (0.23) 0.70 (0.26) .18* .08 .44* – – .23* .27* 5. Attrition 0.05 (0.22) 0.07 (0.26) 0.06 (0.24) 0.04 (0.19) .15* .05 .01 .13* – – – 6. Effort 0.29 (0.18) 0.20 (0.14) 0.18 (0.13) 0.13 (0.10) .17* .04 .14* .12 .26* – .14* 7. Commitment to training 3.77 (0.84) 3.66 (0.87) 3.65 (0.87) 3.85 (0.86) .10 .07 .28* .30* .38* .17* – Note: Columns M1 through M4 report the mean (first number) and standard deviation (in parentheses) for self-assessment, performance, attrition, effort, and commitment for modules one through four. For the individual differences, the overall mean and standard deviation are reported in column M1. For attrition, the number represents the percent of trainees who started but did not complete the module. Between-subjects correlations are below the diagonal and within-subject correlations are above the diagonal. For the between-subjects correlations, attrition is coded such that 0 indicates that trainees completed the course and 1 indicates that trainees withdrew from the course. * p < .05. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 201with Study 1, performance had a positive effect on effort in the subsequent module (Y = 0.06, p < .05; see Table 4). However, the effort by self-assessment interaction was not significant when pre- dicting performance, failing to support Hypothesis 3. Next, we tested Hypothesis 4—there will be a three-way inter- action between conscientiousness, self-assessment of knowledge, and actual performance when predicting performance in the subsequent module. The interaction was significant (Y = 0.70). Consistent with Hypothesis 4, for trainees high and low in consci- entiousness, performance was highest following uniformly positive ratings and lowest following uniformly negative ratings (see Fig. 6). However, performance was 5% points less in the subsequent module following underestimations or overestimations of perfor- mance for trainees high than low in conscientious. Hypothesis 5 predicted a three-way interaction between consci- entiousness, self-assessment of knowledge, and actual perfor- mance when predicting attrition in the subsequent module. Consistent with the hypothesis, the three-way interaction was sig- nificant (logit = 12.81; see Fig. 7). For trainees high and low in con- scientiousness, the probability of dropping out was low following uniformly positive ratings and high following uniformly negative ratings. Underestimating and overestimating performance resulted in lower subsequent attrition for trainees high than low in consci- entious. Thus, the results support Hypothesis 5.6 Finally, we tested Hypothesis 6—the self-assessment/com- mitment to training interaction will fully mediate the effect of the conscientiousness/self-assessment/performance interaction on subsequent attrition; commitment will have a more negative effect on attrition following low than high self-assessments of knowledge. We followed the steps for testing for mediated moder- ation outlined by Muller et al. (2005). As demonstrated in support of Hypothesis 5, conscientiousness, self-assessment, and perfor- mance interacted when predicting attrition from the subsequent module, logit = 12.81. Furthermore, trainees’ performance in the course predicted commitment to training (Y = 0.44; p < .05). Final- ly, self-assessment interacted with commitment when predicting attrition from the subsequent module (logit = 3.42; p < .05), and the conscientiousness/self-assessment/performance interaction was no longer significant, logit = 8.63. Commitment to training had a more negative effect on the probability of dropping out of the subsequent module when trainees’ self-assessments of knowl- edge were low than high (see Fig. 8), supporting the sixth hypothesis.6 We ran post hoc analyses to examine whether the implications of a misfit between trainees’ self-assessments and actual performance differed over time. The results indicate that the three-way interaction between self-assessment, perfor- mance, and module was not significant when predicting either performance or attrition from the subsequent module, Y = 0.16, logit = 2.08.Discussion Study 2 extended the findings from Study 1 in two key areas. First, we demonstrated that the self-assessment/performance interaction differs for trainees high and low in conscientiousness. In particular, overestimating and underestimating one’s perfor- mance increased subsequent attrition to a greater extent for train- ees low in conscientiousness but impaired subsequent performance to a greater extent for trainees high in conscientious- ness. Second, we demonstrated that the self-assessment by com- mitment interaction fully mediated the three-way interaction between conscientiousness, self-assessment, and performance when predicting subsequent attrition from training. Commitment had a more negative effect on subsequent attrition when trainees’ self-assessments were low than high. We will elaborate on these findings and explain their theoretical and practical implications in the following general discussion section.General discussion Best practices in training suggest that trainees should receive performance feedback on a regular basis throughout a learning experience because feedback leads to positive behavior change (Kraiger, 2003; Sitzmann et al., 2006). This ignores the fact that Kluger and DeNisi’s (1996) meta-analysis on feedback interven- tions demonstrated that feedback has a negative effect on perfor- mance in up to a third of cases. Moreover, Atwater and colleagues (2000) found only 50% of managers showed improve- ment following feedback. The current research demonstrates that the effects of trainees’ performance on subsequent performance and attrition are moderated by trainees’ self-assessments of knowledge in courses that provided frequent performance feed- back. Thus, the effect of performance on subsequent behavior is not as straightforward as best practices recommending frequent performance feedback would lead us to believe. This research contributes to our theoretical understanding of the effects of performance feedback by clarifying that trainees’ self-appraisals are an essential moderator of the effects of perfor- mance on subsequent behavior. This interaction supports self- verification and self-enhancement theories and moves beyond existing research in the performance appraisal domain to reveal the utility of these theories in understanding behavior in voluntary online training. Further, little research has been conducted to iso- late the mechanisms regarding why self-assessments moderate performance effects. As such, we demonstrate that the amount of effort exerted explains the process by which trainees’ self-assess- ments and actual performance interact to produce changes in sub- sequent performance, and commitment to training explains the effect of this interaction on subsequent attrition. Finally, we reveal Table 4 Results Examining the Effects of Trainees’ Self-Assessments of Knowledge, Conscientiousness, and Actual Performance on Commitment to Training, Performance, Effort, and Attrition in the Subsequent Module for Study 2. Hypothesis 3 Hypotheses 3 and 4 Hypothesis 5 Hypothesis 6 Hypothesis 6 Performance (subsequent module)a Effort (subsequent module)a Performance (subsequent module)b Attrition (subsequent module)a Attrition (subsequent module)b Commitment to traininga Attrition (subsequent module)b Intercept 0.46* (0.01) 0.19* (0.01) 0.46* (0.01) 2.33* (0.24) 2.32* (0.25) 3.65* (0.06) 3.06* (0.35) Module 0.13* (0.01) 0.02* (0.01) 0.13* (0.01) 0.70* (0.24) 0.75* (0.25) 0.00 (0.03) 0.73* (0.30) Excel 0.02 (0.01) 0.03* (0.01) 0.02 (0.01) 0.11 (0.26) 0.14 (0.26) 0.01 (0.07) 0.28 (0.29) Conscientiousness 0.01 (0.02) 0.01 (0.01) 0.02 (0.02) 0.02 (0.36) 0.15 (0.38) 0.03 (0.10) 0.19 (0.46) Self-assessment of knowledge 0.18* (0.06) 0.12* (0.04) 0.16* (0.06) 1.44 (1.18) 1.76 (1.30) 0.73* (0.20) 2.36 (1.81) Performance 0.51* (0.04) 0.06* (0.02) 0.50* (0.04) 2.56* (0.80) 2.74* (0.85) 0.44* (0.11) 2.39* (1.04) Effort (in subsequent module) 0.10 (0.07) Commitment to training 1.28* (0.24) Conscientiousness  Self- assessment of knowledge 0.08 (0.10) 0.69 (2.20) 2.26 (2.68) Conscientiousness  Performance 0.03 (0.07) 0.51 (1.52) 0.09 (1.86) Self-assessment of knowledge  Performance 0.18 (0.22) 2.12 (4.43) 3.41 (5.43) Effort  Self-assessment of Knowledge 0.25 (0.38) Commitment  Self-assessment of knowledge 3.42* (1.35) Conscientiousness  Self- assessment of knowledge  Performance 0.70** (0.38) 12.81** (7.69) 8.63 (10.04) Note: Hierarchical linear modeling was used to predict performance, effort, and commitment to training; for these results, the top number is the fixed effect and the bottom number is the standard error. Hierarchical generalized linear modeling was used to predict attrition; for these results, the top number is the logit and the bottom number is the standard error. Attrition was coded such that 0 indicates that trainees completed the module and 1 indicates that trainees dropped out in the module. * p < .05. ** p < .10. a Analyses with main effects. b Analyses with main effects and interactions. 202 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207that trainee conscientiousness plays an essential role in determin- ing how trainees behave after receiving performance feedback that is inconsistent with their self-assessments of knowledge. Each of these theoretical contributions and their implications will be elab- orated upon in the subsequent section. Theoretical Contributions and Their Implications Fig. 9 summarizes the results of Studies 1 and 2. The results re- veal that after receiving feedback, trainees’ performance starts off a complex decision making process during which trainees decide whether they are willing to exert effort in training and if they are committed to the course. These decisions determine trainees’ performance in the subsequent module and the likelihood of drop- ping out of training. Ultimately, this decision making process is af- fected by whether trainees’ self-assessments of knowledge suggests that they are learning a lot during training or failing to grasp the course material. When trainees perform at a high level, it sets off a positive cycle by which they continue to perform at a high level and have a lower probability of dropping out of the subsequent module. Further- more, they choose to exert effort in the subsequent module, which results in high performance regardless of whether trainees’ self- assessments are high or low. High performance also increases trainees’ commitment to the course, and commitment has a direct effect on subsequent attrition. Especially when trainees underesti- mate their performance, they rely on their commitment to the course to decide whether to drop out or remain in training. If their commitment is strong, they are likely to complete the subsequent module; if their commitment is weak, they are likely to drop out. Our model of the effects of uniformly positive ratings and underestimations of performance are consistent with our under- standing of human behavior based on the 360-degree feedback lit- erature. Let us start with uniformly positive ratings. Individualswith accurate self-assessments are not threatened by diagnostic performance information (Dweck, 2006), particularly when their performance is high (Kwang & Swann, 2010). As a result, following uniformly positive ratings, employees use feedback to maintain a high level of performance (Försterling & Morgenstern, 2002; Hong et al., 1999), making them particularly successful at self-regulated learning (Kim et al., 2010). Underestimating performance had a negligible detrimental ef- fect on subsequent performance but increased the probability of dropping out, relative to uniformly positive ratings. Underestimat- ing performance represents a weak situation according to situation strength theory (Mischel, 1977); when performance feedback is inconsistent with trainees’ appraisals of their knowledge, the appropriate response is unclear. At this point, trainees’ commit- ment to the course had an especially potent effect on the decision to remain in training or drop out. Research on 360-degree feedback has generally provided mixed results for underestimating one’s performance—although some show improvement following posi- tive feedback, others do not (Atwater & Brett, 2005; Atwater & Yammarino, 1997; Fleenor et al., 2010). The current results indi- cate that employees’ commitment to their goals must be taken into account to understand the decision making process by which underestimation affects future behavior. Employees must be highly committed to continue goal pursuit following underestima- tions of performance. Now let us turn to trainees’ behavior following low performance (see Fig. 9). When trainees perform at a low level, it sets off a downward spiral—performance is lower and attrition is higher from the subsequent module, relative to when trainees perform at a high level in the previous module. Subsequent performance is even worse if trainees’ self-assessments are consistent with their poor performance—revealing uniformly negative ratings. Similarly, the performance appraisal literature has found that self-awareness is not beneficial if people are aware of their poor performance Fig. 6. Graph of the interaction between conscientiousness, self-assessment of knowledge, and actual performance when predicting performance in the subse- quent module in Study 2. Fig. 7. Graph of the interaction between conscientiousness, self-assessment of knowledge, and actual performance when predicting attrition from the subsequent module in Study 2. Fig. 8. Graph of the interaction between self-assessment of knowledge and commitment to training when predicting attrition from the subsequent module in Study 2. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 203(Dunnette, 1993). People are typically unwilling or unable to change their poor performance, especially when they are aware of their deficiencies (Fleenor et al., 2010). Furthermore, the self- awareness that one is performing poorly is related to low motiva- tion to change (Atwater et al., 1998). However, continuing to perform at a low level is not inevita- ble—trainees recovered from poor performance and performed at a high level in the subsequent module if they exerted more effort, and exerting effort was especially important following a low self- assessment of knowledge. A low self-assessment indicates that trainees’ performance is less than their training goals (Sitzmann, Ely, Brown et al., 2010), and they must spend substantial time reviewing the course material if they are going to improve their subsequent performance. Thus, effort had a strong positive effect on performance following a low self-assessment. Accounting for differences in the level of effort that trainees exerted following high and low self-assessments fully explained the process by which self-assessment and performance interacted to influence subsequent performance. Our results also revealed that low performance increased the probability of dropping out, and this effect was stronger following overestimations of performance than uniformly negative ratings. Negative feedback is particularly damaging when individuals per- ceive themselves as performing well (Brett & Atwater, 2001), and our results demonstrate that this may cause trainees to drop out of training. This is consistent with self-enhancement theory’s (Allport, 1937; Leary, 2007; Shrauger, 1975) suggestion that there may be negative repercussions if individuals are provided with performance feedback that is lower than their self-appraisals.Dropping out was not inevitable following uniformly negative ratings or overestimations of performance—if trainees remained committed to training, the probability of dropping out of the subse- quent module was lower than if trainees were less committed. Moreover, commitment had a stronger effect on subsequent attri- tion when trainees’ self-assessments were lower rather than higher in the previous module. Control theory suggests that periodically individuals monitor their performance to determine whether they are making adequate goal progress (Carver & Scheier, 1990). If indi- viduals have high self-assessments, it indicates that they believe High Performance High Performance Exert More Effort Am I Committed to Training? High Commitment is Especially Important Following a Low Self-Assessment High Performance Low Performance Low Performance Will I Exert Effort? Am I Committed to Training? High Commitment is Especially Important Following a Low Self-Assessment High Effort Low Effort Exerting Effort is Especially Important Following a Low Self-Assessment Low Commitment High Commitment Drop Out Complete Module Drop Out Complete Module Behavior Following High Performance (Uniformly Positive Ratings or Underestimation) Behavior Following Low Performance (Uniformly Negative Ratings or Overestimation) Low Commitment High Commitment Fig. 9. Summary of the results from Studies 1 and 2. 204 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207they are on track to achieve their goals and, thus, they are likely to continue goal pursuit (Sitzmann, Ely, Brown et al., 2010). In contrast, a low self-assessment indicates that trainees are not on track to achieve their goals. When trainees’ goal progress is inadequate, they rely on a variety of factors—including their commitment to train- ing—to decide whether to continue goal pursuit (Carver & Scheier, 1990). Although goals were not assessed in the current study, the re- sults support existing theory and research and suggest that commit- ment to training had a stronger effect on attrition when trainees felt they were failing to master the course content. Furthermore, accounting for differences in trainees’ commitment to the course following low and high self-assessments fully explained the process by which conscientiousness, self-assessment, and performance interact to influence subsequent attrition. Considering conscientiousness further complicated the decision making model as trainees received feedback on their performance. Study 2 demonstrated that trainee conscientiousness affects behavior after receiving performance feedback that is inconsistent with their self-assessments of knowledge. Trainees high and low in conscientiousness had similar levels of performance and attrition following uniformly positive and uniformly negative ratings. Rela- tive to low conscientious trainees, those high in conscientiousness had lower subsequent attrition and worse performance when their actual performance was inconsistent with their self-assessments. Receiving performance feedback that is inconsistent with one’s self-assessment represents a weak situation where the appropriate response is ambiguous (Mischel, 1977). Personality tends to have its strongest effect on behavior in weak situations (Haaland & Christiansen, 2002). People prefer to receive self-verifying informa- tion (Swann, 1983) and react negatively when they receive feed- back that is inconsistent with their self-appraisals (Meyer, 1980; Shrauger, 1975; Swann, 1990). Trainees relied on their personalities when deciding how to re- spond to feedback that was inconsistent with their self-appraisals. High conscientious trainees relied on their natural tendency topersevere and follow through on their obligations, whereas low con- scientious trainees were more likely to drop out following underes- timations and overestimations of performance. Despite their perseverance, high conscientious trainees performed worse than low conscientious trainees following underestimations and overes- timations of performance. With regards to overestimation, unfavor- able feedback stirs up negative emotions (Cianci, Klein et al., 2010), and negative emotions impair performance (Cianci, Klein et al., 2010; Kanfer & Ackerman, 1996; Kanfer, Ackerman, & Heggestad, 1996). Trainees may have also experience cognitive interference when they underestimated their performance (Kwang & Swann, 2010), and cognitive interference impairs performance (Kanfer & Ackerman, 1996; Sitzmann & Ely, 2011). Thus, subsequent perfor- mance was impaired as trainees coped with the realization that their actual performance was inconsistent with their self-assess- ments. Similarly, Colquitt et al.’s (2000) meta-analytic findings re- vealed that conscientiousness is positive related to training motivation but negatively related to skill acquisition. As such, addi- tional research is needed to examine the advantages and disadvan- tages of high levels of consciousness in learning environments. Study limitations and directions for future research There are several limitations to the current studies. In Study 1, 123 trainees dropped out during the first module. These trainees were not included in the research because they left the training environment before completing any of the study measures. Additional research is needed to examine why trainees sign up for voluntary online courses and drop out before they can truly benefit from the instructional experience. Another limitation is this research is correlational rather than experimental. This precludes drawing definitive conclusions regarding the causes and conse- quences of self-assessments of knowledge. Additional research may also benefit from measuring the extent to which trainees were focusing their cognitive resources on training as well as the T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 205amount of time devoted to learning to fully capture whether train- ees were engaged in learning. Both main effects and interactions were interpreted at the p < .10 level in Study 1 due to the high attrition rate and low control typical of a field setting, both of which reduce the power to detect an effect. Thus, the Type I error rate may be inflated in Study 1. In Study 2, interactions were interpreted at p < .10 and main effects were inter- preted at p < .05. This approach allowed us to balance the competing concerns of an inflated Type I error rate with the reduced parameter reliabilities for cross-level interactions that decrease the power to detect an effect (Snijders & Bosker, 1999). However, the replication across multiple studies lends confidence in the results. Also, it is important to note that the self-assessment by effort interaction mediated the relationship between the self-assess- ment/actual performance interaction and subsequent performance in Study 1 but not Study 2. Given that Study 2 was a 2-hour labo- ratory experiment, trainees may not have had sufficient time to spend reviewing if they wished to compensate for poor perfor- mance in the previous module. As such, the mediating effect of ef- fort may not be observed unless trainees are given substantial freedom to decide how much time to devote to learning. This sug- gests that in workplace settings, time constraints and competing task demands may weaken the mediating effect of effort on the self-assessment/performance interaction. Furthermore, the strength of the self-assessment/actual perfor- mance relationship did not increase as trainees progressed through the course. This contradicts Sitzmann, Ely, Brown et al.’s (2010) meta-analytic results, suggesting that providing trainees with re- peated opportunities to self-assess their knowledge along with per- formance feedback increases the strength of the self-assessment/ performance relationship. Thus, additional research is needed to examine whether these inconsistencies are due to differences in the level of analysis in which the research is conducted (i.e., the meta-analysis was at the between-subjects level whereas this re- search was at the within-subject level) or because attrition from training may have attenuated the effects in the current research. Our results revealed that trainees’ performance was higher in the subsequent module when their self-assessments of knowledge were favorable. However, informing trainees that they were actu- ally performing at a low level diminished this effect—impairing subsequent performance and increasing subsequent attrition. Thus, when trainees have the option of withdrawing from training, they may be better off not knowing how poorly they are perform- ing so that they remain in the course. Although we would not sug- gest providing inaccurate feedback when trainees are performing poorly, it is possible that trainees would be better off not receiving any feedback until they complete the course or receiving sugges- tions for improving (e.g., you should spend more time reviewing), rather than just revealing that they are performing poorly. Under- standing more effective ways of delivering negative feedback may reduce instances in which feedback impairs performance (Kluger & DeNisi, 1996), and is an essential avenue for future research.Conclusions The effect of trainees’ performance on subsequent performance and attrition is much more complex than previously presumed. Trainees’ performance starts off a complex decision making pro- cess during which trainees consider whether they are willing to ex- ert substantial effort in training and if they are committed to the course. These decisions determine trainees’ performance in the subsequent module and whether they complete training. Ulti- mately, this decision making process is contingent upon whether trainees’ self-assessments of knowledge suggest that they are learning a lot during training or failing to grasp the training mate-rial. As such, self-assessments must be taken into account as we at- tempt to understand the complex effects of trainees’ performance and feedback on subsequent behavior.References Allport (1937). The functional autonomy of motives. American Journal of Psychology, 50, 141–156. Atwater, L. E., & Brett, J. F. (2005). Antecedents and consequences of reactions to developmental 360 feedback. Journal of Vocational Behavior, 66, 532–548. doi:10.1016/j.jvb.2004.05.003. Atwater, L. E., Ostroff, C., Yammarino, F. J., & Fleenor, J. W. (1998). Self–other agreement: Does it really matter? Personnel Psychology, 51, 577–598. doi:10.1111/j.1744-6570.1998.tb00252. Atwater, L. E., Roush, P., & Fischthal, A. (1995). The influence of upward feedback on self- and follower ratings of leadership. Personnel Psychology, 48, 35–59. doi:10.1111/j.1744-6570.1995.tb01745. Atwater, L. E., Waldman, D., Atwater, D., & Cartier, P. (2000). An upward feedback field experiment: Supervisors’ cynicism, follow-up and commitment to subordinates. Personnel Psychology, 53, 275–297. doi:10.1111/j.1744- 6570.2000.tb00202. Atwater, L. E., & Yammarino, F. J. (1997). Self–other rating agreement. In G. R. Ferris (Ed.). Research in personnel and human resources management (Vol. 15, pp. 121–174). US: JAI Press. Bangert-Drowns, R. L., Kulik, J. A., & Morgan, M. T. (1991). The instructional effect of feedback in test-like events. Review of Educational Research, 61, 213–238. doi:10.3102/00346543061002213. Barrick, M. R., & Mount, M. K. (1991). The Big Five personality dimensions and job performance: A meta-analysis. Personnel Psychology, 44, 1–26. Barrick, M. R., Mount, M. K., & Strauss, J. P. (1993). Conscientiousness and performance of sales representatives: Test of the mediating effects of goal setting. Journal of Applied Psychology, 78, 715–722. doi:10.1037/0021- 9010.78.5.715. Barrick, M. R., Stewart, G. L., & Piotrowski, M. (2002). Personality and job performance: Test of the mediating effects of motivation among sales representatives. Journal of Applied Psychology, 87, 43–51. doi:10.1037/0021- 9010.87.1.43. Bean, J. P., & Metzner, B. S. (1985). A conceptual model of nontraditional undergraduate student attrition. Review of Educational Research, 55, 485–540. doi:10.2307/1170245. Bell, S. T., & Arthur, W. Jr., (2008). Feedback acceptance in developmental assessment centers: The role of feedback message, participant personality, and affective response to the feedback session. Journal of Organizational Behavior, 29, 681–703. doi:10.1002/job.525. Bell, B. S., & Federman, J. E. (2010). Self-assessments of knowledge: Where do we go from here? Academy of Management Learning & Education, 9, 342–347. Bell, B. S., & Kozlowski, S. W. J. (2008). Active learning: Effects of core training design elements on self-regulatory processes, learning, and adaptability. Journal of Applied Psychology, 93, 296–316. doi:10.1037/0021-9010.93.2.296. Bernstein, B. L., & Lecomte, C. (1979). Supervisory-type feedback effects: Feedback discrepancy level, trainee psychological differentiation, and immediate responses. Journal of Counseling Psychology, 26, 295–303. doi:10.1037/0022- 0167.26.4.295. Bliese, P. D., & Ployhart, R. E. (2002). Growth modeling using random coefficient models: Building, testing, and illustrations. Organizational Research Methods, 5, 362–387. doi:10.1177/109442802237116. Brett, J., & Atwater, L. (2001). 360 Degree feedback: Accuracy, reactions, and perceptions of usefulness. Journal of Applied Psychology, 86, 930–942. doi:10.1037/0021-9010.86.5.930. Campbell, D. J., & Lee, C. (1988). Self-appraisal in performance evaluation: Development versus evaluation. Academy of Management Review, 13, 302–314. Carver, C. S., & Scheier, M. F. (1981). Attention and self-regulation: A control-theory approach to human behavior. New York: Springer-Verlag. Carver, C. S., & Scheier, M. F. (1990). Origins and functions of positive and negative affect: A control-process view. Psychological Review, 97, 19–35. doi:10.1037/ 0033-295X.97.1.19. Carver, C. S., & Scheier, M. F. (2000). On the structure of behavioral self-regulation. In M. Boekaerts, P. R. Pintrich, & M. Zeidner (Eds.), Handbook of self-regulation (pp. 41–64). New York: Academic Press. Cascio, W. F., & Aguinis, H. (2005). Applied psychology in human resource management (6th ed.). New Jersey: Prentice Hall. Cianci, A. M., Klein, H. J., & Seijts, G. H. (2010). The effect of negative feedback on tension and subsequent performance: The main and interactive effects of goal content and conscientiousness. Journal of Applied Psychology, 95, 618–630. doi:10.1037/a0019130. Cianci, A. M., Schaubroeck, J. M., & McGill, G. A. (2010). Achievement goals, feedback, and task performance. Human Performance, 23, 131–154. doi:10.1080/ 08959281003621687. Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied multiple regression/ correlation analysis for the behavioral sciences. Mahwah, NJ: Lawrence Erlbaum. Colquitt, J. A., LePine, J. A., & Noe, R. A. (2000). Toward an integrative theory of training motivation: A meta-analytic path analysis of 20 years of research. Journal of Applied Psychology, 85, 678–707. doi:10.1037/0021-9010.85.5.678. 206 T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207DeNisi, A., Cafferty, T., & Meglino, B. (1984). A cognitive view of the performance appraisal process: A model and research propositions. Organizational Behavior and Human Performance, 33, 360–390. doi:10.1016/0030-5073(84)90029-1. Digman, J. M. (1990). Personality structure: Emergence of the five-factor model. Annual Review of Psychology, 41, 417–440. doi:10.1146/annurev.ps.41. 020190.002221. Dunnette, M. (1993). My hammer or your hammer? Human Resource Management, 32, 373–384. doi:10.1002/hrm.3930320212. Dunning, D., Heath, C., & Suls, J. M. (2004). Flawed self-assessment: Implications for health, education, and the workplace. Psychological Science in the Public Interest, 5, 69–106. doi:10.1111/j.1529-1006.2004.0018. Dweck, C. S. (2006). Mindset: The new psychology of success. New York, NY: Random House. Falchikov, N., & Boud, D. (1989). Student self-assessment in higher education: A meta-analysis. Review of Educational Research, 59, 395–430. doi:10.3102/ 00346543059004395. Fleenor, J. W., Smither, J. W., Atwater, L. E., Braddy, P. W., & Sturm, R. E. (2010). Self– other rating agreement in leadership: A review. The Leadership Quarterly, 21, 1005–1034. doi:10.1016/j.leaqua.2010.10.006. Försterling, F., & Morgenstern, M. (2002). Accuracy of self-assessment and task performance: Does it pay to know the truth? Journal of Educational Psychology, 94, 576–585. doi:10.1037/0022-0663.94.3.576. Haaland, S., & Christiansen, N. D. (2002). Implications of trait-activation theory for evaluating the construct validity of assessment center ratings. Personnel Psychology, 55, 137–163. doi:10.1111/j.1744-6570.2002.tb00106. Halperin, K., Snyder, C. R., Shenkel, R. J., & Houston, B. K. (1976). Effect of source status and message favorability on acceptance of personality feedback. Journal of Applied Psychology, 61, 85–88. doi:10.1037/0021-9010.61.1.85. Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77, 81–113. doi:10.3102/003465430298487. Hong, Y., Chiu, C.-y., Dweck, C. S., Lin, D. M., & Wan, W. (1999). Implicit theories, attributions, and coping: Focusing on malleable intelligence motivates remedial action via effort attributions. Journal of Personality and Social Psychology, 77, 588–599. doi:10.1037/0022-3514.77.3.588. Ilgen, D. R., Fisher, C. D., & Taylor, M. S. (1979). Consequences of individual feedback on behavior in organizations. Journal of Applied Psychology, 64, 349–371. doi:10.1037/0021-9010.64.4.349. Ilies, R., De Pater, I. E., & Judge, T. (2007). Differential affective reactions to negative and positive feedback, and the role of self-esteem. Journal of Managerial Psychology, 22, 590–609. doi:10.1108/02683940710778459. Jung, H. Y., & McCroskey, J. C. (2004). Communication apprehension in a first language and self-perceived competence as predictors of communication apprehension in a second language: A study of speakers of English as a second language. Communication Quarterly, 52, 170–181. doi:10.1080/ 01463370409370188. Kanfer, R., & Ackerman, P. L. (1996). A self-regulatory skills perspective to reducing cognitive interference. In I. G. Sarason, G. R. Pierce, & B. R. Sarason (Eds.), Cognitive interference: Theories, methods, and findings (pp. 153–171). Hillsdale, NJ: Erlbaum. Kanfer, R., Ackerman, P. L., & Heggestad, E. D. (1996). Motivational skills and self- regulation for learning: A trait perspective. Learning and Individual Differences, 8, 185–209. doi:10.1016/S1041-6080(96)90014-X. Keith, N., & Frese, M. (2005). Self-regulation in error management training: Emotion control and metacognition as mediators of performance effects. Journal of Applied Psychology, 90, 677–691. doi:10.1037/0021-9010.90.4.677. Kim, Y. H., Chiu, C., & Zou, Z. (2010). Know thyself: Misperceptions of actual performance undermine achievement motivation, future performance, and subjective well-being. Journal of Personality and Social Psychology, 99, 395–409. doi:10.1037/a0020555. Klein, H. J., Molloy, J. C., & Brinsfield, C. T. (in press). Reconceptualizing commitment for construct clarity, distinctiveness, and applicability to any workplace target. Academy of Management Review. Kluger, A. N., & DeNisi, A. (1996). The effects of feedback interventions on performance: A historical review, a meta-analysis, and a preliminary feedback intervention theory. Psychological Bulletin, 119, 254–284. doi:10.1037/0033- 2909.119.2.254. Kraiger, K. (2003). Perspectives on training and development. In W. C. Borman, D. R. Ilgen, R. J. Klimoski, & I. B. Weiner (Eds.), Handbook of psychology (pp. 171–192). Hoboken, NJ: Wiley. Kruger, J., & Dunning, D. (1999). Unskilled and unaware of it: How difficulties in recognizing one’s own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77, 1121–1134. doi:10.1037/0022- 3514.77.6.1121. Kwan, V. S., John, O. P., Robins, R. W., & Kuang, L. L. (2008). Conceptualizing and assessing self-enhancement bias: A componential approach. Journal of Personality and Social Psychology, 94, 1062–1077. doi:10.1037/0022- 3514.94.6.1062. Kwang, T., & Swann, W. B. (2010). Do people embrace praise even when they feel unworthy? A review of critical tests of self-enhancement versus self- verification. Personality and Social Psychology Review, 14(3), 263–280. doi:10.1177/1088868310365876. Leary, M. R. (2007). Motivational and emotional aspects of the self. Annual Review of Psychology, 58, 317–344. doi:10.1146/annurev.psych.58.110405.085658. Lecky, P. (1945). Self-consistency: A theory of personality. New York, NY: Island Press.. Locke, E. A., Frederick, E., Lee, C., & Bobko, P. (1984). Effect of self-efficacy, goals, and task strategies on task performance. Journal of Applied Psychology, 69, 241–251. doi:10.1037/0021-9010.69.2.241.Locke, E. A., & Latham, G. P. (1990). A theory of goal setting and task performance. Englewood Cliffs, NJ: Prentice-Hall. Meyer, H. H. (1980). Self-appraisal of job performance. Personnel Psychology, 33, 291–295. doi:10.1111/j.1744-6570.1980.tb02351. Miller, P. J., Wang, S., Sandel, T., & Cho, G. E. (2002). Self-esteem as folk theory: A comparison of European American and Taiwanese mothers’ beliefs. Parenting: Science and Practice, 2, 209–239. doi:10.1207/S15327922PAR0203_02. Mischel, W. (1977). The interaction of person and situation. In D. Magnusson & N. S. Endler (Eds.), Personality at the crossroads: Current issues in interactional psychology (pp. 333–352). Hillsdale, NJ: Lawrence Erlbaum. Muller, D., Judd, C. M., & Yzerbyt, V. Y. (2005). When moderation is mediated and mediation is moderated. Journal of Personality and Social Psychology, 89, 852–863. doi:10.1037/0022-3514.89.6.852. Newell, A., & Simon, H. (1972). Human problem solving. Englewood Cliffs, NJ: Prentice-Hall. Raudenbush, S. W., Bryk, A. S., Cheong, Y. F., Congdon, R. T., & du Toit, M. (2004). HLM 6: Hierarchical linear and nonlinear modeling. Lincolnwood, IL: Scientific Software International. Ree, M. J., Carretta, T. R., & Teachout, M. S. (1995). Role of ability and prior job knowledge in complex training performance. Journal of Applied Psychology, 80, 721–730. Robbins, S. B., Lauver, K., Le, H., Davis, D., Langley, R., & Carlstrom, A. (2004). Do psychosocial and study skill factors predict college outcomes? A meta- analysis. Psychological Bulletin, 130, 261–288. doi:10.1037/0033-2909.130. 2.261. Rubin, R. B., & Graham, E. E. (1988). Communication correlates of college success: An exploratory investigation. Communication Education, 37, 14–27. doi:10.1080/ 03634528809378700. Seligman, M. E., Reivich, K., Jaycox, L., & Gillham, J. (1995). The optimistic child. Boston, MA: Houghton, Mifflin. Shore, T. H., Shore, L. M., & Thornton, G. C. III, (1992). Construct validity of self- and peer evaluations of performance dimensions in an assessment center. Journal of Applied Psychology, 77, 42–54. doi:10.1037/0021-9010.77.1.42. Shrauger, J. S. (1975). Responses to evaluation as a function of initial self- perceptions. Psychological Bulletin, 82, 581–596. doi:10.1037/h0076791. Sitzmann, T. (in press). A theoretical model and analysis of the role of self- regulation in the attrition process. Learning and Individual Differences. Sitzmann, T., & Ely, K. (2010). Sometimes you need a reminder: The effects of prompting self-regulation on regulatory processes, learning, and attrition. Journal of Applied Psychology, 95, 132–144. doi:10.1037/a0018080. Sitzmann, T., & Ely, K. (2011). A meta-analysis of self-regulated learning in work- related training and educational attainment: What we know and where we need to go. Psychological Bulletin, 137, 421–442. Sitzmann, T., Ely, K., Bell, B. S., & Bauer, K. N. (2010). The effects of technical difficulties on learning and attrition during online training. Journal of Experimental Psychology: Applied, 16, 281–292. Sitzmann, T., Ely, K., Brown, K. G., & Bauer, K. N. (2010). Self-assessment of knowledge: A cognitive learning or affective measure? Academy of Management Learning and Education, 9, 169–191. Sitzmann, T., Kraiger, K., Stewart, D., & Wisher, R. (2006). The comparative effectiveness of web-based and classroom instruction: A meta-analysis. Personnel Psychology, 59, 623–664. doi:10.1111/j.1744-6570.2006.00049. Smircich, L., & Chesser, R. (1981). Superiors’ and subordinates’ perceptions of performance: Beyond disagreement. Academy of Management Journal, 24, 198–205. Snijders, T. A. B., & Bosker, R. (1999). Multilevel analysis: An introduction to basic and advanced multilevel modeling. Thousand Oaks, CA: Sage. Stone, D., & Stone, E. (1985). The effects of feedback consistency and feedback favorability on self-perceived task competence and perceived feedback accuracy. Organizational Behavior and Human Decision Processes, 36, 167–185. doi:10.1016/0749-5978(85)90011-1. Swann, W. B. Jr., (1983). Self-verification: Bringing social reality into harmony with the self. In J. Suls & A. G. Greenwald (Eds.). Social psychological perspectives on the self (Vol. 2, pp. 33–66). Hillsdale, NJ: Erlbaum. Swann, W. B. Jr., (1987). Identity negotiation: Where two roads meet. Journal of Personality and Social Psychology, 53, 1038–1051. doi:10.1037/0022- 3514.53.6.1038. Swann, W. B. Jr., (1990). To be adored or to be know? The interplay of self- enhancement and self-verification. In R. M. Sorrentino & E. T. Higgins (Eds.). Foundations of social behavior (Vol. 2, pp. 408–448). New York: Guildford. Taylor, M. S., Fisher, C. D., & Ilgen, D. R. (1984). Individuals’ reactions to performance feedback in organizations: A control theory perspective. In K. Rowland & G. Ferris (Eds.). Research in personnel and human resources management (Vol. 2, pp. 81–124). Greenwich, CT: JAI Press. Tinto, V. (1975). Dropout from higher education: A theoretical synthesis of recent research. Review of Educational Research, 45, 89–125. van Dijk, W. W., van der Pligt, J., & Zeelenberg, M. (1999). Effort invested in vain: The impact of effort on the intensity of disappointment and regret. Motivation and Emotion, 23, 203–220. doi:0146-7239/99/0900-0203. Vancouver, J. B., & Kendall, L. N. (2006). When self-efficacy negatively relates to motivation and performance in a learning context. Journal of Applied Psychology, 91, 1146–1153. doi:10.1037/0021-9010.91.5.1146. Vandenberg, R. J., & Lance, C. E. (2000). A review and synthesis of the measurement invariance literature: Suggestions, practices, and recommendations for organizations research. Organizational Research Methods, 3, 4–69. doi:10.1177/ 109442810031002. T. Sitzmann, S.K. Johnson / Organizational Behavior and Human Decision Processes 117 (2012) 192–207 207VandeWalle, D., Cron, W. L., & Slocum, J. W. Jr., (2001). The role of goal orientation following performance feedback. Journal of Applied Psychology, 86, 629–640. doi:10.1037/0021-9010.86.4.629. Venables, L., & Fairclough, S. H. (2009). The influence of performance feedback on goal-setting and mental effort regulation. Motivation and Emotions, 33, 63–74. doi:10.1007/s11031-008-9116-. Wright, S. S. (2000). Looking at the self in a rose-colored mirror: Unrealistically positive self-views and academic performance. Journal of Social & Clinical Psychology, 19, 451–462. doi:10.1521/jscp.2000.19.4.451. Yammarino, F., & Atwater, L. (1997). Do managers see themselves as others see them? Implications of self-other rating agreement for human resourcesmanagement. Organizational Dynamics, 25, 35–44. doi:10.1016/S0090- 2616(97)90035-8. Yeo, G. B., & Neal, A. (2004). A multilevel analysis of effort, practice, and performance: Effects of ability, conscientiousness, and goal orientation. Journal of Applied Psychology, 89, 231–247. doi:10.1037/0021-9010.89.2.231. Yeo, G. B., & Neal, A. (2006). An examination of the dynamic relationship between self-efficacy and performance across levels of analysis and levels of specificity. Journal of Applied Psychology, 91, 617–631. doi:10.1037/0021-9010.91.5.1088. Yeo, G., & Neal, A. (2008). Subjective cognitive effort: A model of states, traits, and time. Journal of Applied Psychology, 93, 1088–1101. doi:10.1037/0021- 9010.93.3.617.