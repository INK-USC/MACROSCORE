Chorpita_JournConsClinPsy_2015_8VbW.pdf
as6jsq8dIr5wX4EZHwhkw86GKaem-Chorpita_JournConsClinPsy_2015_8VbW.pdf.plain.html

Balancing Effectiveness With Responsiveness: Therapist Satisfaction Across Different Treatment Designs in the Child STEPs Randomized Effectiveness Trial Bruce F. Chorpita, Alayna Park, and Katherine Tsai University of California, Los Angeles Priya Korathu-Larson, Charmaine K. Higa-McMillan, and Brad J. Nakamura University of Hawaii John R. Weisz Harvard University Jennifer Krull University of California, Los Angeles The Research Network on Youth Mental Health Chicago, IL Objective: To investigate the association between protocol design and therapist satisfaction in the Child STEPs Randomized Effectiveness Trial (Weisz et al., 2012). Method: Therapist report was obtained at the close of 145 cases seen by 77 therapists, each of whom was randomized to a Standard evidence-based treatment (EBT), modular EBT, or usual care (UC) condition. Results: Analysis of satisfaction items revealed 2 correlated factors representing perceived effectiveness and perceived responsiveness of the treatments. Therapist total satisfaction scores were significantly higher for cases in the modular condition than for those in the standard EBT or UC conditions. With regard to specific dimensions, the modular and UC cases were rated significantly higher than standard EBT cases on the Responsiveness scale, whereas modular and standard EBT cases were rated significantly higher than UC on the Effectiveness scale. Finally, increases in Effectiveness scores from first to second case were significantly larger for Modular cases than for cases in both other study conditions, and increases from first to second case in Total Satisfaction scores were significantly larger for modular cases than for UC cases. Conclusions: Therapist satisfaction with a treatment approach has independent dimensions, which can vary as a function of the protocol design. By virtue of being perceived as more effective than UC and more responsive than standard EBTs, the modular protocol design was also viewed as more overall satisfying than both, and secondary analysis suggested that these results were not due to mere first impressions of the protocols. What is the public health significance of this article? This study shows that therapist satisfaction with using a treatment protocol varied as a function of how the protocol was designed. Therapists valued both effectiveness and responsiveness of treat- ments—features that were best balanced using a modular treatment design with an intermediate level of flexibility. For treatments to be effective and sustained in practice settings, treatment developers should consider design features that increase the appeal to the therapists who are ultimately responsible for using them. Keywords: randomized trial, dissemination, therapist satisfaction, modular treatment This article was published Online First May 18, 2015. Bruce F. Chorpita, Alayna Park, and Katherine Tsai, Department of Psychology, University of California, Los Angeles; Priya Korathu-Larson, Department of Psychology, University of Hawaii—Manoa; Charmaine K. Higa-McMillan, Department of Psychology, University of Hawaii—Hilo; Brad J. Nakamura, Department of Psychology, University of Hawaii— Manoa; John R. Weisz, Department of Psychology, Harvard University; Jennifer Krull, Department of Psychology, University of California, Los Angeles; The Research Network on Youth Mental Health, Chicago, IL. The study was supported by grants to Drs. Weisz and Chorpita by the John D. and Catherine T. MacArthur Foundation, which shaped neither the study nor the preparation of this article. We thank the participating orga- nizations, therapists, youths, parents for their involvement in this research. The Modular Approach to Treatment of Children with Anxiety, Depres- sion, or Conduct Problems (MATCH) manual used in this study was the precursor to a revised and expanded version for which Drs. Chorpita and Weisz receive income. During the time of this study, the Research Network on Youth Mental Health included Bruce F. Chorpita, Ann Garland, Robert Gibbons, Charles Glisson, Evelyn Polk Green, Kimberly Hoagwood, Kelly Kelleher, John Landsverk, Stephen Mayberg, Jeanne Miranda, Law- rence A. Palinkas, Sonja K. Schoenwald, and John R. Weisz (Network Director). Correspondence concerning this article should be addressed to Bruce F. Chorpita, Department of Psychology, University of California, Los Ange- les, Box 951563, Los Angeles, CA 90095. E-mail: chorpita@ucla.edu T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. Journal of Consulting and Clinical Psychology © 2015 American Psychological Association 2015, Vol. 83, No. 4, 709–718 0022-006X/15/$12.00 http://dx.doi.org/10.1037/a0039301 709 For more than 2 decades, mental health research and policy have prioritized the development and testing of high-quality mental health treatments (e.g., Guyatt & Evidence-Based Medicine Work- ing Group, 1992). In children’s mental health, the impact has been substantial. Hundreds of randomized clinical trials have evaluated the efficacy of treatments for a variety of childhood disorders and problems (Chorpita et al., 2011) and have consistently found evidence-based treatments (EBTs) to outperform usual care within research contexts (e.g., Weisz, Jensen-Doss, & Hawley, 2006; Weisz, Weiss, Han, Granger, & Morton, 1995). Over the last decade, not surprisingly, policymakers at both the state and federal levels have increasingly turned their attention to maximizing the public health impact of EBTs, which requires understanding and managing strategies for their implementation (e.g., Chambers et al., 2005; Chorpita & Daleiden, 2014; Kazdin & Blasé, 2012; National Institute of Mental Health, 2008). It is interesting that some of these recent efforts to understand factors relevant to the real-world application of EBTs were fore- cast in some of the very earliest work defining evidence-based psychological treatments. For example, in 1992, the American Psychological Association Task Force on Psychological Interven- tion Guidelines (1995) outlined a template for evaluating psycho- social interventions that articulated separate dimensions of effi- cacy and effectiveness. The Task Force defined efficacy as the extent to which an intervention can elicit positive outcomes for a target disorder or problem, which can be indexed according to the type and quality of research in which such outcomes were docu- mented, ranging from randomized clinical trials at the highest level, to quantified clinical observations, to clinical consensus, and finally, to experimental findings of negative effects at the lowest level. On the effectiveness dimension, indicators included feasi- bility (i.e., patient acceptability, patient choice, probability of compliance, and ease of training), generalizability (i.e., patient characteristics, therapist characteristics, robustness in practice set- tings, and contextual factors regarding the setting in which the treatment is delivered), and costs and benefits (i.e., costs of deliv- ering intervention to individual and to society, and costs of with- holding the intervention). These aspects of treatment effectiveness have turned out to be a critical part of solving the mental health service quality problem (cf. Kazdin & Blasé, 2012), given early signs that EBT uptake within practice contexts was slower than anticipated and that therapists consistently underutilized EBTs in their everyday prac- tice (Weersing, Weisz, & Donenberg, 2002). Fortunately, a result- ing increase in attention to such topics has brought many of these ideas into better focus. For example, multiple studies have identi- fied a variety of factors that influence therapists’ decisions about whether to adopt an EBT in practice (see Weisz, Ugueto, Cheron, & Herren, 2013), including knowledge barriers (e.g., difficulty identifying appropriate EBTs, extensive training and supervision requirements for accurate implementation; see Nakamura, Higa- McMillan, Okamura, & Shimabukuro, 2011), practical barriers (e.g., few incentives to adopt new treatments, time and costs associated with EBT training; Higa & Chorpita, 2008), and attitude barriers (e.g., beliefs that EBTs are poorly suited to one’s caseload; cf. Addis & Krasnow, 2000). This last set of barriers has been shown to significantly predict self-reported nonuse of EBTs (Nel- son & Steele, 2007). Such findings are also consistent with the larger body of diffusion of innovation literature suggesting that the perceived attributes of any new technology, such as an EBT, may determine the rate at which it will be adopted into practice (e.g., Rogers, 2003). Significant efforts have been made to address both knowledge barriers and practical barriers to the use of EBTs in practice in response to these findings. For example, there are now federal, state, and county registries that identify and describe EBTs (e.g., SAMHSA, 2014; California Institute of Mental Health, 2014), an increase in availability of training opportunities to learn EBTs (e.g., Society of Clinical Child and Adolescent Psychology, Amer- ican Psychological Association & Association of Behavioral & Cognitive Therapies, 2014), an increase in research attention to effective training and consultation methodologies (Beidas & Ken- dall, 2010; Fixsen, Naoom, Blasé, Friedman, & Wallace, 2005; Nakamura, Selbo-Bruns, Okamura, Chang, Slavin, & Shimabu- kuro, 2014), and incentives and funding initiatives to promote the use of EBTs. Relatively less attention, however, has been paid to the third set of barriers, namely, therapist attitudes, other than to establish that they are generally not positive (e.g., Addis & Kras- now, 2000) and that they are indeed predictive of practice (e.g., Nelson & Steele, 2007; Rogers, 2003). Whereas some efforts to address attitudinal barriers have in- volved a focus on social influence and organizational context (e.g., Glisson et al., 2008), other research has focused on the properties of the EBTs themselves. For example, Chorpita, Daleiden, and Weisz (2005) proposed a modular design framework as a strategy to manipulate protocol features such as procedural content, dose, order, and flexibility, so as to begin to investigate whether sys- tematic variations in protocol design could enhance treatment fit (and thereby address major attitudinal barriers) while preserving efficacy of the interventions. In a large randomized effectiveness trial investigating these concepts, Weisz et al. (2012) tested mul- tiple EBTs in community children’s mental health settings, with some EBTs delivered according to their traditional manualized format and some EBTs delivered in a modular fashion that used similar procedures but allowed for a more flexible implementation (i.e., Modular Approach to Therapy for Children, MATCH-ADC; Chorpita & Weisz, 2005). Both EBT designs were compared with usual care as well. In a sample of children and adolescents, ages 7 to 13, with anxiety, depression, or conduct problems, those who received the modular approach showed significantly greater rates of improvement during treatment relative to those who received standard format EBTs or usual care (Weisz et al., 2012). When the long-term outcomes were examined over a 2-year period, youths assigned to the modular treatment continued to show significantly faster improvement than those assigned to usual care (Chorpita et al., 2013), whereas the modular and standard conditions did not differ significantly. Consistent with the study aims, data gathered after the therapist trainings but before the trial began revealed that those trained in the modular approach demonstrated a significant improvement in attitudes toward evidence-based practices relative to those trained in the standard EBT manuals (Borntrager, Chor- pita, Higa-McMillan, & Weisz, 2009), suggesting that protocol design features such as those in the modular condition (i.e., offer- ing more structure than usual care, but more flexibility than the standard EBT condition) have the potential to improve therapist perceptions of EBTs in general. Although these findings are promising, studies in other fields have shown that users’ actual experience with an innovative tech- T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 710 CHORPITA ET AL. nology is a critical factor in how that technology is ultimately evaluated and whether its use is sustained over time (Taylor & Todd, 1995). Accordingly, we sought to investigate levels of therapists’ satisfaction with their therapy approach as they closed each case in the Child STEPs randomized effectiveness trial (Weisz et al., 2012). Therapist satisfaction is an important con- struct in dissemination and implementation efforts, given that it predicts who is likely to continue using a treatment in the future (Stirman et al., 2004) and to influence other therapists, as evidence suggests that therapists are especially impacted by social influence channels and by their peers (Fazio, Zanna, & Cooper, 1978; Meehl, 1993; Herbert et al., 2000). This study examined whether the modular approach was asso- ciated with greater therapist satisfaction relative to standard EBT manuals and usual care. The study aims were to (a) establish the factor structure and psychometric adequacy of brief scales de- signed to assess therapists’ satisfaction with a treatment, (b) eval- uate the overall effect of protocol design on therapist satisfaction and its relevant dimensions, (c) examine whether satisfaction was influenced merely by preferences that were established before having direct experience with an assigned protocol, and (d) inves- tigate whether therapists’ satisfaction with a protocol changed as they obtained more experience with that approach. Method Data for this study were collected as part of the Child STEPs randomized effectiveness trial, which compared two different ap- plications of evidence-based practices for anxiety, depression, and conduct problems with usual care for children ages 7 to 13 (see Weisz et al., 2012 for details and for a CONSORT flow diagram). All procedures were approved by the institutional review boards of Judge Baker Children’s Center (affiliated with Harvard Medical School) and the University of Hawaii at Manoa. Therapists were randomly assigned to three treatment condi- tions, each of which involved the use of a different treatment approach: standard (i.e., the use of three separate manualized EBTs for anxiety, depression, and conduct problems), modular (i.e., MATCH-ADC), or usual care (UC). Blocked randomization strat- ified by therapist education (doctorate vs. masters) was used to randomly assign therapists to condition. Those who were assigned to the standard condition were trained in using the Coping Cat (Kendall, 1994; Kendall et al., 1990), the Primary and Secondary Control Enhancement Training (PASCET; Weisz et al., 2005; Weisz et al., 1997; Weisz et al., 2009), and the Defiant Children (Barkley, 1997) manuals. Therapists in the modular condition were trained in MATCH-ADC (Chorpita & Weisz, 2005), a collection of 33 modules designed to correspond to the treatment procedures included in Coping Cat, PASCET, and Defiant Children. How- ever, MATCH-ADC uses a guiding algorithm that focuses on the problem area collaboratively identified as most important, while allowing for real-time adaptation of the treatment plan and per- sonalized arrangement of procedures to address comorbidity or engagement concerns. Therapists in the UC condition were in- structed to implement their typical treatment procedures. Thera- pists in all three conditions were blind to youth outcomes from the posttreatment assessments. The average treatment duration was 196.24 days (SD  109.46) for the standard protocol, 210.15 days (SD  124.37) for the modular protocol, and 275.49 days (SD  194.43) for UC. Observational coding of recorded treatment ses- sions showed strong adherence to the protocol for the standard and modular conditions, and a lack of standard or modular content within UC sessions. For more details about the treatment integrity of the standard and modular conditions within this randomized effectiveness trial, refer to Weisz et al. (2012). Participants Therapists. Satisfaction measures were collected from 77 therapists (standard: 28; modular: 24; UC: 25) who were recruited across 10 different outpatient clinical service organizations in Massachusetts and Hawaii. Therapists provided individual treat- ment in clinic- and school-based settings. Of these therapists 79.2% were female; 55.8% were Caucasian, 23.4% were Asian American, 6.5% were African American, 6.5% were Pacific Is- lander, and 7.8% did not report their ethnicity. Therapist age ranged from 25 to 59 years (M  40.9 years; SD  9.7) and had an average of 7.7 years (SD  7.5) of clinical experience since earning their highest degree. As their most advanced educational degree, the largest percentage of therapists (37.7%) had earned a master’s of social work, 35.1% had earned a master of arts, and 20.8% had earned a doctorate of philosophy. The therapists most commonly reported their primary theoretical orientation as cognitive–behavioral (46.8%), followed by eclectic (13.0%), psy- chodynamic (13.0%), and family systems (6.5%), and “other” (11.7%). Seven therapists (9.1%) did not report having a primary orientation. At the time of entry into the study, therapists carried a mean caseload of 19.4 clients (SD  14.3; range  0 to 75) in their current position; as part of their study participation, each therapist treated an average of 1.9 study cases (SD  1.1; range  1 to 6). There were no significant differences across conditions on any of the therapist characteristics. Youth. Cases for which satisfaction ratings were obtained included 145 youth aged 7 through 13 years (M  10.19; SD  1.76) who were being treated for problems in any combination of anxiety, depression, or conduct. Youth who received any amount of treatment services by the therapist were eligible for inclusion. Of these 145 youth, 70.14% were male; 41.26% were Caucasian, 37.06% were multiethnic, 9.09% were African American, 6.29% were Latino or Latina, 4.20% were classified as “other,” and 2.80% identified as Asian American. Annual family income was less than $40,000 for 56.30% of study participants; $40,000 to $79,000 for 24.45% of the sample; $80,000 to $119,000 for 12.59% of the sample; and $120,000 or more for 6.66% of the sample, with an average of 3.85 dependents living off of the identified family income. Measures Therapist Background Questionnaire (TBQ). As therapists were enrolled, information on therapist background was collected through the TBQ, a 12-item questionnaire designed to assess therapists’ demographics, training history, clinical experience, and theoretical orientation. To determine whether therapists had al- ready established a preference for a given treatment condition after completing study consent forms, but prior to randomization, the final item of the TBQ asked therapists if they had a preference for assignment, and if so, for which condition. Study hypotheses were T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 711THERAPIST SATISFACTION not communicated to therapists, and data were collected confiden- tially by having therapists submit their answers in writing in sealed envelopes. Therapist Satisfaction Index (TSI). Therapist satisfaction with their treatment approach was assessed using the TSI, a therapist-report measure containing statements about their beliefs and attitudes about the treatment approach just used. The TSI was administered for each case, following the end of treatment. Thus, many therapists contributed more than one TSI assessment record to the final data set. Items were developed based on themes identified in the national survey performed by Addis and Krasnow (2000) regarding thera- pist attitudes toward standard manualized treatments. Some items were adapted directly to assess therapist’s satisfaction of the as- signed treatment protocol (e.g., Addis and Krasnow’s item “Using treatment manuals detracts from the authenticity of the therapeutic interaction” was changed to “The approach I used allowed for authenticity of the therapeutic interaction”), whereas other items were adapted more substantially or used to create new items (e.g., the two items “Using a treatment manual keeps therapist from using his or her intuition in responding to a client” and “Manuals make therapists more like technicians than caring human beings” were referenced to create the single item “This approach allowed me to be responsive to the needs and concerns of my child and his or her parents(s)”). Finally, several items were created simply to assess overall preference and intent (e.g., “I plan to use this treatment approach with other children I treat in the future” and “”I liked using this treatment approach”). This resulted in an initial set of 16 items. A central hypothesis in the Child STEPs effectiveness trial was that in a complex community context, the ideal treatment design would balance the effectiveness of evidence-based procedures with the responsive, individualized nature of routine clinical care (Weisz et al., 2012). Thus, for this investigation, we focused primarily on how we could assess these two aspects of treatment design as perceived by therapists. Prior to any administration of the instrument, the initial 16-item set was coded by investigators for the extent to which the items appeared to capture these relevant dimensions. Eight of the 16 items were rated by two independent judges as related to these two dimensions (i.e., responsiveness, effectiveness). The remaining eight items were rated as “other,” as described above (e.g., “The parents of the child I treated seemed to like the approach I used”). All items were rated on a 5-point Likert scale, ranging from 1 (strongly disagree) to 5 (strongly agree). All items were worded such that higher scores indicated greater ther- apist satisfaction. Modified Practice Attitude Scale. Therapists’ attitudes to- ward evidence-based practices were evaluated using the Modified Practice Attitude Scale (MPAS) (e.g., Borntrager et al., 2009), an eight-item questionnaire designed to assess general attitudes about the use of evidence-based practices. The MPAS was based on the Evidence Based Practice Attitudes Scale (Aarons, 2004), but in- volved modifications to remove references to the notion of “manu- alized” interventions given the different design characteristics be- ing tested in this study. The MPAS prompted therapists to indicate their level of agreement with each item on a 5-point Likert scale, ranging from 0 (not at all) to 4 (to a very great extent). Total scores were calculated by summing all of the items, after reverse-scoring five of them, and could range from 0 to 32, such that higher scores indicated more favorable attitudes. The MPAS was distributed before and after therapists’ training sessions in the study by Born- trager et al., (2009). In the present study, we used scores from the posttraining assessment as an index of attitudes toward EBTs in general, which represented the most recent assessment point in time relative to the completion of the TSI on cases following the training period. Borntrager et al. (2009) previously reported ex- cellent internal consistency (  .80) for the MPAS. Descriptive statistics for relevant study measures can be found in Table 1. Data Analysis All continuous data were initially reviewed for outliers (using box-plots and inspection of z scores) and for non-normality (whether skewness or kurtosis was significantly different from 0), and no concerns were detected. Missing data in tests of reliability and validity were handled using pairwise deletion. In all other analyses, no data were missing (i.e., TSI scores, therapist prefer- ence, and study condition were known for all 145 cases). All analyses were performed with SPSS Version 20.0, with the excep- tion of the multilevel models (analysis of variance and analysis of covariance), which were performed with SAS 9.3. Results Therapist Satisfaction Index: Exploratory Factor Analysis and Item Selection Sixteen items (eight items rationally classified by the investiga- tors, plus eight experimental items) were subject to an initial exploratory factor analysis (FA) to determine whether there were multiple dimensions of therapists’ satisfaction with the treatments Table 1 Therapists’ Treatment Satisfaction and Attitude Toward Evidence-Based Treatments by Condition Scale Standard Modular Usual Care M SD Range M SD Range M SD Range TSI Total 23.88 3.49 16–30 25.74 2.73 19–30 23.31 3.18 16–30 TSI Effectiveness 13.00 1.36 10–15 13.47 1.40 11–15 11.31 1.75 8–15 TSI Responsiveness 10.90 2.40 6–15 12.28 1.80 8–15 12.00 1.79 8–15 MPAS 21.20 3.45 16–29 22.33 3.85 15–29 20.06 3.19 15–26 Note. TSI  Therapist Satisfaction Index; MPAS  Modified Practice and Attitudes Scale. For TSI (youth cases): N  49 (standard); N  47 (modular), N  49 (usual care). For MPAS (therapists): N  28 (standard); N  24 (modular), N  17 (usual care). T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 712 CHORPITA ET AL. implemented.1 Three factors were extracted using the criterion of eigenvalues greater than 1.0 (8.09, 1.52, and 1.14), explaining 67.2% of the total item variance. The scree plot suggested one or two factors; thus, based on these two indicators, we first extracted and rotated two factors. An orthogonal (varimax) rotation was used: Because uncorrelated factors were hypothesized, we did not expect therapists to consider responsiveness and effectiveness as necessarily related and, in fact, thought that some could even perceive them as negatively correlated, with a trade-off between the structure of manualized EBTs and the responsiveness of usual care (cf. Addis, Wade, & Hatgis, 1999). This initial extraction failed to produce simple structure: most items loaded on both factors, with the factor-item relationships failing to produce an interpretable pattern. Before considering the measure as a one-factor instrument, given that the experimental items were not clearly linked to spe- cific constructs, we decided first to repeat the FA without the eight experimental items to see if a more interpretable two-factor struc- ture would emerge. That initial extraction with eight items pro- duced two factors with eigenvalues greater than 1.0 (5.54, 1.25), with the scree plot again suggesting one or two factors. We then extracted two factors, which were interpretable according to the original rational intent of the instrument. The first factor repre- sented the expected “responsiveness” dimension (highest loading item: “This approach allowed me to be responsive to the needs and concerns of my child and his or her parents”), and the second factor represented the expected “effectiveness” factor (highest loading item: “The approach I used will enhance the average outcomes of children seen in psychotherapy”). Two items origi- nally created to represent effectiveness loaded equally on both factors. The item, “the treatment approach I used works well with the kinds of children I usually work with,” had a primary loading of .39 on the responsiveness factor, and a secondary loading of .32 on the effectiveness factor. In the reverse pattern, “the approach I used made me feel like an effective therapist” had a primary loading of .47 on the effectiveness factor, and a loading of .44 on the responsiveness factor. In light of these findings, it appeared that such items may have been interpreted by respondents as representing a mixture of both responsiveness and effectiveness. We therefore repeated the FA once more with these two items removed, using the same extrac- tion criterion and factor rotation. This solution produced a simple structure consistent with factors representing the hypothesized constructs of interest. These six items were therefore retained for subsequent analysis. The factor loadings and items are shown in Table 2. Reliability and Validity Cronbach’s alpha was calculated for the six-item TSI Total Score as well as the two scales represented by each of the factors. These values were .83 for the total score, .82 for responsiveness, and .81 for effectiveness. The Responsiveness and Effectiveness scales were moderately, but significantly correlated with each other (r  .46; p  .05). In tests of convergent validity, correla- tions of the TSI total score with the MPAS total score yielded correlation coefficients of .45 (p  .05) for therapists in the EBT conditions (i.e., standard and modular) and .45 (p  .05) for therapists in the UC condition. These findings are consistent with predictions, suggesting that positive scores on the MPAS were associated with higher scores on measures of therapist satisfaction, but only when those therapists were using EBTs. Positive attitudes toward EBTs in general were associated with lower therapist satisfaction for therapists in the UC condition (i.e., therapists not using EBTs). Similar patterns were noted for the Effectiveness scale (r  .43 and .47 for EBT and UC conditions, respectively) and the Responsiveness scale (r  .37 and .37 for EBT and UC conditions, respectively). Effects of Condition To assess the effects of treatment approach on therapist satis- faction, we estimated a mixed effects regression model for each of the three scales (i.e., TSI total score, Responsiveness, and Effec- tiveness). Because cases were nested within therapists, and tests for Level 2 variance were significant (significant differences in log likelihood fit statistics in full vs. reduced models), we modeled each treatment case as the Level 1 unit of analysis and therapists as the Level 2 unit of analysis. The nature of the design held that therapists were in only one condition for the duration of the study, therefore we modeled treatment condition as a Level 2 variable. The analysis model thus included two fixed effects: (a) an average intercept and the effect of treatment condition and (b) a single Level 2 error term on the intercept to appropriately model simi- larity among the multiple treatment cases for each therapist. Planned contrasts were conducted to compare each of the treat- ment conditions with the other two, with our hypotheses being that (a) therapists in the modular and UC conditions would evaluate their approach as more responsive than would therapists in the standard condition, (b) therapists in the standard and modular conditions would evaluate their approach as more effective than would therapists in the UC condition, and (c) therapists in the modular condition would evaluate their approach as more effective than therapists in the standard and UC conditions. Results of these tests are shown in the top half of Table 3. For tests of responsiveness, the overall test for condition was signifi- cant, indicating that significant differences emerged across the three groups. Therapists in the modular condition rated their ap- proach as the most responsive, followed by UC, and then standard EBTs. Consistent with expectations, the treatment approaches for cases in the UC and modular conditions, which did not differ significantly from each other, were each rated as significantly more responsive than the Standard EBT approach for cases. A different pattern emerged for effectiveness scores, with a significant effect of condition once again. On this scale, scores were highest for the modular condition, followed by the standard EBT condition, and then UC. Effectiveness scores for modular and standard treatments were both significantly higher than those for UC, but they were not significantly different from each other. Finally, on the total score, a significant effect of condition emerged again. Scores were highest for the modular condition, followed by standard, and then UC. The approach used in the modular condition was rated significantly higher than the approach 1 Item-level statistics are available from the corresponding author upon request. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 713THERAPIST SATISFACTION in either the standard EBT or the UC conditions, which were not significantly different from each other.2,3 Effects of Initial Preference Considering that therapists had been randomly assigned to each of these three groups, we next investigated the extent to which therapist satisfaction scores might have been influenced by whether the therapists’ preference of treatment prior to the study matched their assigned condition. Although a chi-square analysis found no significant differences in therapists’ initial study treat- ment preferences across conditions (2  12.95, df  8, p  .05), it was plausible that some part of the variance in satisfaction could have been because therapists were more satisfied when they had been randomized to the condition for which they had an initial preference. For example, given that a larger portion of therapists expressed a preference for the modular condition prior to random- ization, then a higher number of “disappointed” therapists would have been expected in the other two conditions once the trial began, which could have affected the results. The therapist back- ground data indicated such a pattern: A majority of therapists (36.0%) had a preference for the modular condition, 31.6% had a preference for standard, 14% for UC, and 18.4% reported that they did not have any preference. We therefore ran two additional sets of models. The first model included two fixed effects: an average intercept and the effect of therapist preference, which was represented as a dummy variable (0  not assigned to preferred condition; 1  assigned to preferred condition) and a single Level 2 error term on the intercept. Tests of the main effects of preference on TSI responsiveness, effective- ness, and total scores were not significant. Thus, being assigned to a condition for which one had a preference was not associated with significantly different satisfaction levels. We nevertheless ran a second set of models, which was similar to the first set, but added treatment condition as an additional fixed effect. The results for tests of the effect of condition on therapist satisfaction, controlling for initial preference, are shown in the bottom half of Table 3. No differences emerged from the previous analyses of condition, and all predictions were again uniformly supported by the pattern of results. Discussion These findings complement the studies examining the clinical outcomes from the Child STEPs randomized effectiveness trial (Chorpita et al., 2014; Weisz et al., 2012). One of the central themes of that body of research is that protocol designs should fit with the service context (Schoenwald, Kelleher, Weisz, & the Research Network on Youth Mental Health, 2008) and that, spe- cifically, such designs should ideally represent a balance between research-informed structure and locally informed adaptation (Chorpita & Daleiden, 2014). As noted in the original APA Task Force report (American Psychological Association Task Force on Psychological Intervention Guidelines, 1995), treatments should ideally perform well on the dimension of efficacy, or the research support for their approach and on dimensions of effectiveness, including acceptability and robustness to adaptation. Because MATCH-ADC was created to represent a test of this treatment design relative to common EBT structures, it was predicted to perform better than the standard EBTs, primarily on the latter dimensions only. Consistent with the limits of that prediction, standard and modular designs showed large effect sizes relative to UC for the perceived effectiveness of the protocols, with over 50% of the variance accounted for by study condition in the omnibus test. This indicates that providers did perceive all EBTs, regardless of design, as more effective than UC. 2 All of these analyses were repeated with treatment duration as a covariate, with no differences in the pattern of results. 3 Because of the considerable evidence that attitudes and impressions change with experience (e.g., Ajzen & Fishbein, 1980; Bornstein, Leone, & Galley, 1987), we sought to rule out a competing explanation with these findings that differences were largely due to “first impression” effects. Thus, we examined change in TSI scores from first to second case among the 40 study therapists who saw more than one case, as determined by the date of clients’ first session with the study treatment. We used the same regression model as in our initial analyses, adding a second fixed effect for case number. The tests produced similar patterns of estimates, however significant interactions were noted only on the Effectiveness and Total scores. For effectiveness, there was a significant Condition  Case Num- ber interaction for the modular and UC conditions (Estimate  1.94, SE  0.62), t (37)  3.15, p  .05, such that the effect of initial experience increased effectiveness scores significantly in the modular condition rela- tive to the UC condition. Likewise, this interaction was significant for the modular and standard conditions (Estimate  1.30, SE  0.62), t (37)  2.10, p  .05, such that the effect of experience increased effectiveness scores significantly in the modular condition relative to the standard condition. For total score, there was a significant Condition  Case Number interaction for the modular and UC conditions (Estimate  3.32, SE  1.36) t (37)  2.44, p  .05, such that the effect of initial experience increased scores significantly in the modular condition relative to the UC condition. No other interaction contrasts were significant. Table 2 Final Retained Items and Factor Loadings Using Exploratory Factor Analysis for the Therapist Satisfaction Index Item Factor Responsiveness Effectiveness This approach allowed me to individualize the intervention for the child .78 .21 This approach allowed me to be responsive to the needs and concerns of my child and his/her parent(s) .75 .26 The approach I used allowed me to address multiple needs of the child .70 .24 The approach I used will enhance average outcomes of children seen in psychotherapy .26 .75 The approach I used will be helpful for other children I work with in the future .17 .75 The approach I used allowed me to work from interventions that have been demonstrated to be effective .27 .69 Note. Primary loadings are shown in bold. Results based on extraction of two factors with orthogonal (varimax) rotation. Oblique rotation showed no change in item-factor membership, and all loadings increased by approximately .10. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 714 CHORPITA ET AL. That said, standard EBT design was considered significantly worse than modular and UC in terms of its perceived responsivity, with moderate effect sizes of just under 15% of the variance accounted for by condition, a pattern corroborating the historical notion that the degree of structure and the degree of research support are assessed quite independently by providers (e.g., Born- trager et al., 2009). In that context, however, these findings should be viewed as especially encouraging, by demonstrating a design prototype (i.e., MATCH) that balances the application of effica- cious procedures within a framework that allows for responsive- ness. These findings thus have important clinical implications for the design of protocols that are both efficacious and appealing to providers by virtue of their explicit attention to individualizing evidence-based care (Chorpita & Daleiden, 2014). The notion that MATCH-ADC fit with preferred application of practice is also consistent with additional findings from this body of research (Palinkas et al., 2013), which found that therapists in both the standard and modular conditions continued to use the treatments after the clinical trial was complete, but that both groups used the protocols according to the design principles of the modular condition (i.e., selecting and sequencing individual pro- cedures from the protocols according to perceived best clinical fit). Such patterns of use do not speak directly to the efficacy of this strategy, only to its acceptability. However, the outcome findings themselves showed that this flexible approach to treatment assem- bly was not associated with a loss of efficacy, but rather appeared to be associated with relatively superior outcomes (Weisz et al., 2012). A strength of this study is that it assessed perceptions of the protocols following the conclusion of their delivery. The broader literature on experience with new objects or technologies suggests, for example, that attitudes based on experience are better predic- tors of ultimate behavior (e.g., Fazio et al., 1978). Thus, the current findings lend greater support to the notion that therapists are likely to sustain use of the modular approach to evidence-based treatment that could be obtained by surveys of attitudes in general. It is encouraging that in our limited analysis of the effects of repeated exposure to the protocol, these effects only became more pro- nounced on average, suggesting that positive therapist reports regarding MATCH-ADC were not likely due to a transient first impression. Obviously, many questions remain about the degree to which such perceptions and attitudes stabilize over time, whether and how they might become resistant to disconfirmatory experi- ences (e.g., one case with an otherwise promising EBT going poorly), and what types of information or experiences can accel- erate or undermine the formation of attitudes, preference, and intentions about EBTs (cf. Fishbein & Ajzen, 1975). In the field of information technology, an elaboration of the Technology Acceptance Model (Davis, Bagozzi, & Warshaw, 1989), suggests that experience plays a critical role with accep- tance of a new technology, but that prior to direct experience, it is possible to influence attitudes through carefully presented infor- mation (Taylor & Todd, 1995). Notable from this same research is the finding that perceived usefulness of a technology is the best predictor of behavioral intention, but only for experienced users, whereas perceived behavioral control over the technology (which relates both to its simplicity and flexibility) was a better predictor of behavioral intention in individuals who had no prior direct experience with the technology (Taylor & Todd, 1995). The im- plications relevant to the current findings and to dissemination of EBTs more generally is that factors such as controllability and ease of use may be stronger considerations for therapists when initially exposed to an EBT (cf. responsiveness); whereas over time, the usefulness (cf. effectiveness for obtaining desired outcomes) might become the more dominant influence on intention to sustain use. Future research may benefit from testing the relative effects of these different dimensions over a longer time frame, particularly in a context predicting use or disuse of EBTs. The current findings, along with those of Palinkas et al. (2013) are so far consistent with Taylor and Todd’s (1995) augmented Technology Acceptance Model. Our results also lend support to the growing findings that therapist attitudes, beliefs, and preferences regarding EBTs are neither stable, global, nor one-dimensional (e.g., Aarons et al., Table 3 Coefficient Estimates by Condition for Responsiveness, Effectiveness, and Total Satisfaction With and Without Controlling for Therapist Preference Scale Standard vs. UC Modular vs. UC Modular vs. Standard Omnibus Test Estimate SE p Estimate SE p Estimate SE p F p ES ANOVA model (not controlling for therapist preference) Responsiveness 1.00 0.48 .042 0.27 0.50 .59 1.30 0.49 .011 3.83 .027 .14 Effectiveness 1.73 0.37 .0001 2.18 0.38 .0001 0.45 0.37 .23 18.72 .0001 .53 Total 0.74 0.76 .34 2.45 0.78 .003 1.72 0.77 .029 5.17 .008 .19 ANCOVA model (controlling for therapist preference) Responsiveness 1.06 0.49 .034 0.21 0.51 .68 1.27 0.49 .012 3.91 .024 .14 Effectiveness 1.69 0.38 .0001 2.14 0.39 .0001 0.45 0.38 .24 17.08 .0001 .51 Total 0.63 0.77 .42 2.35 0.80 .004 1.71 0.77 .03 4.67 .013 .17 Note. UC  usual care; ES  effect size, calculated as the percent of level 2 variance explained by condition, obtained by comparing Level 2 intercept variance components for full and reduced models; ANOVA  analysis of variance; ANCOVA  analysis of covariance. Parameter estimates represent the model-predicted difference in scale scores for the pairwise contrast in question, with the latter group as the reference. Thus, a negative estimate means that the first group mentioned in the comparison scored lower than the second group. The omnibus test represents the test of condition across the three treatment groups. An asterisk indicates statistical significance at alpha  .05; df  68 for all pairwise tests, and df  2, 68 for all omnibus tests. For all analyses, N  47 (modular); N  49 (standard); N  49 (usual care). T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 715THERAPIST SATISFACTION 2012). That is, a therapist’s beliefs about a treatment approach appear to be able to change significantly with even limited expe- rience (or simply with information, cf. Borntrager et al., 2009); these views do not apply universally to all EBT approaches (Red- ing, Chorpita, Lau, & Innes-Gomberg, 2014); and perceptions of EBTs can organize into relatively independent dimensions. This latter finding suggests that early reports about negative therapist impressions of EBTs (e.g., Addis et al., 1999; Addis & Krasnow, 2000) may be limited to impressions about a perceived lack of responsiveness, and not necessarily to the broader premise of using research findings as a basis for treatment selecting and planning. Similar findings were noted with the same sample of therapists by Borntrager et al. (2009), who concluded that negative perceptions were more likely to be due to the “manualized” nature of EBTs rather than their “evidence-based” nature. Limitations Some limitations of the study warrant mention. Because we aimed to test specific dimensions of satisfaction for which no validated measures were available, our study involved both measure development and application. Given the need to man- age therapist assessment burden in the context of a larger trial, the result was a set of scales that were briefer than what might have been derived from beginning with a much larger item pool related to the constructs of interest. Given these initial findings, it might be beneficial to consider developing more extensive measurement strategies for the Effectiveness and Responsive- ness dimensions. On the other hand, it is a potential strength from the perspective of research feasibility that a very brief scale is able to discriminate satisfaction levels across different treatment conditions. Another limitation is that the UC treat- ment approach is not well-specified in this study. Although earlier reports showed that 92% of the clinical activity in the UC condition did not involve evidence-based procedures (Weisz et al., 2012), we know less about what procedures were implemented, and hence these results may not generalize to all types of actual care delivered in routine service settings. Fi- nally, our study design did not allow us to test what aspects of the MATCH-ADC protocol (e.g., flexibility, multidisorder fo- cus) led to the specific results obtained. Conclusions Despite these limitations, the present findings lend support to the notion that protocol design may warrant significant attention in future efforts to disseminate evidence-based procedures. In addi- tion, the findings that effectiveness and responsiveness dimensions behaved differently depending on study condition highlight that treatment protocols, like any other technology, are likely neither universally satisfying nor unsatisfying. Rather, they may have favorable and unfavorable design features, such that the end-user may have nuanced perceptions of their suitability for sustained use. Continued research on such features is likely to yield improved treatment architectures, which ultimately must succeed on many fronts, including therapist preferences and youth and family out- comes. References Aarons, G. A. (2004). Mental health provider attitudes toward adoption of evidence-based practice: The Evidence-Based Practice Attitude Scale (EBPAS). Mental Health Services Research, 6, 61–74. http://dx.doi.org/ 10.1023/B:MHSR.0000024351.12294.65 Aarons, G. A., Glisson, C., Green, P. D., Hoagwood, K., Kelleher, K. J., Landsverk, J. A., . . . Schoenwald, S., & the Research Network on Youth Mental Health. (2012). The organizational social context of mental health services and clinician attitudes toward evidence-based practice: A United States national study. Implementation Science; IS, 7, 56–71. http://dx.doi.org/10.1186/1748-5908-7-56 Addis, M. E., & Krasnow, A. D. (2000). A national survey of practicing psychologists’ attitudes toward psychotherapy treatment manuals. Jour- nal of Consulting and Clinical Psychology, 68, 331–339. http://dx.doi .org/10.1037/0022-006X.68.2.331 Addis, M. E., Wade, W. A., & Hatgis, C. (1999). Barriers to dissemination of evidence-based practices: Addressing practitioners’ concerns about manual-based psychotherapies. Clinical Psychology: Science and Prac- tice, 6, 430–441. http://dx.doi.org/10.1093/clipsy.6.4.430 Ajzen, I., & Fishbein, M. (1980). Understanding attitudes and predicting social behaviour. Englewood Cliffs, NJ: Prentice Hall. American Psychological Association Task Force on Psychological In- tervention Guidelines. (1995). Template for developing guidelines: Interventions for mental disorders and psychosocial aspects of phys- ical disorders. Washington, DC: American Psychological Associa- tion. Barkley, R. A. (1997). Defiant children: A clinician’s manual for assess- ment and parent training (2nd ed.). New York: Guilford Press. Beidas, R. S., & Kendall, P. C. (2010). Training therapists in evidence- based practice: A critical review of studies from a systems-contextual perspective. Clinical Psychology: Science and Practice, 17, 1–30. http:// dx.doi.org/10.1111/j.1468-2850.2009.01187.x Bornstein, R. F., Leone, D. R., & Galley, D. J. (1987). The generalizability of subliminal mere exposure effects: Influence of stimuli perceived without awareness on social behavior. Journal of Personality and Social Psychology, 53, 1070–1079. http://dx.doi.org/10.1037/0022-3514.53.6 .1070 Borntrager, C. F., Chorpita, B. F., Higa-McMillan, C., & Weisz, J. R. (2009). Provider attitudes toward evidence-based practices: Are the concerns with the evidence or with the manuals? Psychiatric Services, 60, 677–681. http://dx.doi.org/10.1176/ps.2009.60.5.677 California Institute of Mental Health. (2014). Retrieved from http://www .cimh.org/header-link/professionals Chambers, D. A., Ringeisen, H., & Hickman, E. E. (2005). Federal, state, and foundation initiatives around evidence-based practices for child and adolescent mental health. Child and Adolescent Psychiatric Clinics of North America, 14, 307–327, ix. http://dx.doi.org/10.1016/j.chc.2004.04 .006 Chorpita, B. F., & Daleiden, E. L. (2014). Structuring the collaboration of science and service in pursuit of a shared vision. Journal of Clinical Child and Adolescent Psychology, 43, 323–338. http://dx.doi.org/ 10.1080/15374416.2013.828297 Chorpita, B. F., Daleiden, E. L., Ebesutani, C., Young, J., Becker, K. D., Nakamura, B. J., . . . Trent, L. (2011). Evidence-based treatments for children and adolescents: An updated review of indicators of efficacy and effectiveness. Clinical Psychology: Science and Practice, 18, 154– 172. http://dx.doi.org/10.1111/j.1468-2850.2011.01247.x Chorpita, B. F., Daleiden, E. L., & Weisz, J. R. (2005). Modularity in the design and application of therapeutic interventions. Applied & Preven- tive Psychology, 11, 141–156. http://dx.doi.org/10.1016/j.appsy.2005.05 .002 Chorpita, B. F., & Weisz, J. R. (2005). Modular approach to therapy for children with anxiety, depression, or conduct problems. Honolulu, HI: University of Hawaii at Manoa. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 716 CHORPITA ET AL. Chorpita, B. F., Weisz, J. R., Daleiden, E. L., Schoenwald, S. K., Palinkas, L. A., Miranda, J., . . . Gibbons, R. D., & the Research Network on Youth Mental Health. (2013). Long-term outcomes for the Child STEPs randomized effectiveness trial: A comparison of modular and standard treatment designs with usual care. Journal of Consulting and Clinical Psychology, 81, 999 –1009. http://dx.doi.org/10.1037/ a0034200 Davis, F. D., Bagozzi, R. P., & Warshaw, P. R. (1989). User acceptance of computer technology: A comparison of two theoretical models. Man- agement Science, 35, 982–1003. http://dx.doi.org/10.1287/mnsc.35.8 .982 Fazio, R. H., Zanna, M. P., & Cooper, J. (1978). Direct experience and attitude-behavior consistency: An information processing analysis. Per- sonality and Social Psychology Bulletin, 4, 48–51. http://dx.doi.org/ 10.1177/014616727800400109 Fishbein, M., & Ajzen, I. (1975). Belief, attitude, intention and behavior: An introduction to theory and research. Reading, MA: Addison Wesley. Fixsen, D. L., Naoom, S. F., Blasé, K. A., Friedman, R. M., & Wallace, F. (2005). Implementation research: A synthesis of the literature. Tampa, FL: University of South Florida, Louis de la Parte Florida Mental Health Institute, The National Implementation Research Network. Glisson, C., Landsverk, J., Schoenwald, S., Kelleher, K., Hoagwood, K. E., Mayberg, S., & Green, P., & the Research Network on Youth Mental Health. (2008). Assessing the organizational social context (OSC) of mental health services: Implications for research and practice. Administration and Policy in Mental Health and Mental Health Services Research, 35, 98–113. http://dx.doi.org/10.1007/s10488-007-0148-5 Guyatt, G., & the Evidence-Based Medicine Working Group. (1992). Evidence-based medicine. A new approach to teaching the practice of medicine. Journal of the American Medical Association, 268, 2420– 2425. http://dx.doi.org/10.1001/jama.1992.03490170092032 Herbert, J. D., Lilienfeld, S. O., Lohr, J. M., Montgomery, R. W., O’Donohue, W. T., Rosen, G. M., & Tolin, D. F. (2000). Science and pseudoscience in the development of eye movement desensitization and reprocessing: Implications for clinical psychology. Clinical Psy- chology Review, 20, 945–971. http://dx.doi.org/10.1016/S0272- 7358(99)00017-3 Higa, C. K., & Chorpita, B. F. (2008). Evidence-based therapies: Trans- lating research into practice. In R. G. Steele, T. D. Elkin, & M. C. Roberts (Eds.), Handbook of evidence-based therapies for child and adolescents (pp. 45–61). Springer. http://dx.doi.org/10.1007/978-0-387- 73691-4_4 Kazdin, A. E., & Blasé, S. L. (2011). Rebooting psychotherapy research and practice to reduce the burden of mental illness. Perspectives on Psychological Science, 6, 21–37. http://dx.doi.org/10.1177/ 1745691610393527 Kendall, P. C. (1994). Treating anxiety disorders in children: Results of a randomized clinical trial. Journal of Consulting and Clinical Psychol- ogy, 62, 100–110. http://dx.doi.org/10.1037/0022-006X.62.1.100 Kendall, P. C., Kane, M., Howard, B., & Siqueland, L. (1990). Cognitive- behavioral treatment of anxious children: Treatment manual. Ardmore, PA: Workbook Publishing. Meehl, P. E. (1993). Philosophy of science: Help or hindrance? Psycho- logical Reports, 72, 707–733. http://dx.doi.org/10.2466/pr0.1993.72.3 .707 Nakamura, B. J., Higa-McMillan, C. K., Okamura, K. H., & Shimabukuro, S. (2011). Knowledge of and attitudes towards evidence-based practices in community child mental health practitioners. Administration and Policy in Mental Health and Mental Health Services Research, 38, 287–300. http://dx.doi.org/10.1007/s10488-011-0351-2 Nakamura, B. J., Selbo-Bruns, A., Okamura, K., Chang, J., Slavin, L., & Shimabukuro, S. (2014). Developing a systematic evaluation approach for training programs within a train-the-trainer model for youth cogni- tive behavior therapy. Behaviour Research and Therapy, 53, 10–19. http://dx.doi.org/10.1016/j.brat.2013.12.001 National Institute of Mental Health. (2008). National Institute of Mental Health Strategic Plan. Retrieved from http://www.nimh.nih.gov/about/ strategic-planning-reports/nimh-strategic-plan-2008.pdf Nelson, T. D., & Steele, R. G. (2007). Predictors of practitioner self- reported use of evidence-based practices: Practitioner training, clinical setting, and attitudes toward research. Administration and Policy in Mental Health and Mental Health Services Research, 34, 319–330. http://dx.doi.org/10.1007/s10488-006-0111-x Palinkas, L. A., Weisz, J. R., Chorpita, B. F., Garland, A. F., Hoagwood, K. E., & Landsverk, J. (2013). Use of evidence-based treatments for youth mental health subsequent to a randomized controlled effectiveness trial: A qualitative study. Psychiatric Services, 64, 1110–1118. http:// dx.doi.org/10.1176/appi.ps.004682012 Reding, M. E. J., Chorpita, B. F., Lau, A. S., & Innes-Gomberg, D. (2014). Providers’ attitudes toward evidence-based practices: Is it just about providers, or do practices matter, too? Administration and Policy in Mental Health and Mental Health Services Research, 41, 767–776. http://dx.doi.org/10.1007/s10488-013-0525-1 Rogers, E. M. (2003). Diffusion of innovations (5th ed.). New York: Free Press. Schoenwald, S. K., Kelleher, K., & Weisz, J. R., & the Research Network on Youth Mental Health. (2008). Building bridges to evidence-based practice: The MacArthur foundation child system and treatment en- hancement projects (Child STEPs). Administration and Policy in Mental Health and Mental Health Services Research, 35, 66–72. http://dx.doi .org/10.1007/s10488-007-0160-9 Society of Clinical Child and Adolescent Psychology. American Psycho- logical Association & Association of Behavioral and Cognitive Thera- pies. (2014). Effective child therapy: Evidence-based mental health treatment for children and adolescents. Retrieved from http:// effectivechildtherapy.com Stirman, S. W., Crits-Christoph, P., & DeRubeis, R. J. (2004). Achieving successful dissemination of empirically supported psychotherapies: A synthesis of dissemination theory. Clinical Psychology: Science and Practice, 11, 343–359. http://dx.doi.org/10.1093/clipsy.bph091 Substance Abuse & Mental Health Services Administration. (2013). Na- tional registry of effective programs and practices. Retrieved from http://nrepp.samhsa.gov/ Taylor, S., & Todd, P. (1995). Assessing IT usage: The role of prior experience. Management Information Systems Quarterly, 19, 561–570. http://dx.doi.org/10.2307/249633 Weersing, V. R., Weisz, J. R., & Donenberg, G. R. (2002). Development of the Therapy Procedures Checklist: A therapist-report measure of technique use in child and adolescent treatment. Journal of Clinical Child and Adolescent Psychology, 31, 168 –180. http://dx.doi.org/ 10.1207/S15374424JCCP3102_03 Weisz, J. R., Chorpita, B. F., Palinkas, L. A., Schoenwald, S. K., Miranda, J., Bearman, S. K., . . . Gibbons, R. D., & the Research Network on Youth Mental Health. (2012). Testing standard and modular designs for psychotherapy treating depression, anxiety, and conduct problems in youth: A randomized effectiveness trial. Archives of Gen- eral Psychiatry, 69, 274–282. http://dx.doi.org/10.1001/archgenpsychia- try.2011.147 Weisz, J. R., Jensen-Doss, A., & Hawley, K. M. (2006). Evidence-based youth psychotherapies versus usual clinical care: A meta-analysis of direct comparisons. American Psychologist, 61, 671–689. http://dx.doi .org/10.1037/0003-066X.61.7.671 Weisz, J. R., Moore, P. S., Southam-Gerow, M. A., Weersing, V. R., Valeri, S. M., & McCarty, C. A. (2005). Therapist’s Manual PASCET: Primary and secondary control enhancement training program (3rd ed.). Los Angeles, CA: University of California. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 717THERAPIST SATISFACTION Weisz, J. R., Southam-Gerow, M. A., Gordis, E. B., Connor-Smith, J. K., Chu, B. C., Langer, D. A., . . . Weiss, B. (2009). Cognitive-behavioral therapy versus usual clinical care for youth depression: An initial test of transportability to community clinics and clinicians. Journal of Consult- ing and Clinical Psychology, 77, 383–396. http://dx.doi.org/10.1037/ a0013877 Weisz, J. R., Thurber, C. A., Sweeney, L., Proffitt, V. D., & LeGagnoux, G. L. (1997). Brief treatment of mild-to-moderate child depression using primary and secondary control enhancement training. Journal of Con- sulting and Clinical Psychology, 65, 703–707. http://dx.doi.org/10.1037/ 0022-006X.65.4.703 Weisz, J. R., Ugueto, A. M., Cheron, D. M., & Herren, J. (2013). Evidence- based youth psychotherapy in the mental health ecosystem. Journal of Clinical Child and Adolescent Psychology, 42, 274–286. http://dx.doi .org/10.1080/15374416.2013.764824 Weisz, J. R., Weiss, B., Han, S. S., Granger, D. A., & Morton, T. (1995). Effects of psychotherapy with children and adolescents revisited: A meta-analysis of treatment outcome studies. Psychological Bulletin, 117, 450–468. http://dx.doi.org/10.1037/0033-2909.117.3.450 Received April 22, 2014 Revision received March 11, 2015 Accepted March 24, 2015  Members of Underrepresented Groups: Reviewers for Journal Manuscripts Wanted If you are interested in reviewing manuscripts for APA journals, the APA Publications and Communications Board would like to invite your participation. Manuscript reviewers are vital to the publications process. As a reviewer, you would gain valuable experience in publishing. The P&C Board is particularly interested in encouraging members of underrepresented groups to participate more in this process. If you are interested in reviewing manuscripts, please write APA Journals at Reviewers@apa.org. Please note the following important points: • To be selected as a reviewer, you must have published articles in peer-reviewed journals. The experience of publishing provides a reviewer with the basis for preparing a thorough, objective review. • To be selected, it is critical to be a regular reader of the five to six empirical journals that are most central to the area or journal for which you would like to review. Current knowledge of recently published research provides a reviewer with the knowledge base to evaluate a new submission within the context of existing research. • To select the appropriate reviewers for each manuscript, the editor needs detailed information. Please include with your letter your vita. In the letter, please identify which APA journal(s) you are interested in, and describe your area of expertise. Be as specific as possible. For example, “social psychology” is not sufficient—you would need to specify “social cognition” or “attitude change” as well. • Reviewing a manuscript takes time (1–4 hours per manuscript reviewed). If you are selected to review a manuscript, be prepared to invest the necessary time to evaluate the manuscript thoroughly. APA now has an online video course that provides guidance in reviewing manuscripts. To learn more about the course and to access the video, visit http://www.apa.org/pubs/authors/review- manuscript-ce-video.aspx. T hi s do cu m en t is co py ri gh te d by th e A m er ic an Ps yc ho lo gi ca l A ss oc ia tio n or on e of its al lie d pu bl is he rs . T hi s ar tic le is in te nd ed so le ly fo r th e pe rs on al us e of th e in di vi du al us er an d is no t to be di ss em in at ed br oa dl y. 718 CHORPITA ET AL.