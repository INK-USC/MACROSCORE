{
    "abstractText": "We contrasted visual search for targets presented in prototypical views and targets presented in nonprototypical views, when targets were defined by their names andwhen theywere defined by the action thatwould normally be performed on them. The likelihood of the first fixation falling on the target was increased for prototypicalview targets falling in the lower visual field. When targets were defined by actions, the durations of fixations were reduced for targets in the lower field. The results are consistent with eye movements in search being affected by representations within the dorsal visual stream, where there is strong representation of the lower visual field. These representations are sensitive to the familiarity or the affordance offered by objects in prototypical views, and they are influenced by action-based templates for targets. In visual search tasks, participants are typically asked to detect particular targets presented among varying numbers of distractors. How the target is defined appears to affect the nature of the search process.Humphreys andRiddoch (2001) reported data froma patient with unilateral visual neglect, who frequently failed to detect targets on the side of space contralateral to his lesion when targets were defined by their names. However, this neglect was strikingly reduced when the patient was asked to find targets that were defined by the action that would be performed on them (e.g., \u2018\u2018find the object to drink from\u2019\u2019 vs. \u2018\u2018find the cup\u2019\u2019). To account for these findings, the authors suggested that the patient was able tomatch inputwith a template based on the action, but was unable to match input with a template derived from the name of the object. This was true even though the patient knew what each object was from its name, and even though he showed normal identification of single objects. The patient may have been able to maintain the action template better than any visual template derived from the object\u2019s name, so that an action template helped him sustain search on the affected side; alternatively, the patient may have been able to respond to affordances that were computed independently of an object\u2019s identity and that were detectable from objects on both the ipsiand contralesional sides of space. A study by Bekkering and Neggers (2002) provides converging evidence from normal observers. In this study, participants either pointed to or grasped a target defined by a conjunction of its orientation and color. Saccades to distractors having the same orientation as the target were more likely when a grasping response was made than when a pointing response was made. This suggests that contrasting actions can differentially weight visual information, with orientation being weighted more strongly for selection when a grasping rather than a pointing response is required (see also Hannus, Cornelissen, Lindemann, & Bekkering, 2005). These data are consistent withmodels in which search can be guided in a top-down fashion by templates defined by the target or the action to be made with the target (cf. Duncan & Humphreys, 1989;Moores, Laiti, &Chelazzi, 2003;Wolfe, 1994). Apparently, holding a template for a particular action and holding a template based on a visual definition of an object can shape the search process differently. In the study reported in this article, we sought to examine further the contrast between searching for a target defined by an Address correspondence to Glyn W. Humphreys, Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, Birmingham B15 2TT, United Kingdom, e-mail: g.w.humphreys@ bham.ac.uk. PSYCHOLOGICAL SCIENCE 42 Volume 19\u2014Number 1 Copyright r 2008 Association for Psychological Science at UNIV OF CONNECTICUT on April 12, 2015 pss.sagepub.com Downloaded from action and searching for a target defined by its name. We measured eye movements while normal participants searched for named-defined and action-defined targets. Performance was analyzed separately for trials with targets in the upper visual field and trials with targets in the lower visual field. The dorsal area of V1 represents the lower visual field and projects primarily to the dorsal visual pathway, whereas the ventral area of V1 represents the upper visual field and projects primarily to the ventral visual pathway (Horton & Hoyt, 1991; Previc, 1990). Thus, there are stronger projections from the lower visual field than from the upper visual field into posterior parietal cortex (e.g., area V6A; Galletti, Fattori, Gamberini, & Kutz, 1999). It is possible that searching by action and searching by name differentially recruit the dorsal and ventral visual pathways to support performance. Milner and Goodale (1993), for example, argued that the ventral pathway is functionally specialized for object recognition (the \u2018\u2018what\u2019\u2019 pathway) and the dorsal pathway is functionally specialized for the actions linked to objects (the \u2018\u2018how\u2019\u2019 pathway; see also Creem & Proffitt, 2001). It may follow that searching by action, recruiting the dorsal visual stream, favors information in the lower visual field. In addition, Previc (1990) argued that because the lower visual field represents near space, neural regions responding to this area are specialized for the analysis of features relevant to actions with objects in near space. In contrast, searching for an object defined by its namemay favor information in the upper visual field, whichmay bemore specialized for distal properties of objects tied to their identity (cf. Previc, 1990). In addition to examining the effects of instruction, we evaluated search for targets in prototypical relative to nonprototypical views. Though the time needed to recognize objects and to derive action-related information about objects should be less for stimuli in prototypical views than for stimuli in nonprototypical views (e.g., Palmer, Rosch, & Chase, 1981), this effect may be most pronounced for action decisions and for neural regions responsive to action affordances from objects. For example, in Humphreys and Riddoch\u2019s (2001) study of neglect, the benefits for searching by action occurred when objects appeared in prototypical views for action. Similarly, Yoon and Humphreys (2007) reported that comparedwith semantic decisionsmade in response to objects, action decisions are more sensitive to viewpoint. Accordingly, dorsal regions, which are sensitive to action, might be particularly affected by viewpoint.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sara Forti"
        },
        {
            "affiliations": [],
            "name": "Glyn W. Humphreys"
        }
    ],
    "id": "SP:376c154e4d03852b690f6c7676c45be39e4c0554",
    "references": [
        {
            "authors": [
                "H. Bekkering",
                "S.F.W. Neggers"
            ],
            "title": "Visual search is modulated by action intentions",
            "venue": "Psychological Science,",
            "year": 2002
        },
        {
            "authors": [
                "S.H. Creem",
                "D.R. Proffitt"
            ],
            "title": "Defining the cortical visual systems: \u2018\u2018What\u2019\u2019, \u2018\u2018Where\u2019\u2019, and \u2018\u2018How.\u2019",
            "venue": "Acta Psychologica,",
            "year": 2001
        },
        {
            "authors": [
                "J. Duncan",
                "G.W. Humphreys"
            ],
            "title": "Visual search and stimulus similarity",
            "venue": "Psychological Review,",
            "year": 1989
        },
        {
            "authors": [
                "C. Galletti",
                "P. Fattori",
                "M. Gamberini",
                "D.F. Kutz"
            ],
            "title": "The cortical visual area V6: Brain location and visual topography",
            "venue": "European Journal of Neuroscience,",
            "year": 1999
        },
        {
            "authors": [
                "T.C. Handy",
                "S.T. Grafton",
                "N.M. Shroff",
                "S. Ketay",
                "M.S. Gazzaniga"
            ],
            "title": "Graspable objects grab attention when the potential for action is recognized",
            "venue": "Nature Neuroscience,",
            "year": 2003
        },
        {
            "authors": [
                "A. Hannus",
                "F.W. Cornelissen",
                "O. Lindemann",
                "H. Bekkering"
            ],
            "title": "Selection-for-action in visual search",
            "venue": "Acta Psychologica,",
            "year": 2005
        },
        {
            "authors": [
                "S. Heywood",
                "J. Churcher"
            ],
            "title": "Structure of the visual array and saccadic latency: Implications for oculomotor control",
            "venue": "Quarterly Journal of Experimental Psychology,",
            "year": 1980
        },
        {
            "authors": [
                "J.C. Horton",
                "W.F. Hoyt"
            ],
            "title": "Quadrantic visual-field defects: A hallmark of lesions in extrastriate (V2/V3) cortex",
            "year": 1991
        },
        {
            "authors": [
                "G.W. Humphreys",
                "M.J. Riddoch"
            ],
            "title": "Detection by action: Evidence for affordances in search in neglect",
            "venue": "Nature Neuroscience,",
            "year": 2001
        },
        {
            "authors": [
                "A.D. Milner",
                "M.A. Goodale"
            ],
            "title": "Visual pathways to perception and action",
            "venue": "Progress in Brain Research,",
            "year": 1993
        },
        {
            "authors": [
                "E. Moores",
                "L. Laiti",
                "L. Chelazzi"
            ],
            "title": "Associative knowledge controls deployment of visual selective attention",
            "venue": "Nature Neuroscience,",
            "year": 2003
        },
        {
            "authors": [
                "C.L. Niebauer",
                "S.D. Christman"
            ],
            "title": "Upper and lower visual field differences in categorical and coordinate judgments",
            "venue": "Psychonomic Bulletin & Review,",
            "year": 1998
        },
        {
            "authors": [
                "S. Palmer",
                "E. Rosch",
                "P. Chase"
            ],
            "title": "Canonical perspective and the perception of objects",
            "venue": "Attention and performance, IX (pp. 135\u2013151)",
            "year": 1981
        },
        {
            "authors": [
                "F.H. Previc"
            ],
            "title": "Functional specialization in the lower and upper visual fields in humans: Its ecological origins and neurophysiological implications",
            "venue": "Behavioral and Brain Sciences,",
            "year": 1990
        },
        {
            "authors": [
                "J.M. Wolfe"
            ],
            "title": "Guided Search 2.0: A revised model of visual search",
            "venue": "Psychonomic Bulletin & Review,",
            "year": 1994
        },
        {
            "authors": [
                "E.Y. Yoon",
                "G.W. Humphreys"
            ],
            "title": "Dissociative effects of viewpoint and semantic priming on action and semantic decisions: Evidence for dual routes to action from vision",
            "venue": "Quarterly Journal of Experimental Psychology,",
            "year": 2007
        }
    ],
    "sections": [
        {
            "text": "sented in prototypical views and targets presented in nonprototypical views, when targets were defined by their names andwhen theywere defined by the action thatwould normally be performed on them. The likelihood of the first fixation falling on the target was increased for prototypicalview targets falling in the lower visual field. When targets were defined by actions, the durations of fixations were reduced for targets in the lower field. The results are consistent with eye movements in search being affected by representations within the dorsal visual stream, where there is strong representation of the lower visual field. These representations are sensitive to the familiarity or the affordance offered by objects in prototypical views, and they are influenced by action-based templates for targets.\nIn visual search tasks, participants are typically asked to detect particular targets presented among varying numbers of distractors. How the target is defined appears to affect the nature of the search process.Humphreys andRiddoch (2001) reported data froma patient with unilateral visual neglect, who frequently failed to detect targets on the side of space contralateral to his lesion when targets were defined by their names. However, this neglect was strikingly reduced when the patient was asked to find targets that were defined by the action that would be performed on them (e.g., \u2018\u2018find the object to drink from\u2019\u2019 vs. \u2018\u2018find the cup\u2019\u2019). To account\nfor these findings, the authors suggested that the patient was able tomatch inputwith a template based on the action, but was unable to match input with a template derived from the name of the object. This was true even though the patient knew what each object was from its name, and even though he showed normal identification of single objects. The patient may have been able to maintain the action template better than any visual template derived from the object\u2019s name, so that an action template helped him sustain search on the affected side; alternatively, the patient may have been able to respond to affordances that were computed independently of an object\u2019s identity and that were detectable from objects on both the ipsi- and contralesional sides of space.\nA study by Bekkering and Neggers (2002) provides converging evidence from normal observers. In this study, participants either pointed to or grasped a target defined by a conjunction of its orientation and color. Saccades to distractors having the same orientation as the target were more likely when a grasping response was made than when a pointing response was made. This suggests that contrasting actions can differentially weight visual information, with orientation being weighted more strongly for selection when a grasping rather than a pointing response is required (see also Hannus, Cornelissen, Lindemann, & Bekkering, 2005). These data are consistent withmodels in which search can be guided in a top-down fashion by templates defined by the target or the action to be made with the target (cf. Duncan & Humphreys, 1989;Moores, Laiti, &Chelazzi, 2003;Wolfe, 1994). Apparently, holding a template for a particular action and holding a template based on a visual definition of an object can shape the search process differently.\nIn the study reported in this article, we sought to examine further the contrast between searching for a target defined by an Address correspondence to Glyn W. Humphreys, Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, Birmingham B15 2TT, United Kingdom, e-mail: g.w.humphreys@ bham.ac.uk.\n42 Volume 19\u2014Number 1Copyright r 2008 Association for Psychological Science at UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from\naction and searching for a target defined by its name. We measured eye movements while normal participants searched for named-defined and action-defined targets. Performance was analyzed separately for trials with targets in the upper visual field and trials with targets in the lower visual field. The dorsal area of V1 represents the lower visual field and projects primarily to the dorsal visual pathway, whereas the ventral area of V1 represents the upper visual field and projects primarily to the ventral visual pathway (Horton & Hoyt, 1991; Previc, 1990). Thus, there are stronger projections from the lower visual field than from the upper visual field into posterior parietal cortex (e.g., area V6A; Galletti, Fattori, Gamberini, & Kutz, 1999). It is possible that searching by action and searching by name differentially recruit the dorsal and ventral visual pathways to support performance. Milner and Goodale (1993), for example, argued that the ventral pathway is functionally specialized for object recognition (the \u2018\u2018what\u2019\u2019 pathway) and the dorsal pathway is functionally specialized for the actions linked to objects (the \u2018\u2018how\u2019\u2019 pathway; see also Creem & Proffitt, 2001). It may follow that searching by action, recruiting the dorsal visual stream, favors information in the lower visual field. In addition, Previc (1990) argued that because the lower visual field represents near space, neural regions responding to this area are specialized for the analysis of features relevant to actions with objects in near space. In contrast, searching for an object defined by its namemay favor information in the upper visual field, whichmay bemore specialized for distal properties of objects tied to their identity (cf. Previc, 1990).\nIn addition to examining the effects of instruction, we evaluated search for targets in prototypical relative to nonprototypical views. Though the time needed to recognize objects and to derive action-related information about objects should be less for stimuli in prototypical views than for stimuli in nonprototypical views (e.g., Palmer, Rosch, & Chase, 1981), this effect may be most pronounced for action decisions and for neural regions responsive to action affordances from objects. For example, in Humphreys and Riddoch\u2019s (2001) study of neglect, the benefits for searching by action occurred when objects appeared in prototypical views for action. Similarly, Yoon and Humphreys (2007) reported that comparedwith semantic decisionsmade in response to objects, action decisions are more sensitive to viewpoint. Accordingly, dorsal regions, which are sensitive to action, might be particularly affected by viewpoint."
        },
        {
            "heading": "METHOD",
            "text": ""
        },
        {
            "heading": "Participants",
            "text": "The 14 participants (11 females and 3 males; ages 17\u201339 years, M 5 25.7) were all right-handed and had either normal or corrected-to-normal vision."
        },
        {
            "heading": "Apparatus",
            "text": "The experiment was controlled by a 1.5-GHz Pentium IV computer. Stimuli were presented on a Trinitron Multiscan G240\nmonitor (17 in.), using a screen resolution of 600 800 pixels. The display height was adjusted for each participant by setting the height of the chair he or she sat on. Eye movements were recorded using a head-mounted eyetracker (SMI Eyelink V2.04; SensoMotoric Instruments GmbH, Berlin, Germany) with a sampling rate of 250 Hz. Responses were registered using a button box."
        },
        {
            "heading": "Procedure",
            "text": "The display sequence is depicted in Figure 1a. Each trial started with a black fixation point, shown against a white background screen. The duration of this display was unlimited. When ready, the participant pressed a button to remove the fixation point, and the instructions regarding what to search for were displayed for 2,000 ms (black text on a white background). A second fixation point (600 ms) preceded the stimulus display, which remained present until the participant responded. Participants were instructed to look for and to fixate the target; once they were sure they had found the target, they were to press a button to end the trial. The speed of the button-press response was not emphasized. The target was present in all trials. Presentation of stimuli was self-paced, and subjects were allowed to take an unlimited number of breaks.\nThe stimuli were black-and-white photographs of real objects (see Fig. 1b). On any trial, all the stimuli were depicted in either a prototypical or a nonprototypical view (view was randomized across trials). When an object was depicted in a prototypical view, all its main features were visible, and the object was aligned for action. In the nonprototypical view, the object was rotated away from its usual view, and it was not oriented for a right-hand action; typically, the graspable part of the object was positioned toward the nondominant (left) hand (for our righthanded participants).\nVolume 19\u2014Number 1 43\nat UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from\nEach photograph was inscribed into an area measuring 100 100 pixels (4.61 4.61 at a viewing distance of 60 cm), and the relative size of the objects was taken into account (e.g., a bicycle was bigger than a pen). Within each display, eight stimuli were presented in a circle with a radius of 170 pixels (7.41); the two middle objects were placed at eye level, in order to have the three upper objects falling in the upper visual field and the three lower objects falling in the lower visual field. The target\u2019s position was randomized across trials. In the analyses, we excluded trials in which the target was one of the two middle objects, considering only stimuli in the upper and lower visual fields.\nThere were two instruction conditions, presented in two separate blocks of 240 trials each, and block order was randomized across participants. In the name condition, the participants were given the names of the objects they had to look at (e.g., \u2018\u2018scissors\u2019\u2019); in the action condition, each target was defined by the associated action (e.g., \u2018\u2018cut paper\u2019\u2019). Thus, the target was ambiguously specified in the action condition, because there are typically multiple objects consistent with a given action. However, within a search display, there was only one object consistent with the instructions given (i.e., only one object with the name given in name search and only one object consistent with the action given in action search). We used a set of 60 familiar objects; 20 that could be defined either by a name or by a specific action were used as targets, and the remaining 40 were always used as distractors."
        },
        {
            "heading": "RESULTS",
            "text": "We considered the effects of three variables: the instructions (search by name vs. search by action), the viewpoint (prototypical vs. nonprototypical), and the target\u2019s visual field (upper vs. lower).1 The data were analyzed in three-way repeated measures analyses of variance. Including only correct trials (i.e., those on which the target was eventually fixated), we measured (a) the probability that the first fixation was on the target, (b) the time taken until the first fixation on the target, (c) the duration of the first fixation on the target, (d) the total number of fixations on the target, and (e) the total length of fixations on the target (summed across different fixations in a trial)."
        },
        {
            "heading": "Probability of the First Fixation Being on the Target",
            "text": "The probability of the first fixation being on the target showed a significant effect of viewpoint, F(1, 13) 5 50.3, prep > .99: Prototypical-view targets received more first fixations (M 5 12.2%) than nonprototypical-view targets (M 5 5.3%). There\nwas also a significant main effect of the target\u2019s visual field, F(1, 13) 5 22.6, prep > .99, with targets in the lower visual field receiving more first fixations (M 5 12.2%) than targets in the upper visual field (M5 5.3%). These two factors interacted,F(1, 13)5 14.2, prep> .99: The effect of visual field was enhanced for objects depicted in a prototypical orientation, though visual field was significant for both views. There was no main effect of instructions, F(1, 13) 5 1.2, prep 5 .64, and no interactions involving this factor were significant (all Fs < .0). The results for this dependent measure are depicted in the top panel of Figure 2."
        },
        {
            "heading": "Time Until the First Fixation on the Target",
            "text": "This measure showed no reliable effects (see Fig. 2, bottom panel)."
        },
        {
            "heading": "Duration of the First Fixation on the Target",
            "text": "The duration of the first fixation on the target showed a reliable main effect of viewpoint, with longer fixations to nonprototypical than to prototypical targets, F(1, 13)5 10.33, prep5 .852, but no effects of instructions or the target\u2019s visual field, F(1, 13)5 2.46 and F< 1.0, both preps< .88. There was an interaction between the type of instruction and the target\u2019s visual field, F(1, 13) 5 10.926, prep5 .86. In the action condition, first-fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13) 5 2.1, prep 5 .88. In the name condition, the durations of the first fixation on the target were, if anything, shorter for targets in the upper than for those in the lower visual field, t(13)5 1.8, prep5 .82.We also found a reliable interaction between instructions and viewpoint,F(1, 13)5 17.88, prep > .99: First fixations to targets in prototypical viewers were shorter than first fixations to targets in nonprototypical views in the action condition, t(13)5 3.8, prep 5 .98, but not in the name condition, t(13) 5 1.4, prep 5 .74. Finally, there was a reliable three-way interaction among instructions, viewpoint, and visual field, F(1, 13) 5 6.44, prep 5 .92 (see Fig. 3, top panel). The effects of viewpoint were pronounced only in the action condition for targets in the upper field, t(13)5 3.8, prep 5 .98."
        },
        {
            "heading": "Number of Fixations on the Target",
            "text": "The number of fixations on the target (prior to responding to finding the target) showed a reliable main effect of viewpoint, F(1, 13) 5 6.23, prep 5 .91; there were more fixations on nonprototypical-view than on prototypical-view targets. The effect of instructions was not reliable, F(1, 13) 5 1.06, prep 5 .63, though the main effect of the target\u2019s visual field approached significance, F(1, 13) 5 3.81, prep 5 .85. There was an interaction between instructions and visual field, F(1, 13) 5 5.98, prep 5 .91. In the action condition, fewer fixations were made to targets in the lower visual field than to targets in the upper visual field, t(13)5 3.0, prep5 .95; in the name condition, there was no 1We also examined effects of whether items fell in the left or right visual field, because some studies indicate differences between the upper and lower visual fields on either only the left side (Niebauer & Christman, 1998) or only the right side (Handy, Grafton, Shroff, Ketay, & Gazzaniga, 2003), depending on the task. However, we failed to find effects of left versus right field. Hence, the data are averaged across this factor.\n44 Volume 19\u2014Number 1\nat UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from\neffect of visual field, t(13)5 0.3, prep 5 .29. These effects held across both prototypical and nonprototypical views,F(1, 13)< 1.0 for the interaction of instructions, viewpoint, and visual field. The bottom panel in Figure 3 presents the mean numbers of fixations on targets."
        },
        {
            "heading": "Total Length of Fixations on the Target",
            "text": "This measure showed a main effect of viewpoint, F(1, 13) 5 7.50, prep 5 .93, with total fixation time being longer for nonprototypical than for prototypical objects; the main effect of instructions was not reliable (F < 1.0), but that of field approached significance, F(1, 13) 5 4.00, prep 5 .85. There was one reliable interaction, between instructions and visual field, F(1, 13) 5 5.18, prep > .89. In the action condition, fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13)5 2.7, prep5 .93; in the name condition, there was no effect of visual field, t(13) 5 0.3, prep 5 .33. The data are shown in the middle panel of Figure 3."
        },
        {
            "heading": "DISCUSSION",
            "text": "Search varied as a function of the orientation of the stimuli and the instructions given for the search task. We discuss each effect in turn. Generally, we found an effect of orientation in four of the five eye movement parameters measured, with performance being facilitated for stimuli depicted in a prototypical view.\nThus, compared with nonprototypical-view targets, prototypical-view targets were more likely to receive first fixations, had shorter total fixation durations, and required fewer fixations before the detection response was initiated. These effects of viewpoint are consistent with the literature on object recognition and on action decisions in response to objects, which shows that the familiarity of view is a strong determiner of performance (Palmer et al., 1981; Yoon & Humphreys, 2007). Interestingly, though, viewpoint interacted with visual field when the probability of making a first fixation to a target and the duration of the first fixation to the target were measured. The increased probability of making a first fixation to a prototypical-view target was more pronounced when the target was in the lower visual field than when it was in the upper visual field.\nThe instruction manipulation influenced several other eye movement parameters. Specifically, the action instructions facilitated performance as measured by parameters reflecting eye movements after targets had been fixated (Fig. 3). These effects were confined to targets falling in the lower visual field. The duration of the first fixation made to the target, the number of fixations made to the target before the detection response was made, and the average total length of the fixations on the target were all selectively reduced for targets in the lower visual field in the action condition. When objects were cued by their names, these effects of field were absent (if anything, there was a tendency for the duration of the first fixations on targets to be reduced for targets in the upper visual field).\nVolume 19\u2014Number 1 45\nat UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from\nTo understand these results, it is useful to differentiate between effects on the first saccade made in search and effects on subsequent fixation behavior. The probability of the first saccade being directed at a target was affected by the orientation of the stimuli and the visual field of the target, but not by the instructions. The first saccade was more likely to go to a prototypical-view than to a nonprototypical-view target, but only when that target fell in the lower visual field; indeed, only when a prototypical-view target fell in the lower visual field was the likelihood of the first fixation going to the target greater than chance. In many search tasks, search is biased to start in the upper visual field (Heywood & Churcher, 1980). However, there was no evidence for such a bias in the present study. We calculated the probability of the first saccade being directed toward the upper versus the lower visual field, irrespective of the target\u2019s location, and found no difference in the rate of downward\n46 Volume 19\u2014Number 1\nat UNIV OF CONNECTICUT on April 12, 2015pss.sagepub.comDownloaded from\nversus upward saccades, either as amain effect,F(1, 13)5 3.09, prep5 .81, or in combination with instructions or viewpoint (both Fs < 1.0). The data suggest that there was no systematic tendency, across participants, for search to start or end in set locations. The tendency for first fixations to go to a prototypicalview target in the lower field, then, does not reflect a general pattern in search, but rather reflects the capture of overt attention by the stimulus. This result is consistent with the prototypical-view target being detected by the dorsal visual stream prior to the eye movement being programmed\u2014so that the effect emerged only when the target was in the lower visual field. The data suggest that the dorsal stream is sensitive to either the familiarity of the viewpoint or the affordance when the object is in the appropriate orientation for action.\nViewpoint had an early effect on search, influencing where the first saccade was made. However, the task instructions did affect fixation behavior after the first saccade. Fixation durations were reduced, and fewer fixations weremade, when targets were in the lower visual field and the action instructions were given. In the name condition, first-fixation durations tended to be reduced for targets in the upper visual field. These results suggest that the different task instructions affected a stage of processing in which fixated information was matched to a template defining the target. There appears to be a better match of stimulus information to an action-based template for a target falling in the lower, rather than the upper, visual field, whereas, if anything, there is a better match to a template derived from the object\u2019s name when the target is in the upper, rather than the lower, visual field. This fit to the template in the action task is also better for objects depicted in prototypical views, given that the duration of the first fixation in this condition was shorter for targets in prototypical views than for targets in nonprototypical views. These results are consistent with action-based templates being represented in the dorsal visual stream.2\nAlthough action instructions reduced the duration of the first fixation to targets in the lower visual field, first fixations were much longer under action than name instructions when targets fell in the upper visual field. This is not surprising. There is inherently more ambiguity about targets defined by action than about targets defined by their name (\u2018\u2018Is there an object that cuts paper present?\u2019\u2019 vs. \u2018\u2018Are scissors present?\u2019\u2019), and one can thus expect that it would take more time to verify that a target matches a verbal instruction under action than under name instructions. The striking result is that this advantage for the name condition was reversed for targets in the lower field, which suggests that an action template was matched directly to the stimulus in this case.\nIt should be noted that once an observer makes a first saccade to an item in the upper or lower visual field, that item is no longer\nin the same retinotopic location, though the object remains in the same position with respect to the observer\u2019s body. Also, after the first saccade, objects originally in the lower visual field may tend still to be represented in near space, and objects originally in the upper visual field to be represented in far space (cf. Previc, 1990). If processing biases in the dorsal stream are sensitive to the position of objects with respect to the observer\u2019s body, or if the dorsal stream is more sensitive to object locations in near space than to object locations in far space, then the emergence of the lower-field advantage in searching by action can be explained. In addition, it is possible that the advantage of the lower visual field reflects the superior extraction of information from the retinotopic lower field, which then facilitates matching to the action template. The opposite tendency, for an upper-field advantage in searching for objects defined by their names, also arose for fixation behavior subsequent to the first saccade, which suggests that this tendency, too, reflects a process involving matching to memory, rather than directing attention in the first place.\nIn conclusion, the data indicate that action instructions and viewpoint-dependent familiarity or affordance have specific effects on search for objects appearing in the lower visual field. The results fit with the idea that the dorsal visual stream, where there is strong representation of the lower visual field, can both direct overt attention (the first saccade) and modulate the time required to match a stimulus to a template of the target.\nAcknowledgments\u2014This work was supported by grants from\nthe Biotechnology and Biological Sciences Research Council,\nEngineering and Physical Sciences Research Council, and Med-\nical Research Council (UK)."
        }
    ],
    "title": "Sensitivity to Object Viewpoint and Action Instructions During Search for Targets in the Lower Visual Field",
    "year": 2009
}